{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81807332",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db7e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa todas as bibliotecas\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import nrrd\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, Conv3D, MaxPooling3D, Concatenate, Add, ReLU,\n",
    "    BatchNormalization,GlobalAveragePooling1D, Dense, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, Reshape, AveragePooling3D\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22644475",
   "metadata": {},
   "source": [
    "### Aux. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30104676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, mask_dir):\n",
    "    \"\"\"\n",
    "    Encontra e pareia os caminhos das imagens com suas \n",
    "    respectivas máscaras de segmentação.\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "\n",
    "    # Garante que os arquivos estão ordenados para o pareamento correto\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_file, mask_file in zip(image_files, mask_files):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        \n",
    "        if os.path.exists(mask_path):\n",
    "            # Ler a máscara para determinar o rótulo\n",
    "            mask_itk = sitk.ReadImage(mask_path)\n",
    "            mask_np = sitk.GetArrayFromImage(mask_itk)\n",
    "            \n",
    "            # O rótulo é 1 se houver qualquer pixel não-zero na máscara, senão 0\n",
    "            label = 1 if np.sum(mask_np) > 0 else 0\n",
    "            \n",
    "            file_list.append({\n",
    "                \"image\": image_path,\n",
    "                \"mask\": mask_path,\n",
    "                \"label\": label\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Aviso: Máscara não encontrada para {image_path}\")\n",
    "            \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d86e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_encoder(input_shape=(128, 128, 128, 2)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # ... Camadas conv1, pool1, conv2, pool2, conv3, pool3 ...\n",
    "    conv1 = Conv3D(16, 3, padding='same', activation='relu')(inputs)\n",
    "    pool1 = MaxPooling3D(pool_size=2)(conv1)\n",
    "    conv2 = Conv3D(32, 3, padding='same', activation='relu')(pool1)\n",
    "    pool2 = MaxPooling3D(pool_size=2)(conv2)\n",
    "    conv3 = Conv3D(64, 3, padding='same', activation='relu')(pool2)\n",
    "    pool3 = MaxPooling3D(pool_size=2)(conv3)\n",
    "    \n",
    "    # Nível 4 -> Saída 16^3\n",
    "    conv4 = Conv3D(128, 3, padding='same', activation='relu')(pool3)\n",
    "    conv4 = Conv3D(128, 3, padding='same', activation='relu')(conv4)\n",
    "    pool4 = MaxPooling3D(pool_size=2)(conv4) # <-- ADICIONE MAIS UM POOLING\n",
    "\n",
    "    # Nível 5 (Novo Gargalo) -> Saída 8^3\n",
    "    conv5 = Conv3D(256, 3, padding='same', activation='relu')(pool4)\n",
    "    conv5 = Conv3D(256, 3, padding='same', activation='relu')(conv5)\n",
    "\n",
    "    # Coletamos as saídas das escalas que usaremos\n",
    "    multiscale_features = [conv3, conv4, conv5] # <-- ATUALIZE A LISTA\n",
    "    \n",
    "    encoder = Model(inputs, multiscale_features, name=\"cnn_multiscale_encoder\")\n",
    "    return encoder\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    \n",
    "def build_hybrid_transformer_classifier(\n",
    "    input_shape=(128, 128, 128, 2), \n",
    "    num_transformer_blocks=3,\n",
    "    num_heads=8,\n",
    "    embed_dim=224,\n",
    "    ff_dim=224):\n",
    "\n",
    "    encoder = build_cnn_encoder(input_shape)\n",
    "    image_input = Input(shape=input_shape)\n",
    "    features_list = encoder(image_input)\n",
    "\n",
    "    resized_features = []\n",
    "    resized_features.append(AveragePooling3D(pool_size=4)(features_list[0])) \n",
    "    resized_features.append(AveragePooling3D(pool_size=2)(features_list[1]))\n",
    "    resized_features.append(features_list[2])\n",
    "\n",
    "    concatenated_features = Concatenate(axis=-1)(resized_features)\n",
    "\n",
    "    seq_length = concatenated_features.shape[1] * concatenated_features.shape[2] * concatenated_features.shape[3]\n",
    "    reshaped_features = Reshape((seq_length, concatenated_features.shape[-1]))(concatenated_features)\n",
    "\n",
    "    positional_embedding = layers.Embedding(input_dim=seq_length, output_dim=embed_dim)(tf.range(seq_length))\n",
    "    x = reshaped_features + positional_embedding\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "    # --- Cabeça de Classificação ---\n",
    "    # Usamos GlobalAveragePooling1D para agregar a dimensão da sequência.\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # A saída agora é (batch, embed_dim)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7765bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot do treinamento do modelo\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Função de plot da matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadbb31",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64a6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os pares de caminhos\n",
    "IMAGE_DIR = \"Patients_Displasya/T1\"\n",
    "MASK_DIR = \"Mascaras\"\n",
    "file_list = load_data(IMAGE_DIR, MASK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64abd463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras encontradas: 41\n",
      "Amostras com lesão (label 1): 41\n",
      "Amostras saudáveis (label 0): 0\n",
      "Amostras de treino: 29\n",
      "Amostras de validação: 8\n",
      "Amostras de teste: 4\n"
     ]
    }
   ],
   "source": [
    "# Verificar o balanceamento das classes\n",
    "labels = [item['label'] for item in file_list]\n",
    "print(f\"Total de amostras encontradas: {len(file_list)}\")\n",
    "print(f\"Amostras com lesão (label 1): {np.sum(labels)}\")\n",
    "print(f\"Amostras saudáveis (label 0): {len(labels) - np.sum(labels)}\")\n",
    "\n",
    "train_files, test_files = train_test_split(file_list, test_size=0.08, random_state=42, stratify=labels)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.2, random_state=42, stratify=[item['label'] for item in train_files])\n",
    "\n",
    "print(f\"Amostras de treino: {len(train_files)}\")\n",
    "print(f\"Amostras de validação: {len(val_files)}\")\n",
    "print(f\"Amostras de teste: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf94189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 128, 128, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_multiscale_encoder (Functio [(None, 32, 32, 32,  3388624     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_10 (AveragePo (None, 8, 8, 8, 64)  0           cnn_multiscale_encoder[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_11 (AveragePo (None, 8, 8, 8, 128) 0           cnn_multiscale_encoder[0][1]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 8, 448) 0           average_pooling3d_10[0][0]       \n",
      "                                                                 average_pooling3d_11[0][0]       \n",
      "                                                                 cnn_multiscale_encoder[0][2]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 512, 448)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 512, 448)     0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 512, 448)     6837824     tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_7 (Transforme (None, 512, 448)     6837824     transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_8 (Transforme (None, 512, 448)     6837824     transformer_block_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 448)          0           transformer_block_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 448)          0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 448)          201152      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            449         dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,103,697\n",
      "Trainable params: 24,103,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (128, 128, 128, 2)\n",
    "\n",
    "# Construir o modelo híbrido\n",
    "model = build_hybrid_transformer_classifier(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    embed_dim=448,\n",
    "    ff_dim=448\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60914291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o shape final desejado\n",
    "TARGET_SHAPE_3D = (128, 128, 128)\n",
    "\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    def _read_and_resize_nifti(path):\n",
    "        # Decodificar o tensor de bytes para uma string Python\n",
    "        path = path.numpy().decode('utf-8')\n",
    "        \n",
    "        # Carregar a imagem com nibabel\n",
    "        nifti_image = nib.load(path).get_fdata().astype(np.float32)\n",
    "        \n",
    "        # --- CORREÇÃO AQUI: Redimensionamento 3D ---\n",
    "        # Obter a forma original e calcular o fator de zoom para cada eixo\n",
    "        original_shape = nifti_image.shape\n",
    "        zoom_factors = [\n",
    "            TARGET_SHAPE_3D[0] / original_shape[0],\n",
    "            TARGET_SHAPE_3D[1] / original_shape[1],\n",
    "            TARGET_SHAPE_3D[2] / original_shape[2]\n",
    "        ]\n",
    "        \n",
    "        # Aplicar o redimensionamento (interpolação trilinear por padrão)\n",
    "        resized_image = zoom(nifti_image, zoom_factors, order=1)\n",
    "        \n",
    "        return resized_image\n",
    "\n",
    "    # Executar a função de leitura e redimensionamento\n",
    "    image = tf.py_function(\n",
    "        func=_read_and_resize_nifti, \n",
    "        inp=[image_path], \n",
    "        Tout=tf.float32\n",
    "    )\n",
    "    \n",
    "    # Como agora garantimos o tamanho, podemos definir a forma estaticamente\n",
    "    image.set_shape(TARGET_SHAPE_3D)\n",
    "    \n",
    "    # O resto do pré-processamento continua igual\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    image = tf.repeat(image, repeats=INPUT_SHAPE[3], axis=-1)\n",
    "    image = image / (tf.reduce_max(image) + 1e-6) \n",
    "    image.set_shape(INPUT_SHAPE)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Extrair os caminhos e rótulos das nossas listas\n",
    "train_paths = [item['image'] for item in train_files]\n",
    "train_labels = [item['label'] for item in train_files]\n",
    "val_paths = [item['image'] for item in val_files]\n",
    "val_labels = [item['label'] for item in val_files]\n",
    "test_paths = [item['image'] for item in test_files]\n",
    "test_labels = [item['label'] for item in test_files]\n",
    "\n",
    "# Definir o batch_size\n",
    "batch_size = 4\n",
    "\n",
    "# Criar o dataset de treino com .batch()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Criar o dataset de validação com .batch()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18de94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 36s 439ms/step - loss: 0.0652 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.9310 - val_loss: 7.1503e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 269ms/step - loss: 1.1843e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6021e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 268ms/step - loss: 4.8491e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9433e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 272ms/step - loss: 4.3090e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6759e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 6s 286ms/step - loss: 3.0785e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5180e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 8s 417ms/step - loss: 4.1408e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3591e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 10s 375ms/step - loss: 3.6558e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1951e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 8s 361ms/step - loss: 1.9275e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0804e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 6s 275ms/step - loss: 2.0332e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8577e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 268ms/step - loss: 2.3668e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8592e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 269ms/step - loss: 1.9399e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0040e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 271ms/step - loss: 1.7716e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2300e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 6s 281ms/step - loss: 1.8965e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3898e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 277ms/step - loss: 1.4204e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6875e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 278ms/step - loss: 1.4777e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0688e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 272ms/step - loss: 1.1938e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4168e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 269ms/step - loss: 8.2632e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9890e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 272ms/step - loss: 9.7266e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5921e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 271ms/step - loss: 8.8218e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1899e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 270ms/step - loss: 9.2599e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8089e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 283ms/step - loss: 7.8914e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4907e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 9s 355ms/step - loss: 5.9597e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2278e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 9s 391ms/step - loss: 4.6159e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0350e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 9s 367ms/step - loss: 5.2311e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8631e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 9s 357ms/step - loss: 5.3711e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6898e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 9s 368ms/step - loss: 4.6154e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5377e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 9s 440ms/step - loss: 3.3519e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4129e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 9s 364ms/step - loss: 4.0322e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2998e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 9s 381ms/step - loss: 4.0829e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1937e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 9s 360ms/step - loss: 3.0896e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0934e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 9s 358ms/step - loss: 2.7684e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0207e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 10s 413ms/step - loss: 2.1632e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6170e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 9s 376ms/step - loss: 2.4078e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0398e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 9s 395ms/step - loss: 2.2576e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5396e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 9s 423ms/step - loss: 2.4749e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9296e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 10s 378ms/step - loss: 2.5861e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3357e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 9s 358ms/step - loss: 2.0893e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8750e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 9s 365ms/step - loss: 2.0144e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4437e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 10s 404ms/step - loss: 1.9935e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0746e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 8s 356ms/step - loss: 1.3402e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7640e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 9s 352ms/step - loss: 1.6330e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4703e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 10s 386ms/step - loss: 1.2190e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2217e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 9s 375ms/step - loss: 1.4389e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9825e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 9s 373ms/step - loss: 1.2921e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7746e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 10s 365ms/step - loss: 1.7858e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5261e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 9s 389ms/step - loss: 1.4357e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2669e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 9s 368ms/step - loss: 9.4461e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0902e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 9s 382ms/step - loss: 9.9520e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9368e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 9s 370ms/step - loss: 1.0416e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7867e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/100\n"
     ]
    }
   ],
   "source": [
    "# Compilando o modelo híbrido\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]\n",
    ")\n",
    "\n",
    "# Hiperparâmetros\n",
    "num_epochs = 100\n",
    "\n",
    "# Histórico do treinamento\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs)\n",
    "\n",
    "print(\"Treinamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (history.predict(val_paths) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (history.predict(test_paths) > 0.5).astype(int)\n",
    "\n",
    "# Gerar o relatório de classificação\n",
    "print(\"Validação:\")\n",
    "print(classification_report(val_labels, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "print(classification_report(test_labels, y_pred_test)) \n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(val_labels, y_pred_valid)\n",
    "print(\"Teste:\")\n",
    "plot_confusion_matrix(test_labels, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "displasia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
