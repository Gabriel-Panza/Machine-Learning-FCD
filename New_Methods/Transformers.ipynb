{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81807332",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa todas as bibliotecas\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import nrrd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv3D, MaxPooling3D, Concatenate, Add, ReLU,\n",
    "    BatchNormalization,GlobalAveragePooling1D, Dense, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, Reshape, AveragePooling3D\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22644475",
   "metadata": {},
   "source": [
    "### Aux. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30104676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, mask_dir):\n",
    "    \"\"\"\n",
    "    Encontra e pareia os caminhos das imagens com suas \n",
    "    respectivas máscaras de segmentação.\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "\n",
    "    # Garante que os arquivos estão ordenados para o pareamento correto\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_file, mask_file in zip(image_files, mask_files):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        \n",
    "        if os.path.exists(mask_path):\n",
    "            # Ler a máscara para determinar o rótulo\n",
    "            mask_itk = sitk.ReadImage(mask_path)\n",
    "            mask_np = sitk.GetArrayFromImage(mask_itk)\n",
    "            \n",
    "            # O rótulo é 1 se houver qualquer pixel não-zero na máscara, senão 0\n",
    "            label = 1 if np.sum(mask_np) > 0 else 0\n",
    "            \n",
    "            file_list.append({\n",
    "                \"image\": image_path,\n",
    "                \"mask\": mask_path,\n",
    "                \"label\": label\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Aviso: Máscara não encontrada para {image_path}\")\n",
    "            \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_encoder(input_shape=(128, 128, 128, 2)):\n",
    "    \"\"\"\n",
    "    Constrói a parte do Encoder de uma CNN 3D (similar a uma U-Net)\n",
    "    e retorna os mapas de características de múltiplas escalas.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Nível 1 -> Saída 128^3\n",
    "    conv1 = Conv3D(16, 3, padding='same', activation='relu')(inputs)\n",
    "    conv1 = Conv3D(16, 3, padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=2)(conv1)\n",
    "\n",
    "    # Nível 2 -> Saída 64^3\n",
    "    conv2 = Conv3D(32, 3, padding='same', activation='relu')(pool1)\n",
    "    conv2 = Conv3D(32, 3, padding='same', activation='relu')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=2)(conv2)\n",
    "\n",
    "    # Nível 3 -> Saída 32^3\n",
    "    conv3 = Conv3D(64, 3, padding='same', activation='relu')(pool2)\n",
    "    conv3 = Conv3D(64, 3, padding='same', activation='relu')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=2)(conv3)\n",
    "\n",
    "    # Nível 4 (Gargalo) -> Saída 16^3\n",
    "    conv4 = Conv3D(128, 3, padding='same', activation='relu')(pool3)\n",
    "    conv4 = Conv3D(128, 3, padding='same', activation='relu')(conv4)\n",
    "\n",
    "    # Coletamos as saídas de diferentes escalas que usaremos\n",
    "    # O artigo usa as escalas 1/4, 1/8, 1/16, 1/32. Vamos pegar as equivalentes.\n",
    "    # A saída de conv2 está na resolução 1/2.\n",
    "    # A saída de conv3 está na resolução 1/4.\n",
    "    # A saída de conv4 está na resolução 1/8.\n",
    "    multiscale_features = [conv2, conv3, conv4]\n",
    "    \n",
    "    encoder = Model(inputs, multiscale_features, name=\"cnn_multiscale_encoder\")\n",
    "    return encoder\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    \n",
    "def build_hybrid_transformer_classifier(\n",
    "    input_shape=(128, 128, 128, 2), \n",
    "    num_transformer_blocks=3,\n",
    "    num_heads=8,\n",
    "    embed_dim=224, # Ajuste este valor para a soma dos canais concatenados\n",
    "    ff_dim=224,\n",
    "    num_classes=2):\n",
    "\n",
    "    # ... (Toda a parte do Encoder CNN e combinação multiescala continua igual) ...\n",
    "    encoder = build_cnn_encoder(input_shape)\n",
    "    image_input = Input(shape=input_shape)\n",
    "    features_list = encoder(image_input)\n",
    "\n",
    "    target_shape = features_list[-1].shape[1:4]\n",
    "    resized_features = []\n",
    "    resized_features.append(AveragePooling3D(pool_size=4)(features_list[0])) \n",
    "    resized_features.append(AveragePooling3D(pool_size=2)(features_list[1]))\n",
    "    resized_features.append(features_list[2])\n",
    "\n",
    "    concatenated_features = Concatenate(axis=-1)(resized_features)\n",
    "\n",
    "    seq_length = concatenated_features.shape[1] * concatenated_features.shape[2] * concatenated_features.shape[3]\n",
    "    reshaped_features = Reshape((seq_length, concatenated_features.shape[-1]))(concatenated_features)\n",
    "\n",
    "    positional_embedding = layers.Embedding(input_dim=seq_length, output_dim=embed_dim)(tf.range(seq_length))\n",
    "    x = reshaped_features + positional_embedding\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "    # --- Cabeça de Classificação ---\n",
    "    # Usamos GlobalAveragePooling1D para agregar a dimensão da sequência.\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # A saída agora é (batch, embed_dim)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot do treinamento do modelo\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Função de plot da matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadbb31",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os pares de caminhos\n",
    "IMAGE_DIR = \"Patients_Displasya/T1\"\n",
    "MASK_DIR = \"Mascaras\"\n",
    "file_list = load_data(IMAGE_DIR, MASK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o balanceamento das classes\n",
    "labels = [item['label'] for item in file_list]\n",
    "print(f\"Total de amostras encontradas: {len(file_list)}\")\n",
    "print(f\"Amostras com lesão (label 1): {np.sum(labels)}\")\n",
    "print(f\"Amostras saudáveis (label 0): {len(labels) - np.sum(labels)}\")\n",
    "\n",
    "train_files, test_files = train_test_split(file_list, test_size=0.08, random_state=42, stratify=labels)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.2, random_state=42, stratify=[item['label'] for item in train_files])\n",
    "\n",
    "print(f\"Amostras de treino: {len(train_files)}\")\n",
    "print(f\"Amostras de validação: {len(val_files)}\")\n",
    "print(f\"Amostras de teste: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf94189",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (128, 128, 128, 2)\n",
    "NUM_CLASSES = 2 # Saudável vs. Displasia\n",
    "\n",
    "# Construir o modelo híbrido\n",
    "model = build_hybrid_transformer_classifier(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    embed_dim=224,\n",
    "    ff_dim=224,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60914291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o shape final desejado\n",
    "TARGET_SHAPE_3D = (128, 128, 128)\n",
    "\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    def _read_and_resize_nifti(path):\n",
    "        # Decodificar o tensor de bytes para uma string Python\n",
    "        path = path.numpy().decode('utf-8')\n",
    "        \n",
    "        # Carregar a imagem com nibabel\n",
    "        nifti_image = nib.load(path).get_fdata().astype(np.float32)\n",
    "        \n",
    "        # --- CORREÇÃO AQUI: Redimensionamento 3D ---\n",
    "        # Obter a forma original e calcular o fator de zoom para cada eixo\n",
    "        original_shape = nifti_image.shape\n",
    "        zoom_factors = [\n",
    "            TARGET_SHAPE_3D[0] / original_shape[0],\n",
    "            TARGET_SHAPE_3D[1] / original_shape[1],\n",
    "            TARGET_SHAPE_3D[2] / original_shape[2]\n",
    "        ]\n",
    "        \n",
    "        # Aplicar o redimensionamento (interpolação trilinear por padrão)\n",
    "        resized_image = zoom(nifti_image, zoom_factors, order=1)\n",
    "        \n",
    "        return resized_image\n",
    "\n",
    "    # Executar a função de leitura e redimensionamento\n",
    "    image = tf.py_function(\n",
    "        func=_read_and_resize_nifti, \n",
    "        inp=[image_path], \n",
    "        Tout=tf.float32\n",
    "    )\n",
    "    \n",
    "    # Como agora garantimos o tamanho, podemos definir a forma estaticamente\n",
    "    image.set_shape(TARGET_SHAPE_3D)\n",
    "    \n",
    "    # O resto do pré-processamento continua igual\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    image = tf.repeat(image, repeats=INPUT_SHAPE[3], axis=-1)\n",
    "    image = image / (tf.reduce_max(image) + 1e-6) \n",
    "    image.set_shape(INPUT_SHAPE)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Extrair os caminhos e rótulos das nossas listas\n",
    "train_paths = [item['image'] for item in train_files]\n",
    "train_labels = [item['label'] for item in train_files]\n",
    "val_paths = [item['image'] for item in val_files]\n",
    "val_labels = [item['label'] for item in val_files]\n",
    "test_paths = [item['image'] for item in test_files]\n",
    "test_labels = [item['label'] for item in test_files]\n",
    "\n",
    "# Definir o batch_size\n",
    "batch_size = 4\n",
    "\n",
    "# Criar o dataset de treino com .batch()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Criar o dataset de validação com .batch()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18de94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando o modelo híbrido\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]\n",
    ")\n",
    "\n",
    "# Hiperparâmetros\n",
    "num_epochs = 100\n",
    "\n",
    "# Histórico do treinamento\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs)\n",
    "\n",
    "print(\"Treinamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (history.predict(val_paths) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (history.predict(test_paths) > 0.5).astype(int)\n",
    "\n",
    "# Gerar o relatório de classificação\n",
    "print(\"Validação:\")\n",
    "print(classification_report(val_labels, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "print(classification_report(test_labels, y_pred_test)) \n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(val_labels, y_pred_valid)\n",
    "print(\"Teste:\")\n",
    "plot_confusion_matrix(test_labels, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
