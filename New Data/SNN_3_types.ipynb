{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa todas as bibliotecas\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models, callbacks, metrics, Input, Model, regularizers\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, auc, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções necessárias para armazenar os dados e rodar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para carregar as imagens já pré-processadas e calcular os labels\n",
    "def calculate_label(image, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Determina o label da subimagem com base no percentual de fundo não-preto.\n",
    "    :param subimage: Array da subimagem.\n",
    "    :param threshold: Percentual mínimo de fundo não-preto para considerar como label 1.\n",
    "    :return: String indicando o label.\n",
    "    \"\"\"\n",
    "    # Total de pixels na subimagem\n",
    "    total_pixels = image.size\n",
    "    # Número de pixels não-preto\n",
    "    non_zero_pixels = np.count_nonzero(image)\n",
    "    # Proporção de pixels não-preto\n",
    "    non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    \n",
    "    # Verifica se há lesão e se o fundo não-preto é maior que o limiar\n",
    "    if np.any(image == 1) and non_black_ratio >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_patient_data(folder, patient_id):\n",
    "    \"\"\"\n",
    "    Carrega os dados de um único paciente (imagens, máscaras e labels) de um diretório.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Caminho da pasta contendo os dados dos pacientes.\n",
    "        patient_id (str): ID do paciente a ser carregado.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dados do paciente, incluindo imagens, máscaras e labels para os lados esquerdo e direito.\n",
    "              Retorna None se o paciente não for encontrado.\n",
    "    \"\"\"\n",
    "    patient_path = os.path.join(folder, patient_id)\n",
    "    if not os.path.exists(patient_path):\n",
    "        print(f\"Paciente {patient_id} não encontrado na pasta {folder}.\")\n",
    "        return None\n",
    "\n",
    "    # Inicializa estruturas para armazenar os dados do paciente\n",
    "    patient_data = {\n",
    "        \"images_left\": [],\n",
    "        \"images_right\": [],\n",
    "        \"mask_left\": [],\n",
    "        \"mask_right\": [],\n",
    "        \"labels_left\": [],\n",
    "        \"labels_right\": [],\n",
    "    }\n",
    "\n",
    "    areas_image = [\"left\", \"right\"]\n",
    "    areas_mask = [\"lesion_left\", \"lesion_right\"]\n",
    "    path_left = os.path.join(patient_path, areas_image[0])\n",
    "    path_right = os.path.join(patient_path, areas_image[1])\n",
    "    lesion_path_left = os.path.join(patient_path, areas_mask[0])\n",
    "    lesion_path_right = os.path.join(patient_path, areas_mask[1])\n",
    "\n",
    "    # Verifica se os diretórios existem\n",
    "    if not os.path.exists(path_left) or not os.path.exists(path_right) or \\\n",
    "       not os.path.exists(lesion_path_left) or not os.path.exists(lesion_path_right):\n",
    "        print(f\"Estrutura de diretórios inválida para o paciente {patient_id}.\")\n",
    "        return None, None\n",
    "\n",
    "    # Carrega as imagens e máscaras do lado esquerdo e direito\n",
    "    for patch_id_left, mask_id_left, patch_id_right, mask_id_right in zip(\n",
    "        os.listdir(path_left), os.listdir(lesion_path_left),\n",
    "        os.listdir(path_right), os.listdir(lesion_path_right)\n",
    "    ):\n",
    "        img_path_left = os.path.join(path_left, patch_id_left)\n",
    "        mask_path_left = os.path.join(lesion_path_left, mask_id_left)\n",
    "        img_path_right = os.path.join(path_right, patch_id_right)\n",
    "        mask_path_right = os.path.join(lesion_path_right, mask_id_right)\n",
    "\n",
    "        for img_left, msk_left, img_right, msk_right in zip(\n",
    "            os.listdir(img_path_left), os.listdir(mask_path_left),\n",
    "            os.listdir(img_path_right), os.listdir(mask_path_right)\n",
    "        ):\n",
    "            # Carrega os dados do lado esquerdo\n",
    "            data_left = nib.load(os.path.join(img_path_left, img_left)).get_fdata()\n",
    "            data_msk_left = nib.load(os.path.join(mask_path_left, msk_left)).get_fdata()\n",
    "            if len(data_left) > 0 or len(data_msk_left) > 0:\n",
    "                patient_data[\"images_left\"].append(data_left)\n",
    "                patient_data[\"mask_left\"].append(data_msk_left)\n",
    "                patient_data[\"labels_left\"].append(calculate_label(data_msk_left))\n",
    "\n",
    "            # Carrega os dados do lado direito\n",
    "            data_right = nib.load(os.path.join(img_path_right, img_right)).get_fdata()\n",
    "            data_msk_right = nib.load(os.path.join(mask_path_right, msk_right)).get_fdata()\n",
    "            if len(data_right) > 0 or len(data_msk_right) > 0:\n",
    "                patient_data[\"images_right\"].append(np.fliplr(data_right))\n",
    "                patient_data[\"mask_right\"].append(np.fliplr(data_msk_right))\n",
    "                patient_data[\"labels_right\"].append(calculate_label(data_msk_right))\n",
    "\n",
    "    # Gera os pares de labels\n",
    "    labels_pair = []\n",
    "    for label_left, label_right in zip(patient_data[\"labels_left\"], patient_data[\"labels_right\"]):\n",
    "        if label_left == 0 and label_right == 0:\n",
    "            labels_pair.append(0)\n",
    "        else:\n",
    "            labels_pair.append(1)\n",
    "    patient_data[\"labels_pair\"] = labels_pair\n",
    "\n",
    "    print(f\"Paciente {patient_id} carregado com sucesso.\")\n",
    "    print(f\"Total de recortes: {len(labels_pair)}\")\n",
    "    return patient_data, labels_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar entre 0 e 1\n",
    "def normalize_minmax(image_data): \n",
    "    min_val = np.min(image_data)\n",
    "    max_val = np.max(image_data)\n",
    "    normalized_data = (image_data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def augment_image(img_left, img_right, mask_left, mask_right):\n",
    "    \"\"\"\n",
    "    Gera 7 variações (exceto a imagem original) aplicando:\n",
    "    - rotação 180°\n",
    "    - flip vertical\n",
    "    - troca de lado\n",
    "    \"\"\"\n",
    "\n",
    "    def rotate_180(img): return ndi.rotate(img, 180, reshape=False, mode='nearest')\n",
    "    def flip_vertical(img): return np.fliplr(img)\n",
    "\n",
    "    results_left = []\n",
    "    masks_left = []\n",
    "    results_right = []\n",
    "    masks_right = []\n",
    "    \n",
    "    # Todas as combinações possíveis, exceto a (False, False, False)\n",
    "    for rotate in [False, True]:\n",
    "        for flip in [False, True]:\n",
    "            for swap in [False, True]:\n",
    "                if not (rotate or flip or swap):  # pula a imagem padrão\n",
    "                    continue\n",
    "\n",
    "                l_img = img_left.copy()\n",
    "                r_img = img_right.copy()\n",
    "                l_mask = mask_left.copy()\n",
    "                r_mask = mask_right.copy()\n",
    "\n",
    "                if rotate:\n",
    "                    l_img = rotate_180(l_img)\n",
    "                    r_img = rotate_180(r_img)\n",
    "                    l_mask = rotate_180(l_mask)\n",
    "                    r_mask = rotate_180(r_mask)\n",
    "\n",
    "                if flip:\n",
    "                    l_img = flip_vertical(l_img)\n",
    "                    r_img = flip_vertical(r_img)\n",
    "                    l_mask = flip_vertical(l_mask)\n",
    "                    r_mask = flip_vertical(r_mask)\n",
    "\n",
    "                if swap:\n",
    "                    l_img, r_img = r_img, l_img\n",
    "                    l_mask, r_mask = r_mask, l_mask\n",
    "\n",
    "                results_left.append(l_img)\n",
    "                masks_left.append(l_mask)\n",
    "                results_right.append(r_img)\n",
    "                masks_right.append(r_mask)\n",
    "\n",
    "    return results_left, results_right, masks_left, masks_right\n",
    "\n",
    "def augment_single_image(img_left, img_right, mask_left, mask_right, rng):\n",
    "    \"\"\"\n",
    "    Aplica uma única modificação aleatória entre:\n",
    "    - rotação 180°\n",
    "    - flip vertical\n",
    "    - troca de lado\n",
    "    - combinações entre elas\n",
    "    (7 variações possíveis)\n",
    "    \"\"\"\n",
    "\n",
    "    def rotate_180(img): return ndi.rotate(img, 180, reshape=False, mode='nearest')\n",
    "    def flip_vertical(img): return np.fliplr(img)\n",
    "\n",
    "    # Lista de todas combinações possíveis (sem a identidade)\n",
    "    transformations = [\n",
    "        (True, False, False),   # só rotate\n",
    "        (False, True, False),   # só flip\n",
    "        (False, False, True),   # só swap\n",
    "        (True, True, False),    # rotate + flip\n",
    "        (True, False, True),    # rotate + swap\n",
    "        (False, True, True),    # flip + swap\n",
    "        (True, True, True)      # rotate + flip + swap\n",
    "    ]\n",
    "\n",
    "    # Escolhe aleatoriamente uma transformação\n",
    "    rotate, flip, swap = rng.choice(transformations)\n",
    "\n",
    "    l_img = img_left.copy()\n",
    "    r_img = img_right.copy()\n",
    "    l_mask = mask_left.copy()\n",
    "    r_mask = mask_right.copy()\n",
    "\n",
    "    if rotate:\n",
    "        l_img = rotate_180(l_img)\n",
    "        r_img = rotate_180(r_img)\n",
    "        l_mask = rotate_180(l_mask)\n",
    "        r_mask = rotate_180(r_mask)\n",
    "\n",
    "    if flip:\n",
    "        l_img = flip_vertical(l_img)\n",
    "        r_img = flip_vertical(r_img)\n",
    "        l_mask = flip_vertical(l_mask)\n",
    "        r_mask = flip_vertical(r_mask)\n",
    "\n",
    "    if swap:\n",
    "        l_img, r_img = r_img, l_img\n",
    "        l_mask, r_mask = r_mask, l_mask\n",
    "\n",
    "    return l_img, r_img, l_mask, r_mask\n",
    "\n",
    "# Função para filtrar as imagens por paciente\n",
    "def select_by_patients(patients, all_images_original, all_images_opposite, all_labels):\n",
    "    selected_images_original = {}\n",
    "    selected_images_opposite = {}\n",
    "    selected_labels = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        selected_images_original[patient] = []\n",
    "        selected_images_opposite[patient] = []\n",
    "        if patient in all_images_original and patient in all_images_opposite:\n",
    "            selected_images_original[patient].extend(all_images_original[patient])\n",
    "            selected_images_opposite[patient].extend(all_images_opposite[patient])\n",
    "            selected_labels.extend(all_labels[patient])\n",
    "        else:\n",
    "            print(f\"Paciente {patient} não encontrado em uma das listas de imagens.\")\n",
    "    \n",
    "    return selected_images_original, selected_images_opposite, selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados para treino e validação\n",
    "def prepare_data_for_training(images_left, images_right, labels_pair, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_left = {}\n",
    "    balanced_images_right = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_left = {}\n",
    "    balanced_mask_right = {}\n",
    "    balanced_index_patients = {}\n",
    "\n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    train_patients = ['sub-02A13', 'sub-03C08', 'sub-06C09', 'sub-14F04', 'sub-16E03', 'sub-16G09', 'sub-16I12', 'sub-19F09', 'sub-19G04', 'sub-22F14', 'sub-26B09', 'sub-31F07', 'sub-35E12', 'sub-36K02', 'sub-41D08', 'sub-51C05', 'sub-52K04', 'sub-57D04', 'sub-59G00', 'sub-60G13', 'sub-60K04', 'sub-71C07', 'sub-72I02', 'sub-72K02', 'sub-76E02', 'sub-76J09', 'sub-83K08', 'sub-85I05', 'sub-86B13']\n",
    "    valid_patients = ['sub-00H10', 'sub-25B08', 'sub-29D03', 'sub-34J06', 'sub-56E13', 'sub-59E09', 'sub-60G06', 'sub-79H07']\n",
    "    test_patients = ['sub-42B05', 'sub-42K06', 'sub-44H05', 'sub-86G08']\n",
    "\n",
    "    # patients = list(set(images_left.keys()))\n",
    "    # train_patients, valtest_patients = train_test_split(patients, train_size = train_size+0.01)\n",
    "    # valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "    \n",
    "    print(len(train_patients) + len(valid_patients) + len(test_patients))\n",
    "    \n",
    "    class_1_left = {}\n",
    "    class_0_left = {}\n",
    "    class_1_right = {}\n",
    "    class_0_right = {}\n",
    "    class_1_mask_left = {}\n",
    "    class_0_mask_left = {}\n",
    "    class_1_mask_right = {}\n",
    "    class_0_mask_right = {}\n",
    "    class_1_coordinates = {}\n",
    "    class_0_coordinates = {}\n",
    "\n",
    "    for patient_id in images_left:\n",
    "        class_1_labels = []\n",
    "        class_0_labels = []\n",
    "        class_1_left[patient_id] = []\n",
    "        class_0_left[patient_id] = []\n",
    "        class_1_right[patient_id] = []\n",
    "        class_0_right[patient_id] = []\n",
    "        class_1_mask_left[patient_id] = []\n",
    "        class_0_mask_left[patient_id] = []\n",
    "        class_1_mask_right[patient_id] = []\n",
    "        class_0_mask_right[patient_id] = []\n",
    "        class_1_coordinates[patient_id] = []\n",
    "        class_0_coordinates[patient_id] = []\n",
    "        index = 0\n",
    "        seed = hash(patient_id) % (2**32)  # Gera uma seed única por paciente\n",
    "        rng = np.random.default_rng(seed)\n",
    "        \n",
    "        if len(labels_pair[patient_id]) == 0:\n",
    "            continue\n",
    "        \n",
    "        if patient_id in test_patients:\n",
    "            balanced_images_left[patient_id] = images_left[patient_id]\n",
    "            balanced_images_right[patient_id] = images_right[patient_id]\n",
    "            balanced_labels[patient_id] = labels_pair[patient_id]\n",
    "            balanced_mask_left[patient_id] = mask_left[patient_id]\n",
    "            balanced_mask_right[patient_id] = mask_right[patient_id]\n",
    "            continue\n",
    "        \n",
    "        # Iterar sobre os patches e dividir as classes 0 e 1 com base nas labels\n",
    "        for label in labels_pair[patient_id]:\n",
    "            image_left = (images_left[patient_id])[index]\n",
    "            image_right = (images_right[patient_id])[index]\n",
    "            mask_image_left = (mask_left[patient_id])[index]\n",
    "            mask_image_right = (mask_right[patient_id])[index]\n",
    "            index += 1\n",
    "            \n",
    "            if label == 1:\n",
    "                class_1_labels.append(label)\n",
    "                class_1_left[patient_id].append(image_left)\n",
    "                class_1_right[patient_id].append(image_right)\n",
    "                class_1_mask_left[patient_id].append(mask_image_left)\n",
    "                class_1_mask_right[patient_id].append(mask_image_right)\n",
    "            else:\n",
    "                class_0_labels.append(label)\n",
    "                class_0_left[patient_id].append(image_left)\n",
    "                class_0_right[patient_id].append(image_right)\n",
    "                class_0_mask_left[patient_id].append(mask_image_left)\n",
    "                class_0_mask_right[patient_id].append(mask_image_right)\n",
    "        \n",
    "        class_1_count = len(class_1_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com label 1: {class_1_count}\")\n",
    "        class_0_count = len(class_0_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com label 0: {class_0_count}\")\n",
    "\n",
    "        # Fazer Uppersampling da classe minoritária (label 1) para igualar ao número de exemplos da classe 0\n",
    "        print(f\"Paciente {patient_id}: Total de patches classe 1 antes do uppersampling: {class_1_count}\")\n",
    "        \n",
    "        # Se a classe 1 for menor, aplicamos data augmentation\n",
    "        if class_1_count < class_0_count:\n",
    "            augmented_images_left = []\n",
    "            augmented_images_right = []\n",
    "            augmented_masks_left = []\n",
    "            augmented_masks_right = []\n",
    "\n",
    "            for idx, elem in enumerate(class_1_left[patient_id]):\n",
    "                imgs_left_aug, imgs_right_aug, masks_left_aug, masks_right_aug = augment_image(class_0_left[patient_id][idx], class_0_right[patient_id][idx], class_0_mask_left[patient_id][idx], class_0_mask_right[patient_id][idx])\n",
    "            \n",
    "                augmented_images_left.extend(imgs_left_aug)\n",
    "                augmented_images_right.extend(imgs_right_aug)\n",
    "                augmented_masks_left.extend(masks_left_aug)\n",
    "                augmented_masks_right.extend(masks_right_aug)\n",
    "\n",
    "            # Adiciona os dados aumentados\n",
    "            class_1_left[patient_id].extend(augmented_images_left)\n",
    "            class_1_right[patient_id].extend(augmented_images_right)\n",
    "            class_1_mask_left[patient_id].extend(augmented_masks_left)\n",
    "            class_1_mask_right[patient_id].extend(augmented_masks_right)\n",
    "            class_1_labels.extend([1] * (class_1_count*7))\n",
    "            \n",
    "        class_1_count = len(class_1_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de patches classe 1 depois do uppersampling: {class_1_count}\")\n",
    "        \n",
    "        augmented_class_0_left = []\n",
    "        augmented_class_0_right = []\n",
    "        augmented_class_0_mask_left = []\n",
    "        augmented_class_0_mask_right = []\n",
    "\n",
    "        i=0\n",
    "        for img_left, img_right, mask_l, mask_r in zip(class_0_left[patient_id], class_0_right[patient_id], class_0_mask_left[patient_id], class_0_mask_right[patient_id]):\n",
    "            # Decide aleatoriamente se vai aplicar augmentação\n",
    "            seed = (hash(patient_id)+i) % (2**32)  # Gera uma seed única por paciente\n",
    "            rng2 = np.random.default_rng(seed)\n",
    "            if rng2.choice(2, 1, replace=False) < 1:\n",
    "                aug_l, aug_r, aug_mask_l, aug_mask_r = augment_single_image(img_left, img_right, mask_l, mask_r, rng)\n",
    "                augmented_class_0_left.append(aug_l)\n",
    "                augmented_class_0_right.append(aug_r)\n",
    "                augmented_class_0_mask_left.append(aug_mask_l)\n",
    "                augmented_class_0_mask_right.append(aug_mask_r)\n",
    "            else:\n",
    "                # Mantém a original\n",
    "                augmented_class_0_left.append(img_left)\n",
    "                augmented_class_0_right.append(img_right)\n",
    "                augmented_class_0_mask_left.append(mask_l)\n",
    "                augmented_class_0_mask_right.append(mask_r)\n",
    "            i+=1\n",
    "\n",
    "        # Atualiza as listas da classe 0 com as versões modificadas\n",
    "        class_0_left[patient_id] = augmented_class_0_left\n",
    "        class_0_right[patient_id] = augmented_class_0_right\n",
    "        class_0_mask_left[patient_id] = augmented_class_0_mask_left\n",
    "        class_0_mask_right[patient_id] = augmented_class_0_mask_right\n",
    "        \n",
    "        # Fazer undersampling aleatório da classe majoritária (label 0) para igualar ao número de exemplos da classe 1\n",
    "        class_0_count = len(class_0_labels)\n",
    "        if class_0_count > class_1_count:\n",
    "            sampled_indices = rng.choice(len(class_0_left[patient_id]), class_1_count, replace=False)\n",
    "            sampled_class_0_slices_left = [class_0_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_slices_right = [class_0_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_original_modified = {}\n",
    "            class_0_original_modified[patient_id] = []\n",
    "            class_0_opposite_modified = {}\n",
    "            class_0_opposite_modified[patient_id] = []\n",
    "            sampled_class_0_mask_left = [class_0_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_mask_right = [class_0_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_mask_original_modified = {}\n",
    "            class_0_mask_original_modified[patient_id] = []\n",
    "            class_0_mask_opposite_modified = {}\n",
    "            class_0_mask_opposite_modified[patient_id] = []\n",
    "            \n",
    "            for left_image, left_mask in zip(sampled_class_0_slices_left, sampled_class_0_mask_left):\n",
    "                class_0_original_modified[patient_id].append(left_image)\n",
    "                class_0_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_0_slices_right, sampled_class_0_mask_right):\n",
    "                class_0_opposite_modified[patient_id].append(right_image)\n",
    "                class_0_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_0_left = class_0_original_modified\n",
    "            class_0_right = class_0_opposite_modified\n",
    "            class_0_mask_left = class_0_mask_original_modified\n",
    "            class_0_mask_right = class_0_mask_opposite_modified\n",
    "            class_0_labels = [0] * (class_1_count)\n",
    "        else:\n",
    "            sampled_indices = rng.choice(len(class_1_left[patient_id]), class_0_count, replace=False)\n",
    "            sampled_class_1_slices_left = [class_1_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_1_slices_right = [class_1_right[patient_id][i] for i in sampled_indices]\n",
    "            class_1_original_modified = {}\n",
    "            class_1_original_modified[patient_id] = []\n",
    "            class_1_opposite_modified = {}\n",
    "            class_1_opposite_modified[patient_id] = []\n",
    "            sampled_class_1_mask_left = [class_1_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_1_mask_right = [class_1_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_1_mask_original_modified = {}\n",
    "            class_1_mask_original_modified[patient_id] = []\n",
    "            class_1_mask_opposite_modified = {}\n",
    "            class_1_mask_opposite_modified[patient_id] = []\n",
    "\n",
    "            for left_image, left_mask in zip(sampled_class_1_slices_left, sampled_class_1_mask_left):\n",
    "                class_1_original_modified[patient_id].append(left_image)\n",
    "                class_1_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_1_slices_right, sampled_class_1_mask_right):\n",
    "                class_1_opposite_modified[patient_id].append(right_image)\n",
    "                class_1_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_1_left = class_1_original_modified\n",
    "            class_1_right = class_1_opposite_modified\n",
    "            class_1_mask_left = class_1_mask_original_modified\n",
    "            class_1_mask_right = class_1_mask_opposite_modified\n",
    "            class_1_labels = [1] * (class_0_count)\n",
    "        \n",
    "        print(len(class_1_left[patient_id]))\n",
    "        print(len(class_1_right[patient_id]))\n",
    "        print(len(class_1_labels))\n",
    "        \n",
    "        balanced_images_left[patient_id] = class_1_left[patient_id][:] + class_0_left[patient_id][:]\n",
    "        balanced_images_right[patient_id] = class_1_right[patient_id][:] + class_0_right[patient_id][:]\n",
    "        balanced_labels[patient_id] = class_1_labels + class_0_labels\n",
    "        balanced_mask_left[patient_id] = class_1_mask_left[patient_id][:] + class_0_mask_left[patient_id][:]\n",
    "        balanced_mask_right[patient_id] = class_1_mask_right[patient_id][:] + class_0_mask_right[patient_id][:]\n",
    "        \n",
    "        balanced_index = rng.choice(range(len(balanced_labels[patient_id])), len(balanced_labels[patient_id]), replace=False)            \n",
    "        balanced_images_left[patient_id] = [balanced_images_left[patient_id][i] for i in balanced_index]\n",
    "        balanced_images_right[patient_id] = [balanced_images_right[patient_id][i] for i in balanced_index]\n",
    "        balanced_labels[patient_id] = [balanced_labels[patient_id][i] for i in balanced_index]\n",
    "        balanced_mask_left[patient_id] = [balanced_mask_left[patient_id][i] for i in balanced_index]\n",
    "        balanced_mask_right[patient_id] = [balanced_mask_right[patient_id][i] for i in balanced_index]\n",
    "        balanced_index_patients[patient_id] = balanced_index\n",
    "        \n",
    "        class_1_count = len(class_1_labels)\n",
    "        class_0_count = len(class_0_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de patches no final: {class_1_count+class_0_count}\")\n",
    "\n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    \n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, X_test_original, X_test_opposite, np.array(y_train), np.array(y_val), np.array(y_test), train_patients, valid_patients, test_patients, balanced_mask_left, balanced_mask_right, balanced_index_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados para treino e validação pareados\n",
    "def prepare_data_aligned(images_left, images_right, labels_pair, mask_left, mask_right):\n",
    "    import numpy as np\n",
    "\n",
    "    patients = list(images_left.keys())\n",
    "\n",
    "    train_patients_split = ['sub-02A13', 'sub-03C08', 'sub-06C09', 'sub-14F04', 'sub-16E03', 'sub-16G09', 'sub-16I12', 'sub-19F09', 'sub-19G04', 'sub-22F14', 'sub-26B09', 'sub-31F07', 'sub-35E12', 'sub-36K02', 'sub-41D08', 'sub-51C05', 'sub-52K04', 'sub-57D04', 'sub-59G00', 'sub-60G13', 'sub-60K04', 'sub-71C07', 'sub-72I02', 'sub-72K02', 'sub-76E02', 'sub-76J09', 'sub-83K08', 'sub-85I05', 'sub-86B13']\n",
    "    val_patients_split = ['sub-00H10', 'sub-25B08', 'sub-29D03', 'sub-34J06', 'sub-56E13', 'sub-59E09', 'sub-60G06', 'sub-79H07']\n",
    "    test_patients_split = ['sub-42B05', 'sub-42K06', 'sub-44H05', 'sub-86G08']\n",
    "\n",
    "\n",
    "    patches_per_patient = {}\n",
    "    for patient in patients:\n",
    "        patches_per_patient[patient] = []\n",
    "        for idx, label in enumerate(labels_pair[patient]):\n",
    "            patch_info = {\n",
    "                'index': idx,\n",
    "                'image_left': images_left[patient][idx],\n",
    "                'image_right': images_right[patient][idx],\n",
    "                'mask_left': mask_left[patient][idx],\n",
    "                'mask_right': mask_right[patient][idx],\n",
    "                'label': label\n",
    "            }\n",
    "            patches_per_patient[patient].append(patch_info)\n",
    "\n",
    "    paired_displasia = []\n",
    "    paired_saudavel = []\n",
    "\n",
    "    patient_ids = sorted(patients)\n",
    "    for i in test_patients_split:\n",
    "        if i in patient_ids:\n",
    "            patient_ids.remove(i)\n",
    "\n",
    "    for patient in test_patients_split:\n",
    "        for patch in patches_per_patient[patient]:\n",
    "            if patch['label'] == 1:\n",
    "                paired_displasia.append((patient, patch))\n",
    "            else:\n",
    "                paired_saudavel.append((patient, patch))\n",
    "\n",
    "    for i in range(len(patient_ids) - 1):\n",
    "        patient_current = patient_ids[i]\n",
    "        patient_next = patient_ids[i + 1]\n",
    "\n",
    "        patches_current = patches_per_patient[patient_current]\n",
    "        patches_next = patches_per_patient[patient_next]\n",
    "\n",
    "        displasia_indices = [p['index'] for p in patches_current if p['label'] == 1]\n",
    "\n",
    "        if not displasia_indices:\n",
    "            print(f\"Paciente {patient_current} sem regiões de displasia.\")\n",
    "            continue\n",
    "\n",
    "        min_idx = min(displasia_indices)\n",
    "        max_idx = max(displasia_indices)\n",
    "\n",
    "        print(f\"Paciente {patient_current} displasia de {min_idx} a {max_idx}.\")\n",
    "\n",
    "        for idx in range(min_idx, max_idx + 1):\n",
    "            if idx < len(patches_current) and patches_current[idx]['label'] == 1:\n",
    "                paired_displasia.append((patient_current, patches_current[idx]))\n",
    "\n",
    "        valid_saudavel = True\n",
    "        for idx in range(min_idx, max_idx + 1):\n",
    "            if idx >= len(patches_next) or patches_next[idx]['label'] == 1:\n",
    "                valid_saudavel = False\n",
    "                break\n",
    "\n",
    "        if valid_saudavel:\n",
    "            for idx in range(min_idx, max_idx + 1):\n",
    "                paired_saudavel.append((patient_next, patches_next[idx]))\n",
    "        else:\n",
    "            print(f\"Conflito de indices no paciente {patient_next}, randomizando saudáveis.\")\n",
    "            saudaveis = [p for p in patches_next if p['label'] == 0]\n",
    "            rng = np.random.default_rng(hash(patient_current + patient_next) % (2 ** 32))\n",
    "            selected = rng.choice(saudaveis, size=(max_idx - min_idx + 1), replace=True)\n",
    "            for s in selected:\n",
    "                paired_saudavel.append((patient_next, s))\n",
    "\n",
    "    all_data = paired_displasia + paired_saudavel\n",
    "\n",
    "    data_by_patient = {}\n",
    "    for patient, patch in all_data:\n",
    "        if patient not in data_by_patient:\n",
    "            data_by_patient[patient] = []\n",
    "        data_by_patient[patient].append(patch)\n",
    "\n",
    "    selected_indices_by_patient = {}\n",
    "\n",
    "    def collect_data(patient_split, boolean):\n",
    "        X_left, X_right, y = [], [], []\n",
    "        M_left, M_right = [], []\n",
    "\n",
    "        patch_metadata = []  # vai guardar (paciente, idx_original) para mapear depois\n",
    "\n",
    "        for patient in patient_split:\n",
    "            for patch in data_by_patient.get(patient, []):\n",
    "                X_left.append(patch['image_left'])\n",
    "                X_right.append(patch['image_right'])\n",
    "                M_left.append(patch['mask_left'])\n",
    "                M_right.append(patch['mask_right'])\n",
    "                y.append(patch['label'])\n",
    "                patch_metadata.append((patient, patch['index']))\n",
    "\n",
    "        if boolean:\n",
    "            rng = np.random.default_rng(42)\n",
    "            indices_class_1 = [i for i, label in enumerate(y) if label == 1]\n",
    "            indices_class_0 = [i for i, label in enumerate(y) if label == 0]\n",
    "\n",
    "            min_class = min(len(indices_class_1), len(indices_class_0))\n",
    "            selected_indices_class_1 = rng.choice(indices_class_1, min_class, replace=False)\n",
    "            selected_indices_class_0 = rng.choice(indices_class_0, min_class, replace=False)\n",
    "\n",
    "            selected_indices = np.concatenate((selected_indices_class_1, selected_indices_class_0))\n",
    "            rng.shuffle(selected_indices)\n",
    "\n",
    "            X_left = [X_left[i] for i in selected_indices]\n",
    "            X_right = [X_right[i] for i in selected_indices]\n",
    "            M_left = [M_left[i] for i in selected_indices]\n",
    "            M_right = [M_right[i] for i in selected_indices]\n",
    "            y = [y[i] for i in selected_indices]\n",
    "            patch_metadata = [patch_metadata[i] for i in selected_indices]\n",
    "\n",
    "        # Reconstruir o dicionário de índices por paciente\n",
    "        local_selected = {}\n",
    "        for i, (patient, idx_original) in enumerate(patch_metadata):\n",
    "            if patient not in local_selected:\n",
    "                local_selected[patient] = []\n",
    "            local_selected[patient].append(i)  # i é o índice final (em X_left, y, etc.)\n",
    "\n",
    "        return X_left, X_right, M_left, M_right, y, local_selected\n",
    "\n",
    "\n",
    "    X_train_original, X_train_opposite, M_train_left, M_train_right, y_train, train_selected = collect_data(train_patients_split, True)\n",
    "    X_val_original, X_val_opposite, M_val_left, M_val_right, y_val, val_selected = collect_data(val_patients_split, True)\n",
    "    X_test_original, X_test_opposite, M_test_left, M_test_right, y_test, test_selected = collect_data(test_patients_split, False)\n",
    "\n",
    "    selected_indices_by_patient = {\n",
    "        'train': train_selected,\n",
    "        'val': val_selected,\n",
    "        'test': test_selected\n",
    "    }\n",
    "\n",
    "    print(f\"Total de pares de recortes no treino com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com label 0: {y_test.count(0)}\")\n",
    "\n",
    "    return (\n",
    "        np.array(X_train_original), np.array(X_train_opposite),\n",
    "        np.array(X_val_original), np.array(X_val_opposite),\n",
    "        np.array(X_test_original), np.array(X_test_opposite),\n",
    "        np.array(y_train), np.array(y_val), np.array(y_test),\n",
    "        train_patients_split, val_patients_split, test_patients_split,\n",
    "        np.array(M_train_left), np.array(M_train_right),\n",
    "        np.array(M_val_left), np.array(M_val_right),\n",
    "        np.array(M_test_left), np.array(M_test_right),\n",
    "        selected_indices_by_patient\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir o modelo CNN 2D\n",
    "def build_cnn_model_backup():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(8, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(16, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.3)) \n",
    "     \n",
    "    model.add(layers.Conv2D(32, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir a rede siamesa\n",
    "def build_siamese_model(input_shape):\n",
    "    input_original = Input(shape=input_shape)\n",
    "    input_opposite = Input(shape=input_shape)\n",
    "\n",
    "    # Criar a CNN base compartilhada\n",
    "    cnn_base = build_cnn_model_backup()\n",
    "    \n",
    "    # Aplicar a mesma CNN base para ambas as entradas\n",
    "    output_original = cnn_base(input_original)\n",
    "    output_opposite = cnn_base(input_opposite)\n",
    "\n",
    "    # Calcula a diferença absoluta\n",
    "    # l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([output_original, output_opposite])\n",
    "\n",
    "    # Subtrair as duas saídas (Lado esquerdo - Contra-lateral)\n",
    "    subtracted = layers.Subtract()([output_original, output_opposite])\n",
    "    subtracted = layers.BatchNormalization()(subtracted)\n",
    "\n",
    "    # Concatenar as duas saídas (Lado esquerdo + Contra-lateral)\n",
    "    # concatenated = layers.Concatenate()([output_original, output_opposite])\n",
    "    # concatenated = layers.BatchNormalization()(concatenated)\n",
    "    \n",
    "    # Passar o resultado pela rede densa\n",
    "    subtracted = layers.Dense(64, activation='relu')(subtracted)\n",
    "    subtracted = layers.Dropout(0.3)(subtracted)\n",
    "    subtracted = layers.Dense(32, activation='relu')(subtracted)\n",
    "    subtracted = layers.Dropout(0.3)(subtracted)\n",
    "\n",
    "    output = layers.Dense(1, activation='sigmoid')(subtracted)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_original, input_opposite], outputs=output)\n",
    "    siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', metrics.Precision(name=\"precision\"), metrics.Recall(name=\"recall\")])\n",
    "\n",
    "    return siamese_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot do treinamento do modelo\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot da matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rodando função de Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modalidade de imagem: T1\n",
      "Paciente sub-00H10 carregado com sucesso.\n",
      "Total de recortes: 1105\n",
      "Paciente sub-02A13 carregado com sucesso.\n",
      "Total de recortes: 1082\n",
      "Paciente sub-06C09 carregado com sucesso.\n",
      "Total de recortes: 1101\n",
      "Paciente sub-14F04 carregado com sucesso.\n",
      "Total de recortes: 1169\n",
      "Paciente sub-16E03 carregado com sucesso.\n",
      "Total de recortes: 1223\n",
      "Paciente sub-16G09 carregado com sucesso.\n",
      "Total de recortes: 1118\n",
      "Paciente sub-16I12 carregado com sucesso.\n",
      "Total de recortes: 1206\n",
      "Paciente sub-19F09 carregado com sucesso.\n",
      "Total de recortes: 1196\n",
      "Paciente sub-19G04 carregado com sucesso.\n",
      "Total de recortes: 1128\n",
      "Paciente sub-26B09 carregado com sucesso.\n",
      "Total de recortes: 1171\n",
      "Paciente sub-29D03 carregado com sucesso.\n",
      "Total de recortes: 1102\n",
      "Paciente sub-31F07 carregado com sucesso.\n",
      "Total de recortes: 1102\n",
      "Paciente sub-35E12 carregado com sucesso.\n",
      "Total de recortes: 1130\n",
      "Paciente sub-36K02 carregado com sucesso.\n",
      "Total de recortes: 1154\n",
      "Paciente sub-41D08 carregado com sucesso.\n",
      "Total de recortes: 1088\n",
      "Paciente sub-42K06 carregado com sucesso.\n",
      "Total de recortes: 1052\n",
      "Paciente sub-44H05 carregado com sucesso.\n",
      "Total de recortes: 1197\n",
      "Paciente sub-51C05 carregado com sucesso.\n",
      "Total de recortes: 1224\n",
      "Paciente sub-52K04 carregado com sucesso.\n",
      "Total de recortes: 1145\n",
      "Paciente sub-56E13 carregado com sucesso.\n",
      "Total de recortes: 1097\n",
      "Paciente sub-59G00 carregado com sucesso.\n",
      "Total de recortes: 1051\n",
      "Paciente sub-60G06 carregado com sucesso.\n",
      "Total de recortes: 1183\n",
      "Paciente sub-60G13 carregado com sucesso.\n",
      "Total de recortes: 1135\n",
      "Paciente sub-60K04 carregado com sucesso.\n",
      "Total de recortes: 1054\n",
      "Paciente sub-71C07 carregado com sucesso.\n",
      "Total de recortes: 1032\n",
      "Paciente sub-72I02 carregado com sucesso.\n",
      "Total de recortes: 1218\n",
      "Paciente sub-72K02 carregado com sucesso.\n",
      "Total de recortes: 1183\n",
      "Paciente sub-76E02 carregado com sucesso.\n",
      "Total de recortes: 1275\n",
      "Paciente sub-76J09 carregado com sucesso.\n",
      "Total de recortes: 1023\n",
      "Paciente sub-83K08 carregado com sucesso.\n",
      "Total de recortes: 1097\n",
      "Paciente sub-85I05 carregado com sucesso.\n",
      "Total de recortes: 1211\n",
      "Paciente sub-86B13 carregado com sucesso.\n",
      "Total de recortes: 1095\n",
      "\n",
      "\n",
      "Modalidade de imagem: Flair\n",
      "Paciente sub-00H10 carregado com sucesso.\n",
      "Total de recortes: 1092\n",
      "Paciente sub-02A13 carregado com sucesso.\n",
      "Total de recortes: 1062\n",
      "Paciente sub-06C09 carregado com sucesso.\n",
      "Total de recortes: 1133\n",
      "Paciente sub-14F04 carregado com sucesso.\n",
      "Total de recortes: 1154\n",
      "Paciente sub-16E03 carregado com sucesso.\n",
      "Total de recortes: 1024\n",
      "Paciente sub-16G09 carregado com sucesso.\n",
      "Total de recortes: 1125\n",
      "Paciente sub-16I12 carregado com sucesso.\n",
      "Total de recortes: 1210\n",
      "Paciente sub-19F09 carregado com sucesso.\n",
      "Total de recortes: 1219\n",
      "Paciente sub-19G04 carregado com sucesso.\n",
      "Total de recortes: 1132\n",
      "Paciente sub-26B09 carregado com sucesso.\n",
      "Total de recortes: 1160\n",
      "Paciente sub-29D03 carregado com sucesso.\n",
      "Total de recortes: 1110\n",
      "Paciente sub-31F07 carregado com sucesso.\n",
      "Total de recortes: 1143\n",
      "Paciente sub-35E12 carregado com sucesso.\n",
      "Total de recortes: 1047\n",
      "Paciente sub-36K02 carregado com sucesso.\n",
      "Total de recortes: 1010\n",
      "Paciente sub-41D08 carregado com sucesso.\n",
      "Total de recortes: 1036\n",
      "Paciente sub-42K06 carregado com sucesso.\n",
      "Total de recortes: 923\n",
      "Paciente sub-44H05 carregado com sucesso.\n",
      "Total de recortes: 1105\n",
      "Paciente sub-51C05 carregado com sucesso.\n",
      "Total de recortes: 1042\n",
      "Paciente sub-52K04 carregado com sucesso.\n",
      "Total de recortes: 1019\n",
      "Paciente sub-56E13 carregado com sucesso.\n",
      "Total de recortes: 1080\n",
      "Paciente sub-59G00 carregado com sucesso.\n",
      "Total de recortes: 1041\n",
      "Paciente sub-60G06 carregado com sucesso.\n",
      "Total de recortes: 1062\n",
      "Paciente sub-60G13 carregado com sucesso.\n",
      "Total de recortes: 1100\n",
      "Paciente sub-60K04 carregado com sucesso.\n",
      "Total de recortes: 1033\n",
      "Paciente sub-71C07 carregado com sucesso.\n",
      "Total de recortes: 1068\n",
      "Paciente sub-72I02 carregado com sucesso.\n",
      "Total de recortes: 1065\n",
      "Paciente sub-72K02 carregado com sucesso.\n",
      "Total de recortes: 1073\n",
      "Paciente sub-76E02 carregado com sucesso.\n",
      "Total de recortes: 1311\n",
      "Paciente sub-76J09 carregado com sucesso.\n",
      "Total de recortes: 1057\n",
      "Paciente sub-83K08 carregado com sucesso.\n",
      "Total de recortes: 1063\n",
      "Paciente sub-85I05 carregado com sucesso.\n",
      "Total de recortes: 1134\n",
      "Paciente sub-86B13 carregado com sucesso.\n",
      "Total de recortes: 1060\n",
      "\n",
      "\n",
      "Modalidade de imagem: T2\n",
      "Paciente sub-00H10 carregado com sucesso.\n",
      "Total de recortes: 1073\n",
      "Paciente sub-02A13 carregado com sucesso.\n",
      "Total de recortes: 1071\n",
      "Paciente sub-06C09 carregado com sucesso.\n",
      "Total de recortes: 1076\n",
      "Paciente sub-14F04 carregado com sucesso.\n",
      "Total de recortes: 1158\n",
      "Paciente sub-16E03 carregado com sucesso.\n",
      "Total de recortes: 1209\n",
      "Paciente sub-16G09 carregado com sucesso.\n",
      "Total de recortes: 1108\n",
      "Paciente sub-16I12 carregado com sucesso.\n",
      "Total de recortes: 1192\n",
      "Paciente sub-19F09 carregado com sucesso.\n",
      "Total de recortes: 1202\n",
      "Paciente sub-19G04 carregado com sucesso.\n",
      "Total de recortes: 1134\n",
      "Paciente sub-26B09 carregado com sucesso.\n",
      "Total de recortes: 1135\n",
      "Paciente sub-29D03 carregado com sucesso.\n",
      "Total de recortes: 1133\n",
      "Paciente sub-31F07 carregado com sucesso.\n",
      "Total de recortes: 1121\n",
      "Paciente sub-35E12 carregado com sucesso.\n",
      "Total de recortes: 1129\n",
      "Paciente sub-36K02 carregado com sucesso.\n",
      "Total de recortes: 1174\n",
      "Paciente sub-41D08 carregado com sucesso.\n",
      "Total de recortes: 1094\n",
      "Paciente sub-42K06 carregado com sucesso.\n",
      "Total de recortes: 1038\n",
      "Paciente sub-44H05 carregado com sucesso.\n",
      "Total de recortes: 1171\n",
      "Paciente sub-51C05 carregado com sucesso.\n",
      "Total de recortes: 1226\n",
      "Paciente sub-52K04 carregado com sucesso.\n",
      "Total de recortes: 1157\n",
      "Paciente sub-56E13 carregado com sucesso.\n",
      "Total de recortes: 1082\n",
      "Paciente sub-59G00 carregado com sucesso.\n",
      "Total de recortes: 1078\n",
      "Paciente sub-60G06 carregado com sucesso.\n",
      "Total de recortes: 1179\n",
      "Paciente sub-60G13 carregado com sucesso.\n",
      "Total de recortes: 1131\n",
      "Paciente sub-60K04 carregado com sucesso.\n",
      "Total de recortes: 1094\n",
      "Paciente sub-71C07 carregado com sucesso.\n",
      "Total de recortes: 1064\n",
      "Paciente sub-72I02 carregado com sucesso.\n",
      "Total de recortes: 1198\n",
      "Paciente sub-72K02 carregado com sucesso.\n",
      "Total de recortes: 1214\n",
      "Paciente sub-76E02 carregado com sucesso.\n",
      "Total de recortes: 1267\n",
      "Paciente sub-76J09 carregado com sucesso.\n",
      "Total de recortes: 1065\n",
      "Paciente sub-83K08 carregado com sucesso.\n",
      "Total de recortes: 1087\n",
      "Paciente sub-85I05 carregado com sucesso.\n",
      "Total de recortes: 1205\n",
      "Paciente sub-86B13 carregado com sucesso.\n",
      "Total de recortes: 1101\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient_id \u001b[38;5;129;01min\u001b[39;00m data_T1:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m patient_id \u001b[38;5;129;01min\u001b[39;00m data_FLAIR \u001b[38;5;129;01mand\u001b[39;00m patient_id \u001b[38;5;129;01min\u001b[39;00m data_T2:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# Junta as três modalidades no eixo da cor\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m         img_rgb_left \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_T1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages_left\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_FLAIR\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages_left\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_T2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages_left\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m         img_rgb_right \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m     43\u001b[0m             data_T1[patient_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages_right\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     44\u001b[0m             data_FLAIR[patient_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages_right\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     45\u001b[0m             data_T2[patient_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages_right\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     46\u001b[0m         ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m# Armazena\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Panza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:449\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    451\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    452\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# Pastas com os tipos\n",
    "folder_T1 = \"Novo_Contralateral/Contralateral_T1\"\n",
    "folder_FLAIR = \"Novo_Contralateral/Contralateral_Flair\"\n",
    "folder_T2 = \"Novo_Contralateral/Contralateral_T2\"\n",
    "\n",
    "# Dicionários para cada modalidade\n",
    "data_T1, data_FLAIR, data_T2 = {}, {}, {}\n",
    "\n",
    "# Função genérica para carregar dados por modalidade\n",
    "def load_all_modalities(folder, modality_dict, modality_type):\n",
    "    print(\"Modalidade de imagem: \" + modality_type)\n",
    "    for patient_id in os.listdir(folder):\n",
    "        patient_data, labels_pair = load_patient_data(folder, patient_id)\n",
    "        if patient_data is not None:\n",
    "            modality_dict[patient_id] = {\n",
    "                \"images_left\": patient_data[\"images_left\"],\n",
    "                \"images_right\": patient_data[\"images_right\"],\n",
    "                \"mask_left\": patient_data[\"mask_left\"],\n",
    "                \"mask_right\": patient_data[\"mask_right\"],\n",
    "                \"labels_pair\": labels_pair\n",
    "            }\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Carrega os dados das três modalidades\n",
    "load_all_modalities(folder_T1, data_T1, \"T1\")\n",
    "load_all_modalities(folder_FLAIR, data_FLAIR, \"Flair\")\n",
    "load_all_modalities(folder_T2, data_T2, \"T2\")\n",
    "\n",
    "# Agora criamos os dicionários finais\n",
    "X_rgb_left, X_rgb_right = {}, {}\n",
    "mask_left, mask_right, y = {}, {}, {}\n",
    "\n",
    "for patient_id in data_T1:\n",
    "    if patient_id in data_FLAIR and patient_id in data_T2:\n",
    "        # Junta as três modalidades no eixo da cor\n",
    "        img_rgb_left = np.stack([\n",
    "            data_T1[patient_id][\"images_left\"],\n",
    "            data_FLAIR[patient_id][\"images_left\"],\n",
    "            data_T2[patient_id][\"images_left\"]\n",
    "        ], axis=-1)\n",
    "\n",
    "        img_rgb_right = np.stack([\n",
    "            data_T1[patient_id][\"images_right\"],\n",
    "            data_FLAIR[patient_id][\"images_right\"],\n",
    "            data_T2[patient_id][\"images_right\"]\n",
    "        ], axis=-1)\n",
    "\n",
    "        # Armazena\n",
    "        X_rgb_left[patient_id] = img_rgb_left\n",
    "        X_rgb_right[patient_id] = img_rgb_right\n",
    "        mask_left[patient_id] = data_T1[patient_id][\"mask_left\"]\n",
    "        mask_right[patient_id] = data_T1[patient_id][\"mask_right\"]\n",
    "        y[patient_id] = data_T1[patient_id][\"labels_pair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para treino, validação e teste\n",
    "train_left_balanced, train_right_balanced, valid_left_balanced, valid_right_balanced, test_left, test_right, y_train_balanced, y_valid_balanced, y_test, train_patients, valid_patients, test_patients, balanced_mask_left, balanced_mask_right, balanced_index_patients = prepare_data_for_training(X_rgb_left, X_rgb_right, y, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1)\n",
    "train_left_balanced = normalize_minmax(np.array([elemento for lista in train_left_balanced.values() for elemento in lista]))\n",
    "train_right_balanced = normalize_minmax(np.array([elemento for lista in train_right_balanced.values() for elemento in lista]))\n",
    "valid_left_balanced = normalize_minmax(np.array([elemento for lista in valid_left_balanced.values() for elemento in lista]))\n",
    "valid_right_balanced = normalize_minmax(np.array([elemento for lista in valid_right_balanced.values() for elemento in lista]))\n",
    "test_left = normalize_minmax(np.array([elemento for lista in test_left.values() for elemento in lista]))\n",
    "test_right = normalize_minmax(np.array([elemento for lista in test_right.values() for elemento in lista]))\n",
    "\n",
    "# train_left_balanced, train_right_balanced, valid_left_balanced, valid_right_balanced, test_left, test_right, y_train_balanced, y_valid_balanced, y_test, train_patients, valid_patients, test_patients, mask_train_left, mask_train_right, mask_valid_left, mask_valid_right, mask_test_left, mask_test_right, paired_index_dictionary = prepare_data_aligned(X_rgb_left, X_rgb_right, y, mask_left, mask_right)\n",
    "# train_left_balanced = normalize_minmax(train_left_balanced)\n",
    "# train_right_balanced = normalize_minmax(train_right_balanced)\n",
    "# valid_left_balanced = normalize_minmax(valid_left_balanced)\n",
    "# valid_right_balanced = normalize_minmax(valid_right_balanced)\n",
    "# test_left = normalize_minmax(test_left)\n",
    "# test_right = normalize_minmax(test_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciono camada de cor\n",
    "train_left_balanced = np.expand_dims(train_left_balanced, axis=-1)\n",
    "train_right_balanced = np.expand_dims(train_right_balanced, axis=-1)\n",
    "valid_left_balanced = np.expand_dims(valid_left_balanced, axis=-1)\n",
    "valid_right_balanced = np.expand_dims(valid_right_balanced, axis=-1)\n",
    "test_left = np.expand_dims(test_left, axis=-1)\n",
    "test_right = np.expand_dims(test_right, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir  e compilar o modelo CNN\n",
    "input_shape = (train_left_balanced[0].shape)\n",
    "\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o callback EarlyStopping e low rate scheduler\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
    "\n",
    "# Ajusta learning rate\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(factor=0.8, patience=15, verbose=1)\n",
    "\n",
    "# Suponha que seus rótulos estejam em y_train_balanced\n",
    "# classes = np.unique(y_valid_balanced)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_valid_balanced)\n",
    "# class_weight_dict = dict(zip(classes, weights))\n",
    "\n",
    "# Salvar a melhor epoca\n",
    "checkpoint = callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True,  save_weights_only=True, mode='min')\n",
    "\n",
    "# Treinamento do modelo siames\n",
    "history = siamese_model.fit([train_left_balanced, train_right_balanced], y_train_balanced, validation_data=([valid_left_balanced, valid_right_balanced], y_valid_balanced), batch_size=128, epochs=150, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o histórico do treinamento\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando pesos da melhor época\n",
    "siamese_model.load_weights('best_model.h5')\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_train = (siamese_model.predict([train_left_balanced, train_right_balanced]) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (siamese_model.predict([valid_left_balanced, valid_right_balanced]) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (siamese_model.predict([test_left, test_right]) > 0.5).astype(int)\n",
    "\n",
    "# Calcula a curva precision-recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_test)\n",
    "\n",
    "# Calcula a AUC precision-recall\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Plote a curva precision-recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'AUC = {auc_pr:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o relatório de classificação\n",
    "print(\"Treino:\")\n",
    "print(classification_report(y_train_balanced, y_pred_train))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Validação:\")\n",
    "print(classification_report(y_valid_balanced, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "#print(classification_report(y_test, y_pred_test)) \n",
    "print(classification_report(y_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(y_valid_balanced, y_pred_valid)\n",
    "print(\"Teste:\")\n",
    "plot_confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodando processos de Pós-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_data_per_slice(folder, patient_id): # carregar dados de teste, mantendo os dados de cada fatia em um vetor\n",
    "    patient_path = os.path.join(folder, patient_id)  # folder/patient/\n",
    "    if not os.path.exists(patient_path):\n",
    "        print(f\"Paciente {patient_id} não encontrado na pasta {folder}.\")\n",
    "        return None\n",
    "\n",
    "    # Inicializa estruturas para armazenar os dados do paciente\n",
    "    patient_data = {\n",
    "        \"images_left\": [],\n",
    "        \"images_right\": [],\n",
    "        \"mask_left\": [],\n",
    "        \"mask_right\": [],\n",
    "        \"labels_left\": [],\n",
    "        \"labels_right\": [],\n",
    "    }\n",
    "\n",
    "    labels_total = []\n",
    "    areas_image = [\"left\", \"right\"]\n",
    "    areas_mask = [\"lesion_left\", \"lesion_right\"]\n",
    "    path_left = os.path.join(patient_path, areas_image[0])  # folder/patient/left\n",
    "    path_right = os.path.join(patient_path, areas_image[1])\n",
    "    lesion_path_left = os.path.join(patient_path, areas_mask[0])\n",
    "    lesion_path_right = os.path.join(patient_path, areas_mask[1])\n",
    "\n",
    "    # Verifica se os diretórios existem\n",
    "    if not os.path.exists(path_left) or not os.path.exists(path_right) or \\\n",
    "       not os.path.exists(lesion_path_left) or not os.path.exists(lesion_path_right):\n",
    "        print(f\"Estrutura de diretórios inválida para o paciente {patient_id}.\")\n",
    "        return None\n",
    "\n",
    "    # Carrega as imagens e máscaras do lado esquerdo e direito\n",
    "    for patch_id_left, mask_id_left, patch_id_right, mask_id_right in zip(\n",
    "        os.listdir(path_left), os.listdir(lesion_path_left),\n",
    "        os.listdir(path_right), os.listdir(lesion_path_right)\n",
    "    ):\n",
    "        img_path_left = os.path.join(path_left, patch_id_left)  # folder/patient/left/slice_\n",
    "        mask_path_left = os.path.join(lesion_path_left, mask_id_left)\n",
    "        img_path_right = os.path.join(path_right, patch_id_right)\n",
    "        mask_path_right = os.path.join(lesion_path_right, mask_id_right)\n",
    "        \n",
    "        slice_left_img = []\n",
    "        slice_right_img = []\n",
    "        slice_left_mask = []\n",
    "        slice_right_mask = []\n",
    "        slice_left_labels = []\n",
    "        slice_right_labels = []\n",
    "\n",
    "        for img_left, msk_left, img_right, msk_right in zip(\n",
    "            os.listdir(img_path_left), os.listdir(mask_path_left),\n",
    "            os.listdir(img_path_right), os.listdir(mask_path_right)\n",
    "        ):\n",
    "            # Carrega os dados do lado esquerdo\n",
    "            data_left = nib.load(os.path.join(img_path_left, img_left)).get_fdata()\n",
    "            data_msk_left = nib.load(os.path.join(mask_path_left, msk_left)).get_fdata()\n",
    "\n",
    "            if len(data_left) > 0 or len(data_msk_left) > 0:\n",
    "                slice_left_img.append(data_left)\n",
    "                slice_left_mask.append(data_msk_left)\n",
    "                slice_left_labels.append(calculate_label(data_msk_left))\n",
    "\n",
    "            # Carrega os dados do lado direito\n",
    "            data_right = nib.load(os.path.join(img_path_right, img_right)).get_fdata()\n",
    "            data_msk_right = nib.load(os.path.join(mask_path_right, msk_right)).get_fdata()\n",
    "\n",
    "            if len(data_right) > 0 or len(data_msk_right) > 0:\n",
    "                slice_right_img.append(data_right)\n",
    "                slice_right_mask.append(data_msk_right)\n",
    "                slice_right_labels.append(calculate_label(data_msk_right))\n",
    "\n",
    "        patient_data[\"images_left\"].append(slice_left_img)\n",
    "        patient_data[\"mask_left\"].append(slice_left_mask)\n",
    "        patient_data[\"labels_left\"].append(slice_left_labels)\n",
    "\n",
    "        patient_data[\"images_right\"].append(slice_right_img)\n",
    "        patient_data[\"mask_right\"].append(slice_right_mask)\n",
    "        patient_data[\"labels_right\"].append(slice_right_labels)\n",
    "\n",
    "        labels_pair = []\n",
    "        for label_left, label_right in zip(slice_left_labels, slice_right_labels):\n",
    "            if label_left == 0 and label_right == 0:\n",
    "                labels_pair.append(0)\n",
    "            else:\n",
    "                labels_pair.append(1)\n",
    "        labels_total.append(labels_pair)\n",
    "\n",
    "    patient_data[\"labels_pair\"] = labels_total\n",
    "\n",
    "    print(f\"Paciente {patient_id} carregado com sucesso.\")\n",
    "    print(f\"Total de recortes: {len(labels_total)}\")\n",
    "    return patient_data, labels_total\n",
    "\n",
    "def test_labels_near(predictions): # pós-processamento\n",
    "    new_pred = copy.deepcopy(predictions)\n",
    "    previous_pos = 0\n",
    "    actual_pos = 0\n",
    "    next_pos = 0\n",
    "\n",
    "    for i in range(1, len(predictions) - 1):\n",
    "\n",
    "        # testa posições \"perto\", mas tá errado pela ordem dos recortes dentro da fatia\n",
    "        for j in range(1, len(predictions[i])-1):\n",
    "            if predictions[i][j] == 0 and predictions[i][j-1] == 1 and predictions[i][j+1] == 1:\n",
    "                new_pred[i][j+1] = 0\n",
    "                new_pred[i][j-1] = 0\n",
    "                print(f\"ANTES unit: {predictions[i]}\")\n",
    "                print(f\"DEPOIS: {new_pred[i]}\\n\")\n",
    "\n",
    "        # testa 3 fatias sequenciais\n",
    "        previous_pos = np.count_nonzero(predictions[i - 1])\n",
    "        actual_pos = np.count_nonzero(predictions[i])\n",
    "        next_pos = np.count_nonzero(predictions[i + 1])\n",
    "\n",
    "        if (previous_pos == 0 and actual_pos >= 1 and next_pos == 0):\n",
    "            new_pred[i] = np.array([0 for j in range(len(predictions[i]))])\n",
    "            print(f\"ANTES whole: {predictions[i]}\")\n",
    "            print(f\"DEPOIS: {new_pred[i]}\\n\")\n",
    "\n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho da pasta contendo os dados dos pacientes\n",
    "folder = \"Novo_Contralateral\"\n",
    "\n",
    "# Lista de IDs dos pacientes\n",
    "test_patient_ids = ['sub-42B05', 'sub-42K06', 'sub-44H05', 'sub-86G08']\n",
    "\n",
    "X_slices_left, X_slices_right, y_slices, mask_slices_left, mask_slices_right = {}, {}, {}, {}, {}\n",
    "\n",
    "# Processa um paciente por vez\n",
    "for patient_id in test_patient_ids:\n",
    "    # Carrega os dados do paciente\n",
    "    patient_data_test, labels_pair_test = load_patient_data_per_slice(folder, patient_id)\n",
    "    \n",
    "    if patient_data_test is not None:\n",
    "        X_slices_left[patient_id] = patient_data_test[\"images_left\"]\n",
    "        X_slices_right[patient_id] = patient_data_test[\"images_right\"]\n",
    "        mask_slices_left[patient_id] = patient_data_test[\"mask_left\"]\n",
    "        mask_slices_right[patient_id] = patient_data_test[\"mask_right\"]\n",
    "        y_slices[patient_id] = labels_pair_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização e tratamento de dimensões do dado de teste\n",
    "test_single_left = {}\n",
    "test_single_right = {}\n",
    "\n",
    "for id in test_patient_ids:\n",
    "    test_single_left[id] = []\n",
    "    test_single_right[id] = []\n",
    "\n",
    "    for i in range(0, len(X_slices_left[id])):\n",
    "        test_single_left[id].append([])\n",
    "        test_single_right[id].append([])\n",
    "\n",
    "        for j in range(0, len(X_slices_left[id][i])):\n",
    "            # print(f\"Dados do paciente {id} da fatia {i} do dado {j} esquerdo\")\n",
    "            test_single_left[id][i].append(normalize_minmax(np.array(X_slices_left[id][i][j]))) # normaliza as imagens\n",
    "            test_single_right[id][i].append(normalize_minmax(np.array(X_slices_right[id][i][j])))\n",
    "\n",
    "        test_single_left[id][i] = np.expand_dims(test_single_left[id][i], axis=-1) # expande eixo pra passar rede pra predict\n",
    "        test_single_right[id][i] = np.expand_dims(test_single_right[id][i], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir e compilar o modelo CNN\n",
    "input_shape = (test_single_left[test_patient_ids[0]][0][0].shape)\n",
    "\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()\n",
    "\n",
    "# Carregando pesos da melhor época\n",
    "siamese_model.load_weights('best_model.h5')\n",
    "\n",
    "y_test_slices_pred = {}\n",
    "\n",
    "for patient in test_patient_ids:\n",
    "    print(f\"paciente {patient}\")\n",
    "    y_test_slices_pred[patient] = []\n",
    "\n",
    "    for i in range(0, len(X_slices_left[patient])):\n",
    "        print(f\"fatia {i}\")\n",
    "        left = test_single_left[patient][i]\n",
    "        right = test_single_right[patient][i]\n",
    "        y_test_slices_pred[patient].append((siamese_model.predict([left, right]) > 0.5).astype(int).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparando resultados sem e com Pós-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels certos -> y_slices\n",
    "# predição não processada -> y_test_slices_pred\n",
    "# predição processada -> processed labels\n",
    "\n",
    "processed_labels = {}\n",
    "\n",
    "# crio um novo vetor com os labels processados\n",
    "for patient_name in test_patient_ids:\n",
    "    processed_labels[patient_name] = test_labels_near(y_test_slices_pred[patient_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_processed = list(itertools.chain(*list(itertools.chain(*processed_labels.values()))))\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "print(\"RESULTADO ORIGINAL:\")\n",
    "plot_confusion_matrix(y_test, y_pred_test)\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"PÓS PROCESSADO:\")\n",
    "plot_confusion_matrix(y_test, labels_pred_processed)\n",
    "\n",
    "# print(labels_true)\n",
    "# print(labels_pred_raw)\n",
    "# print(labels_pred_processed)\n",
    "\n",
    "# print(np.count_nonzero(labels_true))\n",
    "# print(np.count_nonzero(labels_pred_raw))\n",
    "# print(np.count_nonzero(labels_pred_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Teste\") \n",
    "print(classification_report(y_test, labels_pred_processed)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotando PDFs para comparação dos resultados e análise das classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para adicionar borda ao patch com a cor da classificação\n",
    "def add_border(image, color, thickness=3):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    bordered_image = cv2.copyMakeBorder(image_rgb, thickness, thickness, thickness, thickness, cv2.BORDER_CONSTANT, value=color)\n",
    "    return bordered_image\n",
    "\n",
    "def enhance_contrast(img, factor=1.1):\n",
    "    img = img.astype(np.float32)\n",
    "    img = img * factor\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Função para carregar imagens no formato NIfTI (.nii.gz)\n",
    "def load_nii_slice(patient_id, slice_index, base_path):\n",
    "    file_path = os.path.join(base_path, patient_id, f\"Slice_{slice_index:03d}.nii.gz\")\n",
    "    if os.path.exists(file_path):\n",
    "        nii_img = nib.load(file_path)\n",
    "        img_data = nii_img.get_fdata()\n",
    "        return img_data\n",
    "    return None\n",
    "\n",
    "# Função para carregar coordenadas de arquivos .txt\n",
    "def load_coordinates(patient_id, slice_index, base_path):\n",
    "    coord_file = os.path.join(base_path, patient_id, f\"Slice_{slice_index:03d}.txt\")\n",
    "    if os.path.exists(coord_file):\n",
    "        with open(coord_file, \"r\") as file:\n",
    "            coordinates = [tuple(map(int, line.strip().split(\",\"))) for line in file]\n",
    "        return coordinates\n",
    "    return []\n",
    "\n",
    "# Função para reconstruir a imagem e sobrepor o grid\n",
    "def build_image_with_grid(patient_id, slice_index, labels_pred, labels_true, image_path, mask_path, coordinates_path, index):\n",
    "    img = load_nii_slice(patient_id, slice_index, image_path)\n",
    "    img = cv2.normalize(img, None, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    mask = load_nii_slice(patient_id, slice_index, mask_path)\n",
    "    mask = cv2.normalize(mask, None, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    coordinates = load_coordinates(patient_id, slice_index, coordinates_path)\n",
    "    \n",
    "    if img is None or mask is None or not coordinates:\n",
    "        return None, None, index\n",
    "\n",
    "    img = enhance_contrast(img)\n",
    "    mask = enhance_contrast(mask)\n",
    "\n",
    "    reconstructed_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    reconstructed_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    colors = {\"TP\": (0, 255, 0), \"TN\": (120, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "    \n",
    "    half = len(coordinates) // 2\n",
    "    classifications = []\n",
    "\n",
    "    for i in range(half):\n",
    "        true = labels_true[i + index]\n",
    "        pred = labels_pred[i + index]\n",
    "        if pred == true:\n",
    "            classif = \"TP\" if pred == 1 else \"TN\"\n",
    "        else:\n",
    "            classif = \"FP\" if pred == 1 else \"FN\"\n",
    "        classifications.append(classif)\n",
    "    \n",
    "    # Repetir a classificação para o lado direito\n",
    "    classifications.extend(classifications)\n",
    "\n",
    "    for i, (y1, y2, x1, x2) in enumerate(coordinates):\n",
    "        classif = classifications[i]\n",
    "\n",
    "        patch_img = img[y1+3:y2-3, x1+3:x2-3]\n",
    "        patch_mask = mask[y1+3:y2-3, x1+3:x2-3]\n",
    "\n",
    "        bordered_patch_img = add_border(patch_img, colors[classif])\n",
    "        bordered_patch_mask = add_border(patch_mask, colors[classif])\n",
    "\n",
    "        reconstructed_img[y1:y2, x1:x2] = bordered_patch_img\n",
    "        reconstructed_mask[y1:y2, x1:x2] = bordered_patch_mask\n",
    "\n",
    "    return reconstructed_img, reconstructed_mask, (index + half)\n",
    "\n",
    "# Reconstrói uma fatia do paciente usando coordenadas + indexes mapeados\n",
    "def build_image_with_grid_indexed(patient_id, slice_index, balanced_index_patients,\n",
    "                                  labels_pred, labels_true, image_path, mask_path,\n",
    "                                  coordinates_path, patch_metadata):\n",
    "    img = load_nii_slice(patient_id, slice_index, image_path)\n",
    "    img = cv2.normalize(img, None, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    mask = load_nii_slice(patient_id, slice_index, mask_path)\n",
    "    mask = cv2.normalize(mask, None, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    coordinates = load_coordinates(patient_id, slice_index, coordinates_path)\n",
    "\n",
    "    if img is None or mask is None or not coordinates:\n",
    "        return None, None\n",
    "\n",
    "    img = enhance_contrast(img)\n",
    "    mask = enhance_contrast(mask)\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    reconstructed_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    reconstructed_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    colors = {\"TP\": (0, 255, 0), \"TN\": (120, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "\n",
    "    for i, (y1, y2, x1, x2) in enumerate(coordinates):\n",
    "        # Identifica o global_index da coordenada\n",
    "        global_index = None\n",
    "        for idx, meta in patch_metadata.items():\n",
    "            if meta[0] == patient_id and meta[1] == slice_index and meta[3:] == (y1, y2, x1, x2):\n",
    "                global_index = idx\n",
    "                break\n",
    "\n",
    "        if global_index in balanced_index_patients:\n",
    "            label_pos = balanced_index_patients.index(global_index)\n",
    "            true_label = labels_true[label_pos]\n",
    "            pred_label = labels_pred[label_pos]\n",
    "\n",
    "            if pred_label == true_label:\n",
    "                classif = \"TP\" if pred_label == 1 else \"TN\"\n",
    "            else:\n",
    "                classif = \"FP\" if pred_label == 1 else \"FN\"\n",
    "\n",
    "            patch_img = img[y1+3:y2-3, x1+3:x2-3]\n",
    "            patch_mask = mask[y1+3:y2-3, x1+3:x2-3]\n",
    "        else:\n",
    "            classif = \"TN\"\n",
    "            patch_img = np.zeros((y2 - y1 - 6, x2 - x1 - 6), dtype=np.uint8)\n",
    "            patch_mask = np.zeros((y2 - y1 - 6, x2 - x1 - 6), dtype=np.uint8)\n",
    "\n",
    "        bordered_patch_img = add_border(patch_img, colors[classif])\n",
    "        bordered_patch_mask = add_border(patch_mask, colors[classif])\n",
    "\n",
    "        reconstructed_img[y1:y2, x1:x2] = bordered_patch_img\n",
    "        reconstructed_mask[y1:y2, x1:x2] = bordered_patch_mask\n",
    "\n",
    "    return reconstructed_img, reconstructed_mask\n",
    "\n",
    "# Gera metadados global_index → (patient, slice, side, y1, y2, x1, x2)\n",
    "def generate_patch_metadata(patients, coordinates_path):\n",
    "    patch_metadata = {}\n",
    "    global_index = 0\n",
    "    for patient in patients:\n",
    "        patient_dir = os.path.join(coordinates_path, patient)\n",
    "        if not os.path.isdir(patient_dir):\n",
    "            continue\n",
    "        for filename in sorted(os.listdir(patient_dir)):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                slice_index = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "                coord_file = os.path.join(patient_dir, filename)\n",
    "                with open(coord_file, \"r\") as f:\n",
    "                    coords = [tuple(map(int, line.strip().split(\",\"))) for line in f if line.strip()]\n",
    "                half = len(coords) // 2\n",
    "                for i, (y1, y2, x1, x2) in enumerate(coords):\n",
    "                    side = 'left' if i < half else 'right'\n",
    "                    patch_metadata[global_index] = (patient, slice_index, side, y1, y2, x1, x2)\n",
    "                    global_index += 1\n",
    "    print(f\"✅ Mapeamento gerado com {len(patch_metadata)} patches.\")\n",
    "    return patch_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_slices(pdf_filename, patients, coordinates_path, image_path, mask_path, labels_true, labels_pred):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "    \n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            for slice_index in range(test_patients_quantity[patient]):\n",
    "                img_recon, mask_recon, index = build_image_with_grid(patient, slice_index, labels_pred, labels_true, image_path, mask_path, coordinates_path, index)\n",
    "                \n",
    "                if img_recon is None:\n",
    "                    continue\n",
    "                \n",
    "                fig, axs = plt.subplots(2, 1, figsize=(6, 6))\n",
    "                axs[0].imshow(img_recon, cmap='gray')\n",
    "                axs[0].set_title(f'Paciente {patient} - Imagem')\n",
    "                axs[0].axis('off')\n",
    "                axs[1].imshow(mask_recon, cmap='gray')\n",
    "                axs[1].set_title(f'Paciente {patient} - Máscara')\n",
    "                axs[1].axis('off')\n",
    "                \n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "                \n",
    "        print(f\"As imagens foram salvas no arquivo PDF {pdf_filename} com sucesso.\")\n",
    "\n",
    "# Chamando a função para gerar o PDF\n",
    "test_patients_quantity = {'sub-42B05': 1204, 'sub-42K06': 1122, 'sub-44H05': 1213, 'sub-86G08': 1189}\n",
    "plot_patient_slices(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Reconstruidos_Com_Uppersampling+Undersampling.pdf\",\n",
    "    patients=test_patients,\n",
    "    coordinates_path=\"Coordenadas_grid\",\n",
    "    image_path=\"Fatias_Patients\",\n",
    "    mask_path=\"Fatias_Mask\",\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nifti_patient_slices_with_borders_and_masks(\n",
    "    pdf_folder, patients, coordinates_path, image_path, mask_path,\n",
    "    labels_true, labels_pred, balanced_index_patients\n",
    "):\n",
    "    os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "    patch_metadata = generate_patch_metadata(patients, coordinates_path)\n",
    "\n",
    "    # Mapeia slices por paciente\n",
    "    slices_por_paciente = {}\n",
    "    for idx, (patient_id, slice_idx, _, _, _, _, _) in patch_metadata.items():\n",
    "        slices_por_paciente.setdefault(patient_id, set()).add(slice_idx)\n",
    "\n",
    "    for patient in patients:\n",
    "        if patient not in slices_por_paciente:\n",
    "            continue\n",
    "\n",
    "        slice_indices = sorted(slices_por_paciente[patient])\n",
    "        patient_folder = os.path.join(pdf_folder, patient)\n",
    "        os.makedirs(patient_folder, exist_ok=True)\n",
    "        pdf_filename = os.path.join(patient_folder, f\"Paciente_{patient}.pdf\")\n",
    "\n",
    "        with PdfPages(pdf_filename) as pdf:\n",
    "            for slice_idx in slice_indices:\n",
    "                img_reconstructed, mask_reconstructed = build_image_with_grid_indexed(\n",
    "                    patient_id=patient,\n",
    "                    slice_index=slice_idx,\n",
    "                    balanced_index_patients=balanced_index_patients,\n",
    "                    labels_pred=labels_pred,\n",
    "                    labels_true=labels_true,\n",
    "                    image_path=image_path,\n",
    "                    mask_path=mask_path,\n",
    "                    coordinates_path=coordinates_path,\n",
    "                    patch_metadata=patch_metadata\n",
    "                )\n",
    "\n",
    "                if img_reconstructed is None or mask_reconstructed is None:\n",
    "                    continue\n",
    "\n",
    "                fig, axs = plt.subplots(2, 1, figsize=(8, 12))\n",
    "                axs[0].imshow(img_reconstructed)\n",
    "                axs[0].set_title(f\"Reconstrução com Classificação - {patient} - Slice {slice_idx:03d}\")\n",
    "                axs[0].axis(\"off\")\n",
    "\n",
    "                axs[1].imshow(mask_reconstructed)\n",
    "                axs[1].set_title(\"Máscara Correspondente\")\n",
    "                axs[1].axis(\"off\")\n",
    "\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "        print(f\"✅ PDF salvo: {pdf_filename}\")\n",
    "\n",
    "    print(f\"\\n📁 Todos os PDFs foram salvos em: {pdf_folder}\")\n",
    "\n",
    "# plot_nifti_patient_slices_with_borders_and_masks(\n",
    "#     pdf_folder=\"Pdf_Final_NIfTI_Reconstruido\",\n",
    "#     patients=train_patients,\n",
    "#     coordinates_path=\"Coordenadas_grid\",\n",
    "#     image_path=\"Fatias\",\n",
    "#     mask_path=\"Mask_Fatias\",\n",
    "#     labels_true=y_train_balanced,\n",
    "#     labels_pred=y_pred_train,\n",
    "#     balanced_index_patients=balanced_index_patients\n",
    "# )\n",
    "\n",
    "plot_nifti_patient_slices_with_borders_and_masks(\n",
    "    pdf_folder=\"Pdf_Final_NIfTI_Reconstruido\",\n",
    "    patients=valid_patients,\n",
    "    coordinates_path=\"Coordenadas_grid\",\n",
    "    image_path=\"Fatias_Patients\",\n",
    "    mask_path=\"Fatias_Mask\",\n",
    "    labels_true=y_valid_balanced,\n",
    "    labels_pred=y_pred_valid,\n",
    "    balanced_index_patients=balanced_index_patients\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_slices_paired(pdf_filename, patients, coordinates_path, image_path, mask_path, labels_true, labels_pred):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "    \n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            for slice_index in range(test_patients_quantity[patient]):\n",
    "                img_recon, mask_recon, index = build_image_with_grid(patient, slice_index, labels_pred, labels_true, image_path, mask_path, coordinates_path, index)\n",
    "                \n",
    "                if img_recon is None:\n",
    "                    continue\n",
    "                \n",
    "                fig, axs = plt.subplots(2, 1, figsize=(6, 6))\n",
    "                axs[0].imshow(img_recon, cmap='gray')\n",
    "                axs[0].set_title(f'Paciente {patient} - Imagem')\n",
    "                axs[0].axis('off')\n",
    "                axs[1].imshow(mask_recon, cmap='gray')\n",
    "                axs[1].set_title(f'Paciente {patient} - Máscara')\n",
    "                axs[1].axis('off')\n",
    "                \n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "                \n",
    "        print(f\"As imagens foram salvas no arquivo PDF {pdf_filename} com sucesso.\")\n",
    "\n",
    "# Chamando a função para gerar o PDF\n",
    "test_patients_quantity = {'sub-42B05': 1204, 'sub-42K06': 1122, 'sub-44H05': 1213, 'sub-86G08': 1189}\n",
    "plot_patient_slices_paired(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Reconstruidos_Com_Pareamento.pdf\",\n",
    "    patients=test_patients,\n",
    "    coordinates_path=\"Coordenadas_grid\",\n",
    "    image_path=\"Fatias_Patients\",\n",
    "    mask_path=\"Fatias_Mask\",\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_patches_paired(pdf_filename, patients, images_left, images_right, masks_left, masks_right, labels_true, labels_pred, balanced_index_by_patients, type):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            print(f\"\\n🔍 Paciente: {patient}\")\n",
    "            indices = paired_index_dictionary[type].get(patient, [])\n",
    "            print(f\"📊 Número de pares: {len(indices)}\")\n",
    "\n",
    "            for i in range(len(indices)):\n",
    "                colors = {\"TP\": (0, 255, 0), \"TN\": (150, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "\n",
    "                # Calcula a classificação\n",
    "                true_label = labels_true[index]\n",
    "                pred_label = labels_pred[index]\n",
    "                if pred_label == true_label:\n",
    "                    classification = \"TP\" if pred_label == 1 else \"TN\"\n",
    "                else:\n",
    "                    classification = \"FP\" if pred_label == 1 else \"FN\"\n",
    "\n",
    "                color = colors[classification]\n",
    "\n",
    "                # Pega patches esquerdo e direito e máscaras pelos arrays alinhados\n",
    "                patch_left = images_left[index]\n",
    "                patch_right = images_right[index]\n",
    "                mask_l = masks_left[index]\n",
    "                mask_r = masks_right[index]\n",
    "\n",
    "                # Aplica bordas\n",
    "                bordered_patch_left = add_border(patch_left, color)\n",
    "                bordered_patch_right = add_border(patch_right, color)\n",
    "                bordered_mask_left = add_border(mask_l, color)\n",
    "                bordered_mask_right = add_border(mask_r, color)\n",
    "\n",
    "                # Plotagem\n",
    "                fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "                axs[0, 0].imshow(bordered_patch_left)\n",
    "                axs[0, 0].set_title(\"Img Esq\")\n",
    "                axs[0, 1].imshow(bordered_patch_right)\n",
    "                axs[0, 1].set_title(\"Img Dir\")\n",
    "                axs[1, 0].imshow(bordered_mask_left)\n",
    "                axs[1, 0].set_title(\"Mask Esq\")\n",
    "                axs[1, 1].imshow(bordered_mask_right)\n",
    "                axs[1, 1].set_title(\"Mask Dir\")\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.axis('off')\n",
    "\n",
    "                fig.suptitle(f\"Paciente: {patient} | {classification}\", fontsize=10)\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "                index += 1\n",
    "\n",
    "        print(f\"Patches com bordas salvos em {pdf_filename}\")\n",
    "\n",
    "plot_patient_patches_paired(\n",
    "    pdf_filename=\"Pdf_SNN/Train_Patches_SemReconstrucao_Pareamento.pdf\",\n",
    "    patients=train_patients,\n",
    "    images_left=train_left_balanced,\n",
    "    images_right=train_right_balanced,\n",
    "    masks_left=mask_train_left,\n",
    "    masks_right=mask_train_right,\n",
    "    labels_true=y_train_balanced,\n",
    "    labels_pred=y_pred_train,\n",
    "    balanced_index_by_patients=paired_index_dictionary['train'],\n",
    "    type = 'train'\n",
    ")\n",
    "\n",
    "plot_patient_patches_paired(\n",
    "    pdf_filename=\"Pdf_SNN/Valid_Patches_SemReconstrucao_Pareamento.pdf\",\n",
    "    patients=valid_patients,\n",
    "    images_left=valid_left_balanced,\n",
    "    images_right=valid_right_balanced,\n",
    "    masks_left=mask_valid_left,\n",
    "    masks_right=mask_valid_right,\n",
    "    labels_true=y_valid_balanced,\n",
    "    labels_pred=y_pred_valid,\n",
    "    balanced_index_by_patients=paired_index_dictionary['val'],\n",
    "    type = 'val'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
