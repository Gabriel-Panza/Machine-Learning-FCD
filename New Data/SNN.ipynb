{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa todas as bibliotecas\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models, callbacks, metrics, Input, Model, regularizers\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, auc, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para carregar as imagens já pré-processadas e calcular os labels\n",
    "def calculate_label(image, threshold=0.04):\n",
    "    \"\"\"\n",
    "    Determina o label da subimagem com base no percentual de fundo não-preto.\n",
    "    :param subimage: Array da subimagem.\n",
    "    :param threshold: Percentual mínimo de fundo não-preto para considerar como label 1.\n",
    "    :return: String indicando o label.\n",
    "    \"\"\"\n",
    "    # Total de pixels na subimagem\n",
    "    total_pixels = image.size\n",
    "    # Número de pixels não-preto\n",
    "    non_zero_pixels = np.count_nonzero(image)\n",
    "    # Proporção de pixels não-preto\n",
    "    non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    \n",
    "    # Verifica se há lesão e se o fundo não-preto é maior que o limiar\n",
    "    if np.any(image == 1) and non_black_ratio >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def load_patient_data(folder, patient_id):\n",
    "    \"\"\"\n",
    "    Carrega os dados de um único paciente (imagens, máscaras e labels) de um diretório.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Caminho da pasta contendo os dados dos pacientes.\n",
    "        patient_id (str): ID do paciente a ser carregado.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dados do paciente, incluindo imagens, máscaras e labels para os lados esquerdo e direito.\n",
    "              Retorna None se o paciente não for encontrado.\n",
    "    \"\"\"\n",
    "    patient_path = os.path.join(folder, patient_id)\n",
    "    if not os.path.exists(patient_path):\n",
    "        print(f\"Paciente {patient_id} não encontrado na pasta {folder}.\")\n",
    "        return None\n",
    "\n",
    "    # Inicializa estruturas para armazenar os dados do paciente\n",
    "    patient_data = {\n",
    "        \"images_left\": [],\n",
    "        \"images_right\": [],\n",
    "        \"mask_left\": [],\n",
    "        \"mask_right\": [],\n",
    "        \"labels_left\": [],\n",
    "        \"labels_right\": [],\n",
    "    }\n",
    "\n",
    "    areas_image = [\"left\", \"right\"]\n",
    "    areas_mask = [\"lesion_left\", \"lesion_right\"]\n",
    "    path_left = os.path.join(patient_path, areas_image[0])\n",
    "    path_right = os.path.join(patient_path, areas_image[1])\n",
    "    lesion_path_left = os.path.join(patient_path, areas_mask[0])\n",
    "    lesion_path_right = os.path.join(patient_path, areas_mask[1])\n",
    "\n",
    "    # Verifica se os diretórios existem\n",
    "    if not os.path.exists(path_left) or not os.path.exists(path_right) or \\\n",
    "       not os.path.exists(lesion_path_left) or not os.path.exists(lesion_path_right):\n",
    "        print(f\"Estrutura de diretórios inválida para o paciente {patient_id}.\")\n",
    "        return None\n",
    "\n",
    "    # Carrega as imagens e máscaras do lado esquerdo e direito\n",
    "    for patch_id_left, mask_id_left, patch_id_right, mask_id_right in zip(\n",
    "        os.listdir(path_left), os.listdir(lesion_path_left),\n",
    "        os.listdir(path_right), os.listdir(lesion_path_right)\n",
    "    ):\n",
    "        img_path_left = os.path.join(path_left, patch_id_left)\n",
    "        mask_path_left = os.path.join(lesion_path_left, mask_id_left)\n",
    "        img_path_right = os.path.join(path_right, patch_id_right)\n",
    "        mask_path_right = os.path.join(lesion_path_right, mask_id_right)\n",
    "\n",
    "        for img_left, msk_left, img_right, msk_right in zip(\n",
    "            os.listdir(img_path_left), os.listdir(mask_path_left),\n",
    "            os.listdir(img_path_right), os.listdir(mask_path_right)\n",
    "        ):\n",
    "            # Carrega os dados do lado esquerdo\n",
    "            data_left = nib.load(os.path.join(img_path_left, img_left)).get_fdata()\n",
    "            data_msk_left = nib.load(os.path.join(mask_path_left, msk_left)).get_fdata()\n",
    "            if len(data_left) > 0 or len(data_msk_left) > 0:\n",
    "                patient_data[\"images_left\"].append(data_left)\n",
    "                patient_data[\"mask_left\"].append(data_msk_left)\n",
    "                patient_data[\"labels_left\"].append(calculate_label(data_msk_left))\n",
    "\n",
    "            # Carrega os dados do lado direito\n",
    "            data_right = nib.load(os.path.join(img_path_right, img_right)).get_fdata()\n",
    "            data_msk_right = nib.load(os.path.join(mask_path_right, msk_right)).get_fdata()\n",
    "            if len(data_right) > 0 or len(data_msk_right) > 0:\n",
    "                patient_data[\"images_right\"].append(data_right)\n",
    "                patient_data[\"mask_right\"].append(data_msk_right)\n",
    "                patient_data[\"labels_right\"].append(calculate_label(data_msk_right))\n",
    "\n",
    "    # Gera os pares de labels\n",
    "    labels_pair = []\n",
    "    for label_left, label_right in zip(patient_data[\"labels_left\"], patient_data[\"labels_right\"]):\n",
    "        if label_left == 0 and label_right == 0:\n",
    "            labels_pair.append(0)\n",
    "        else:\n",
    "            labels_pair.append(1)\n",
    "    patient_data[\"labels_pair\"] = labels_pair\n",
    "\n",
    "    print(f\"Paciente {patient_id} carregado com sucesso.\")\n",
    "    print(f\"Total de recortes: {len(labels_pair)}\")\n",
    "    return patient_data, labels_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar entre 0 e 1\n",
    "def normalize_minmax(image_data): \n",
    "    min_val = np.min(image_data)\n",
    "    max_val = np.max(image_data)\n",
    "    normalized_data = (image_data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def augment_image(img_left, img_right, mask_left, mask_right):\n",
    "    \"\"\"\n",
    "    Gera 7 variações (exceto a imagem original) aplicando:\n",
    "    - rotação 180°\n",
    "    - flip vertical\n",
    "    - troca de lado\n",
    "    \"\"\"\n",
    "\n",
    "    def rotate_180(img): return ndi.rotate(img, 180, reshape=False, mode='nearest')\n",
    "    def flip_vertical(img): return np.fliplr(img)\n",
    "\n",
    "    results_left = []\n",
    "    masks_left = []\n",
    "    results_right = []\n",
    "    masks_right = []\n",
    "    \n",
    "    # Todas as combinações possíveis, exceto a (False, False, False)\n",
    "    for rotate in [False, True]:\n",
    "        for flip in [False, True]:\n",
    "            for swap in [False, True]:\n",
    "                if not (rotate or flip or swap):  # pula a imagem padrão\n",
    "                    continue\n",
    "\n",
    "                l_img = img_left.copy()\n",
    "                r_img = img_right.copy()\n",
    "                l_mask = mask_left.copy()\n",
    "                r_mask = mask_right.copy()\n",
    "\n",
    "                if rotate:\n",
    "                    l_img = rotate_180(l_img)\n",
    "                    r_img = rotate_180(r_img)\n",
    "                    l_mask = rotate_180(l_mask)\n",
    "                    r_mask = rotate_180(r_mask)\n",
    "\n",
    "                if flip:\n",
    "                    l_img = flip_vertical(l_img)\n",
    "                    r_img = flip_vertical(r_img)\n",
    "                    l_mask = flip_vertical(l_mask)\n",
    "                    r_mask = flip_vertical(r_mask)\n",
    "\n",
    "                if swap:\n",
    "                    l_img, r_img = r_img, l_img\n",
    "                    l_mask, r_mask = r_mask, l_mask\n",
    "\n",
    "                results_left.append(l_img)\n",
    "                masks_left.append(l_mask)\n",
    "                results_right.append(r_img)\n",
    "                masks_right.append(r_mask)\n",
    "\n",
    "    return results_left, results_right, masks_left, masks_right\n",
    "            \n",
    "# Função para filtrar as imagens por paciente\n",
    "def select_by_patients(patients, all_images_original, all_images_opposite, all_labels):\n",
    "    selected_images_original = {}\n",
    "    selected_images_opposite = {}\n",
    "    selected_labels = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        selected_images_original[patient] = []\n",
    "        selected_images_opposite[patient] = []\n",
    "        if patient in all_images_original and patient in all_images_opposite:\n",
    "            selected_images_original[patient].extend(all_images_original[patient])\n",
    "            selected_images_opposite[patient].extend(all_images_opposite[patient])\n",
    "            selected_labels.extend(all_labels[patient])\n",
    "        else:\n",
    "            print(f\"Paciente {patient} não encontrado em uma das listas de imagens.\")\n",
    "    \n",
    "    return selected_images_original, selected_images_opposite, selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados para treino e validação\n",
    "def prepare_data_for_training(images_left, images_right, labels_pair, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_left = {}\n",
    "    balanced_images_right = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_left = {}\n",
    "    balanced_mask_right = {}\n",
    "    balanced_index_patients = {}\n",
    "\n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    train_patients = ['sub-02A13', 'sub-03C08', 'sub-06C09', 'sub-14F04', 'sub-16E03', 'sub-16G09', 'sub-16I12', 'sub-19F09', 'sub-19G04', 'sub-22F14', 'sub-26B09', 'sub-31F07', 'sub-35E12', 'sub-36K02', 'sub-41D08', 'sub-51C05', 'sub-52K04', 'sub-57D04', 'sub-59G00', 'sub-60G13', 'sub-60K04', 'sub-71C07', 'sub-72I02', 'sub-72K02', 'sub-76E02', 'sub-76J09', 'sub-83K08', 'sub-85I05', 'sub-86B13']\n",
    "    valid_patients = ['sub-00H10', 'sub-25B08', 'sub-29D03', 'sub-34J06', 'sub-56E13', 'sub-59E09', 'sub-60G06', 'sub-79H07']\n",
    "    test_patients = ['sub-42B05', 'sub-42K06', 'sub-44H05', 'sub-86G08']\n",
    "\n",
    "    # patients = list(set(images_left.keys()))\n",
    "    # train_patients, valtest_patients = train_test_split(patients, train_size = train_size+0.01)\n",
    "    # valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "    \n",
    "    print(len(train_patients) + len(valid_patients) + len(test_patients))\n",
    "    \n",
    "    class_1_left = {}\n",
    "    class_0_left = {}\n",
    "    class_1_right = {}\n",
    "    class_0_right = {}\n",
    "    class_1_mask_left = {}\n",
    "    class_0_mask_left = {}\n",
    "    class_1_mask_right = {}\n",
    "    class_0_mask_right = {}\n",
    "    class_1_coordinates = {}\n",
    "    class_0_coordinates = {}\n",
    "    \n",
    "    for patient_id in images_left:\n",
    "        class_1_labels = []\n",
    "        class_0_labels = []\n",
    "        class_1_left[patient_id] = []\n",
    "        class_0_left[patient_id] = []\n",
    "        class_1_right[patient_id] = []\n",
    "        class_0_right[patient_id] = []\n",
    "        class_1_mask_left[patient_id] = []\n",
    "        class_0_mask_left[patient_id] = []\n",
    "        class_1_mask_right[patient_id] = []\n",
    "        class_0_mask_right[patient_id] = []\n",
    "        class_1_coordinates[patient_id] = []\n",
    "        class_0_coordinates[patient_id] = []\n",
    "        index = 0\n",
    "        seed = hash(patient_id) % (2**32)  # Gera uma seed única por paciente\n",
    "        rng = np.random.default_rng(seed)\n",
    "        \n",
    "        if len(labels_pair[patient_id]) == 0:\n",
    "            continue\n",
    "        \n",
    "        if patient_id in test_patients:\n",
    "            balanced_images_left[patient_id] = images_left[patient_id]\n",
    "            balanced_images_right[patient_id] = images_right[patient_id]\n",
    "            balanced_labels[patient_id] = labels_pair[patient_id]\n",
    "            balanced_mask_left[patient_id] = mask_left[patient_id]\n",
    "            balanced_mask_right[patient_id] = mask_right[patient_id]\n",
    "            continue\n",
    "        \n",
    "        # Iterar sobre os patches e dividir as classes 0 e 1 com base nas labels\n",
    "        for label in labels_pair[patient_id]:\n",
    "            image_left = (images_left[patient_id])[index]\n",
    "            image_right = (images_right[patient_id])[index]\n",
    "            mask_image_left = (mask_left[patient_id])[index]\n",
    "            mask_image_right = (mask_right[patient_id])[index]\n",
    "            index += 1\n",
    "            \n",
    "            if label == 1:\n",
    "                class_1_labels.append(label)\n",
    "                class_1_left[patient_id].append(image_left)\n",
    "                class_1_right[patient_id].append(image_right)\n",
    "                class_1_mask_left[patient_id].append(mask_image_left)\n",
    "                class_1_mask_right[patient_id].append(mask_image_right)\n",
    "            else:\n",
    "                class_0_labels.append(label)\n",
    "                class_0_left[patient_id].append(image_left)\n",
    "                class_0_right[patient_id].append(image_right)\n",
    "                class_0_mask_left[patient_id].append(mask_image_left)\n",
    "                class_0_mask_right[patient_id].append(mask_image_right)\n",
    "        \n",
    "        class_1_count = len(class_1_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com label 1: {class_1_count}\")\n",
    "        class_0_count = len(class_0_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com label 0: {class_0_count}\")\n",
    "\n",
    "        # Fazer Uppersampling da classe minoritária (label 1) para igualar ao número de exemplos da classe 0\n",
    "        print(f\"Paciente {patient_id}: Total de patches classe 1 antes do uppersampling: {class_1_count}\")\n",
    "        \n",
    "        # # Se a classe 1 for menor, aplicamos data augmentation\n",
    "        # if class_1_count < class_0_count:\n",
    "        #     augmented_images_left = []\n",
    "        #     augmented_images_right = []\n",
    "        #     augmented_masks_left = []\n",
    "        #     augmented_masks_right = []\n",
    "\n",
    "        #     for idx, elem in enumerate(class_1_left[patient_id]):\n",
    "        #         imgs_left_aug, imgs_right_aug, masks_left_aug, masks_right_aug = augment_image(class_0_left[patient_id][idx], class_0_right[patient_id][idx], class_0_mask_left[patient_id][idx], class_0_mask_right[patient_id][idx])\n",
    "            \n",
    "        #         augmented_images_left.extend(imgs_left_aug)\n",
    "        #         augmented_images_right.extend(imgs_right_aug)\n",
    "        #         augmented_masks_left.extend(masks_left_aug)\n",
    "        #         augmented_masks_right.extend(masks_right_aug)\n",
    "\n",
    "        #     # Adiciona os dados aumentados\n",
    "        #     class_1_left[patient_id].extend(augmented_images_left)\n",
    "        #     class_1_right[patient_id].extend(augmented_images_right)\n",
    "        #     class_1_mask_left[patient_id].extend(augmented_masks_left)\n",
    "        #     class_1_mask_right[patient_id].extend(augmented_masks_right)\n",
    "        #     class_1_labels.extend([1] * (class_1_count*7))\n",
    "            \n",
    "        # class_1_count = len(class_1_labels)\n",
    "        # print(f\"Paciente {patient_id}: Total de patches classe 1 depois do uppersampling: {class_1_count}\")\n",
    "        \n",
    "        # Fazer undersampling aleatório da classe majoritária (label 0) para igualar ao número de exemplos da classe 1\n",
    "        class_0_count = len(class_0_labels)\n",
    "        if class_0_count > class_1_count:\n",
    "            sampled_indices = rng.choice(len(class_0_left[patient_id]), class_1_count, replace=False)\n",
    "            sampled_class_0_slices_left = [class_0_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_slices_right = [class_0_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_original_modified = {}\n",
    "            class_0_original_modified[patient_id] = []\n",
    "            class_0_opposite_modified = {}\n",
    "            class_0_opposite_modified[patient_id] = []\n",
    "            sampled_class_0_mask_left = [class_0_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_mask_right = [class_0_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_mask_original_modified = {}\n",
    "            class_0_mask_original_modified[patient_id] = []\n",
    "            class_0_mask_opposite_modified = {}\n",
    "            class_0_mask_opposite_modified[patient_id] = []\n",
    "            \n",
    "            for left_image, left_mask in zip(sampled_class_0_slices_left, sampled_class_0_mask_left):\n",
    "                class_0_original_modified[patient_id].append(left_image)\n",
    "                class_0_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_0_slices_right, sampled_class_0_mask_right):\n",
    "                class_0_opposite_modified[patient_id].append(right_image)\n",
    "                class_0_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_0_left = class_0_original_modified\n",
    "            class_0_right = class_0_opposite_modified\n",
    "            class_0_mask_left = class_0_mask_original_modified\n",
    "            class_0_mask_right = class_0_mask_opposite_modified\n",
    "            class_0_labels = [0] * (class_1_count)\n",
    "        else:\n",
    "            sampled_indices = rng.choice(len(class_1_left[patient_id]), class_0_count, replace=False)\n",
    "            sampled_class_1_slices_left = [class_1_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_1_slices_right = [class_1_right[patient_id][i] for i in sampled_indices]\n",
    "            class_1_original_modified = {}\n",
    "            class_1_original_modified[patient_id] = []\n",
    "            class_1_opposite_modified = {}\n",
    "            class_1_opposite_modified[patient_id] = []\n",
    "            sampled_class_1_mask_left = [class_1_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_1_mask_right = [class_1_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_1_mask_original_modified = {}\n",
    "            class_1_mask_original_modified[patient_id] = []\n",
    "            class_1_mask_opposite_modified = {}\n",
    "            class_1_mask_opposite_modified[patient_id] = []\n",
    "\n",
    "            for left_image, left_mask in zip(sampled_class_1_slices_left, sampled_class_1_mask_left):\n",
    "                class_1_original_modified[patient_id].append(left_image)\n",
    "                class_1_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_1_slices_right, sampled_class_1_mask_right):\n",
    "                class_1_opposite_modified[patient_id].append(right_image)\n",
    "                class_1_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_1_left = class_1_original_modified\n",
    "            class_1_right = class_1_opposite_modified\n",
    "            class_1_mask_left = class_1_mask_original_modified\n",
    "            class_1_mask_right = class_1_mask_opposite_modified\n",
    "            class_1_labels = [1] * (class_0_count)\n",
    "        \n",
    "        print(len(class_1_left[patient_id]))\n",
    "        print(len(class_1_right[patient_id]))\n",
    "        print(len(class_1_labels))\n",
    "        \n",
    "        balanced_images_left[patient_id] = class_1_left[patient_id][:] + class_0_left[patient_id][:]\n",
    "        balanced_images_right[patient_id] = class_1_right[patient_id][:] + class_0_right[patient_id][:]\n",
    "        balanced_labels[patient_id] = class_1_labels + class_0_labels\n",
    "        balanced_mask_left[patient_id] = class_1_mask_left[patient_id][:] + class_0_mask_left[patient_id][:]\n",
    "        balanced_mask_right[patient_id] = class_1_mask_right[patient_id][:] + class_0_mask_right[patient_id][:]\n",
    "        \n",
    "        balanced_index = rng.choice(range(len(balanced_labels[patient_id])), len(balanced_labels[patient_id]), replace=False)            \n",
    "        balanced_images_left[patient_id] = [balanced_images_left[patient_id][i] for i in balanced_index]\n",
    "        balanced_images_right[patient_id] = [balanced_images_right[patient_id][i] for i in balanced_index]\n",
    "        balanced_labels[patient_id] = [balanced_labels[patient_id][i] for i in balanced_index]\n",
    "        balanced_mask_left[patient_id] = [balanced_mask_left[patient_id][i] for i in balanced_index]\n",
    "        balanced_mask_right[patient_id] = [balanced_mask_right[patient_id][i] for i in balanced_index]\n",
    "        balanced_index_patients[patient_id] = balanced_index\n",
    "    \n",
    "        class_1_count = len(class_1_labels)\n",
    "        class_0_count = len(class_0_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de patches no final: {class_1_count+class_0_count}\")\n",
    "\n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_left, balanced_images_right, balanced_labels)\n",
    "    \n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, X_test_original, X_test_opposite, np.array(y_train), np.array(y_val), np.array(y_test), train_patients, valid_patients, test_patients, balanced_mask_left, balanced_mask_right, balanced_index_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir o modelo CNN 2D\n",
    "def build_cnn_model_backup():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(8, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((3,3)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(layers.Conv2D(16, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((3,3)))\n",
    "    model.add(layers.Dropout(0.4)) \n",
    "     \n",
    "    model.add(layers.Conv2D(32, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((3,3)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((3,3)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir a rede siamesa\n",
    "def build_siamese_model(input_shape):\n",
    "    input_original = Input(shape=input_shape)\n",
    "    input_opposite = Input(shape=input_shape)\n",
    "\n",
    "    # Criar a CNN base compartilhada\n",
    "    cnn_base = build_cnn_model_backup()\n",
    "    \n",
    "    # Aplicar a mesma CNN base para ambas as entradas\n",
    "    output_original = cnn_base(input_original)\n",
    "    output_opposite = cnn_base(input_opposite)\n",
    "\n",
    "    # Calcula a diferença absoluta\n",
    "    # l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([output_original, output_opposite])\n",
    "\n",
    "    # Subtrair as duas saídas (Lado esquerdo - Contra-lateral)\n",
    "    subtracted = layers.Subtract()([output_original, output_opposite])\n",
    "    subtracted = layers.BatchNormalization()(subtracted)\n",
    "\n",
    "    # Concatenar as duas saídas (Lado esquerdo + Contra-lateral)\n",
    "    # concatenated = layers.Concatenate()([output_original, output_opposite])\n",
    "    # concatenated = layers.BatchNormalization()(concatenated)\n",
    "    \n",
    "    # Passar o resultado pela rede densa\n",
    "    subtracted = layers.Dense(64, activation='relu')(subtracted)\n",
    "    subtracted = layers.Dropout(0.4)(subtracted)\n",
    "    subtracted = layers.Dense(32, activation='relu')(subtracted)\n",
    "    subtracted = layers.Dropout(0.4)(subtracted)\n",
    "\n",
    "    output = layers.Dense(1, activation='sigmoid')(subtracted)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_original, input_opposite], outputs=output)\n",
    "    siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy', metrics.Precision(name=\"precision\"), metrics.Recall(name=\"recall\")])\n",
    "\n",
    "    return siamese_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot do treinamento do modelo\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot da matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho da pasta contendo os dados dos pacientes\n",
    "folder = \"Novo_Contralateral\"\n",
    "\n",
    "# Lista de IDs dos pacientes\n",
    "patient_ids = os.listdir(folder)\n",
    "\n",
    "X_left, X_right, y, mask_left, mask_right = {}, {}, {}, {}, {}\n",
    "\n",
    "# Processa um paciente por vez\n",
    "for patient_id in patient_ids:\n",
    "    # Carrega os dados do paciente\n",
    "    patient_data, labels_pair = load_patient_data(folder, patient_id)\n",
    "    \n",
    "    if patient_data is not None:\n",
    "        X_left[patient_id] = patient_data[\"images_left\"]\n",
    "        X_right[patient_id] = patient_data[\"images_right\"]\n",
    "        mask_left[patient_id] = patient_data[\"mask_left\"]\n",
    "        mask_right[patient_id] = patient_data[\"mask_right\"]\n",
    "        y[patient_id] = labels_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para treino, validação e teste\n",
    "train_left_balanced, train_right_balanced, valid_left_balanced, valid_right_balanced, test_left, test_right, y_train_balanced, y_valid_balanced, y_test, train_patients, valid_patients, test_patients, balanced_mask_left, balanced_mask_right, balanced_index_patients = prepare_data_for_training(X_left, X_right, y, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciono camada de cor\n",
    "train_left_balanced = normalize_minmax(np.array([elemento for lista in train_left_balanced.values() for elemento in lista]))\n",
    "train_left_balanced = np.expand_dims(train_left_balanced, axis=-1)\n",
    "train_right_balanced = normalize_minmax(np.array([elemento for lista in train_right_balanced.values() for elemento in lista]))\n",
    "train_right_balanced = np.expand_dims(train_right_balanced, axis=-1)\n",
    "valid_left_balanced = normalize_minmax(np.array([elemento for lista in valid_left_balanced.values() for elemento in lista]))\n",
    "valid_left_balanced = np.expand_dims(valid_left_balanced, axis=-1)\n",
    "valid_right_balanced = normalize_minmax(np.array([elemento for lista in valid_right_balanced.values() for elemento in lista]))\n",
    "valid_right_balanced = np.expand_dims(valid_right_balanced, axis=-1)\n",
    "test_left = normalize_minmax(np.array([elemento for lista in test_left.values() for elemento in lista]))\n",
    "test_left = np.expand_dims(test_left, axis=-1)\n",
    "test_right = normalize_minmax(np.array([elemento for lista in test_right.values() for elemento in lista]))\n",
    "test_right = np.expand_dims(test_right, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir e compilar o modelo CNN\n",
    "input_shape = (train_left_balanced[0].shape)\n",
    "\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o callback EarlyStopping e low rate scheduler\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
    "\n",
    "# Ajusta learning rate\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(factor=0.8, patience=15, verbose=1)\n",
    "\n",
    "# Suponha que seus rótulos estejam em y_train_balanced\n",
    "# classes = np.unique(y_valid_balanced)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_valid_balanced)\n",
    "# class_weight_dict = dict(zip(classes, weights))\n",
    "\n",
    "# Salvar a melhor epoca\n",
    "checkpoint = callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True,  save_weights_only=True, mode='min')\n",
    "\n",
    "# Treinamento do modelo siames\n",
    "history = siamese_model.fit([train_left_balanced, train_right_balanced], y_train_balanced, validation_data=([valid_left_balanced, valid_right_balanced], y_valid_balanced), batch_size=128, epochs=150, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o histórico do treinamento\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando pesos da melhor época\n",
    "siamese_model.load_weights('best_model.h5')\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_train = (siamese_model.predict([train_left_balanced, train_right_balanced]) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (siamese_model.predict([valid_left_balanced, valid_right_balanced]) > 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (siamese_model.predict([test_left, test_right]) > 0.5).astype(int)\n",
    "\n",
    "# Calcula a curva precision-recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_test)\n",
    "\n",
    "# Calcula a AUC precision-recall\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Plote a curva precision-recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'AUC = {auc_pr:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o relatório de classificação\n",
    "print(\"Validação:\")\n",
    "print(classification_report(y_valid_balanced, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "#print(classification_report(y_test, y_pred_test)) \n",
    "print(classification_report(y_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(y_valid_balanced, y_pred_valid)\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "#plot_confusion_matrix(y_test, y_pred_test)\n",
    "plot_confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para adicionar borda ao patch com a cor da classificação\n",
    "def add_border(image, color, thickness=3):\n",
    "    image_normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    image_rgb = cv2.cvtColor(image_normalized, cv2.COLOR_GRAY2RGB)\n",
    "    bordered_image = cv2.copyMakeBorder(image_rgb, thickness, thickness, thickness, thickness, cv2.BORDER_CONSTANT, value=color)\n",
    "    return bordered_image\n",
    "\n",
    "# Função para carregar imagens no formato NIfTI (.nii.gz)\n",
    "def load_nii_slice(patient_id, slice_index, base_path):\n",
    "    file_path = os.path.join(base_path, patient_id, f\"Slice_{slice_index:03d}.nii.gz\")\n",
    "    if os.path.exists(file_path):\n",
    "        nii_img = nib.load(file_path)\n",
    "        img_data = nii_img.get_fdata()\n",
    "        return img_data\n",
    "    return None\n",
    "\n",
    "# Função para carregar coordenadas de arquivos .txt\n",
    "def load_coordinates(patient_id, slice_index, base_path):\n",
    "    coord_file = os.path.join(base_path, patient_id, f\"Slice_{slice_index:03d}.txt\")\n",
    "    if os.path.exists(coord_file):\n",
    "        with open(coord_file, \"r\") as file:\n",
    "            coordinates = [tuple(map(int, line.strip().split(\",\"))) for line in file]\n",
    "        return coordinates\n",
    "    return []\n",
    "\n",
    "# Função para reconstruir a imagem e sobrepor o grid\n",
    "def build_image_with_grid(patient_id, slice_index, labels_pred, labels_true, image_path, mask_path, coordinates_path, index):\n",
    "    img = load_nii_slice(patient_id, slice_index, image_path)\n",
    "    mask = load_nii_slice(patient_id, slice_index, mask_path)\n",
    "    coordinates = load_coordinates(patient_id, slice_index, coordinates_path)\n",
    "    \n",
    "    if img is None or mask is None or not coordinates:\n",
    "        return None, None, index\n",
    "    \n",
    "    reconstructed_img = np.zeros((233, 197, 3), dtype=np.uint8)\n",
    "    reconstructed_mask = np.zeros((233, 197, 3), dtype=np.uint8)\n",
    "    \n",
    "    colors = {\"TP\": (0, 255, 0), \"TN\": (150, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "    classifications = []\n",
    "    classifications_right = []\n",
    "    \n",
    "    # Determinar a classificação de cada patch\n",
    "    half = len(coordinates) // 2\n",
    "\n",
    "    if half == 1:\n",
    "        axs = [axs]  # Handle single patch pair case\n",
    "\n",
    "    for i in range(half):\n",
    "        if labels_pred[i+index] == labels_true[i+index]:\n",
    "            if labels_pred[i+index] == 1:\n",
    "                classification = \"TP\"\n",
    "            else:\n",
    "                classification = \"TN\"\n",
    "        else:\n",
    "            if labels_pred[i+index] == 1:\n",
    "                classification = \"FP\"\n",
    "            else:\n",
    "                classification = \"FN\"\n",
    "        classifications.append(classification)\n",
    "        classifications_right.append(classification)\n",
    "        \n",
    "    # Sincronizar classificações entre os lados do cérebro\n",
    "    classifications.extend(classifications_right)\n",
    "    \n",
    "    # Reconstruir a imagem com base nas classificações sincronizadas\n",
    "    for i, (y1, y2, x1, x2) in enumerate(coordinates):\n",
    "        classification = classifications[i]\n",
    "        \n",
    "        patch_img = img[y1+3:y2-3, x1+3:x2-3]\n",
    "        patch_mask = mask[y1+3:y2-3, x1+3:x2-3]\n",
    "        bordered_patch_img = add_border(patch_img, colors[classification])\n",
    "        bordered_patch_mask = add_border(patch_mask, colors[classification])\n",
    "        \n",
    "        # Inserir os patches na imagem reconstruída\n",
    "        reconstructed_img[y1:y2, x1:x2] = bordered_patch_img\n",
    "        reconstructed_mask[y1:y2, x1:x2] = bordered_patch_mask\n",
    "    \n",
    "    return reconstructed_img, reconstructed_mask, (index+half)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar PDF reconstruido\n",
    "def plot_patient_slices(pdf_filename, patients, coordinates_path, image_path, mask_path, labels_true, labels_pred):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "    \n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            for slice_index in range(test_patients_quantity[patient]):\n",
    "                img_recon, mask_recon, index = build_image_with_grid(patient, slice_index, labels_pred, labels_true, image_path, mask_path, coordinates_path, index)\n",
    "                \n",
    "                if img_recon is None:\n",
    "                    continue\n",
    "                \n",
    "                fig, axs = plt.subplots(2, 1, figsize=(6, 6))\n",
    "                axs[0].imshow(img_recon, cmap='gray')\n",
    "                axs[0].set_title(f'Paciente {patient} - Imagem')\n",
    "                axs[0].axis('off')\n",
    "                axs[1].imshow(mask_recon, cmap='gray')\n",
    "                axs[1].set_title(f'Paciente {patient} - Máscara')\n",
    "                axs[1].axis('off')\n",
    "                \n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "                \n",
    "        print(f\"As imagens foram salvas no arquivo PDF {pdf_filename} com sucesso.\")\n",
    "\n",
    "# Chamando a função para gerar o PDF\n",
    "test_patients_quantity = {'sub-42B05': 1204, 'sub-42K06': 1122, 'sub-44H05': 1213, 'sub-86G08': 1189}\n",
    "plot_patient_slices(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Reconstruidos_Com_Uppersampling.pdf\",\n",
    "    patients=test_patients,\n",
    "    coordinates_path=\"Coordenadas_grid\",\n",
    "    image_path=\"Fatias\",\n",
    "    mask_path=\"Mask_Fatias\",\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar PDF sem reconstruir\n",
    "def plot_patient_patches(pdf_filename, patients, coordinates_path, image_path, mask_path, labels_true, labels_pred):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "    \n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            for slice_index in range(test_patients_quantity[patient]):\n",
    "                img = load_nii_slice(patient, slice_index, image_path)\n",
    "                mask = load_nii_slice(patient, slice_index, mask_path)\n",
    "                coordinates = load_coordinates(patient, slice_index, coordinates_path)\n",
    "                \n",
    "                if img is None or mask is None or not coordinates:\n",
    "                    continue\n",
    "\n",
    "                colors = {\"TP\": (0, 255, 0), \"TN\": (150, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "                classifications = []\n",
    "                classifications_right = []\n",
    "                \n",
    "                # Determinar a classificação de cada patch\n",
    "                half = len(coordinates) // 2\n",
    "\n",
    "                if half == 1:\n",
    "                    axs = [axs]  # Handle single patch pair case\n",
    "\n",
    "                for i in range(half):\n",
    "                    if labels_pred[i+index] == labels_true[i+index]:\n",
    "                        if labels_pred[i+index] == 1:\n",
    "                            classification = \"TP\"\n",
    "                        else:\n",
    "                            classification = \"TN\"\n",
    "                    else:\n",
    "                        if labels_pred[i+index] == 1:\n",
    "                            classification = \"FP\"\n",
    "                        else:\n",
    "                            classification = \"FN\"\n",
    "                    classifications.append(classification)\n",
    "                    classifications_right.append(classification)\n",
    "\n",
    "                # Sincronizar classificações entre os lados do cérebro\n",
    "                classifications.extend(classifications_right)\n",
    "\n",
    "                half = len(coordinates) // 2\n",
    "                fig, axs = plt.subplots(half, 4, figsize=(8, half * 2))  # 2 patches per row: image + mask\n",
    "\n",
    "                if half == 1:\n",
    "                    axs = [axs]  # Handle single patch pair case\n",
    "\n",
    "                for i in range(half):\n",
    "                    # Get both contralateral patches\n",
    "                    (y1a, y2a, x1a, x2a) = coordinates[i]\n",
    "                    (y1b, y2b, x1b, x2b) = coordinates[i + half]\n",
    "\n",
    "                    patch_img_a = img[y1a+3:y2a-3, x1a+3:x2a-3]\n",
    "                    patch_mask_a = mask[y1a+3:y2a-3, x1a+3:x2a-3]\n",
    "\n",
    "                    patch_img_b = img[y1b+3:y2b-3, x1b+3:x2b-3]\n",
    "                    patch_mask_b = mask[y1b+3:y2b-3, x1b+3:x2b-3]\n",
    "\n",
    "                    classification_a = classifications[i]\n",
    "                    classification_b = classifications[i + half]\n",
    "\n",
    "                    color_a = colors[classification_a]\n",
    "                    color_b = colors[classification_b]\n",
    "\n",
    "                    bordered_img_a = add_border(patch_img_a, color_a)\n",
    "                    bordered_mask_a = add_border(patch_mask_a, color_a)\n",
    "\n",
    "                    bordered_img_b = add_border(patch_img_b, color_b)\n",
    "                    bordered_mask_b = add_border(patch_mask_b, color_b)\n",
    "\n",
    "                    # Left patch (image + mask)\n",
    "                    axs[i][0].imshow(bordered_img_a)\n",
    "                    axs[i][0].set_title(f\"Patch left - {classification_a}\")\n",
    "                    axs[i][0].axis(\"off\")\n",
    "\n",
    "                    axs[i][2].imshow(bordered_mask_a)\n",
    "                    axs[i][2].set_title(f\"Mask left - {classification_a}\")\n",
    "                    axs[i][2].axis(\"off\")\n",
    "\n",
    "                    # Right patch (image + mask)\n",
    "                    axs[i][1].imshow(bordered_img_b)\n",
    "                    axs[i][1].set_title(f\"Patch right - {classification_b}\")\n",
    "                    axs[i][1].axis(\"off\")\n",
    "\n",
    "                    axs[i][3].imshow(bordered_mask_b)\n",
    "                    axs[i][3].set_title(f\"Mask right - {classification_b}\")\n",
    "                    axs[i][3].axis(\"off\")\n",
    "\n",
    "                fig.suptitle(f\"Paciente {patient} - Fatia {slice_index}\")\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "                index += half\n",
    "\n",
    "        print(f\"Patches com bordas salvos em {pdf_filename}\")\n",
    "\n",
    "plot_patient_patches(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Patches_SemReconstrucao_Com_Uppersampling.pdf\",\n",
    "    patients=test_patients,\n",
    "    coordinates_path=\"Coordenadas_grid\",\n",
    "    image_path=\"Fatias\",\n",
    "    mask_path=\"Mask_Fatias\",\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar PDF sem reconstruir\n",
    "def plot_patient_patches_balanced(pdf_filename, patients, images_left, images_right, masks_left, masks_right, labels_true, labels_pred, balanced_index_by_patients):\n",
    "    os.makedirs(os.path.dirname(pdf_filename), exist_ok=True)\n",
    "    \n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        index = 0\n",
    "        for patient in patients:\n",
    "            print(f\"\\n🔍 Paciente: {patient}\")\n",
    "            indices = balanced_index_by_patients.get(patient, [])\n",
    "            print(f\"📊 Número de pares após undersampling: {len(indices)}\")\n",
    "            for i in range (len(indices)):\n",
    "                colors = {\"TP\": (0, 255, 0), \"TN\": (150, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}\n",
    "                classifications = []\n",
    "                \n",
    "                if labels_pred[i+index] == labels_true[i+index]:\n",
    "                    if labels_pred[i+index] == 1:\n",
    "                        classification = \"TP\"\n",
    "                    else:\n",
    "                        classification = \"TN\"\n",
    "                else:\n",
    "                    if labels_pred[i+index] == 1:\n",
    "                        classification = \"FP\"\n",
    "                    else:\n",
    "                        classification = \"FN\"\n",
    "                classifications.append(classification)\n",
    "\n",
    "                color = colors[classification]\n",
    "\n",
    "                # Pega patches esquerdo e direito e máscaras\n",
    "                patch_left = images_left[i+index]\n",
    "                patch_right = images_right[i+index]\n",
    "                mask_l = masks_left[patient][i]\n",
    "                mask_r = masks_right[patient][i]\n",
    "\n",
    "                # Aplica borda nos patches e máscaras\n",
    "                bordered_patch_left = add_border(patch_left, color)\n",
    "                bordered_patch_right = add_border(patch_right, color)\n",
    "                bordered_mask_left = add_border(mask_l, color)\n",
    "                bordered_mask_right = add_border(mask_r, color)\n",
    "\n",
    "                # Plotagem\n",
    "                fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "                axs[0, 0].imshow(bordered_patch_left)\n",
    "                axs[0, 0].set_title(\"Img Esq\")\n",
    "                axs[0, 1].imshow(bordered_patch_right)\n",
    "                axs[0, 1].set_title(\"Img Dir\")\n",
    "                axs[1, 0].imshow(bordered_mask_left)\n",
    "                axs[1, 0].set_title(\"Mask Esq\")\n",
    "                axs[1, 1].imshow(bordered_mask_right)\n",
    "                axs[1, 1].set_title(\"Mask Dir\")\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.axis('off')\n",
    "\n",
    "                fig.suptitle(f\"Paciente: {patient}\", fontsize=10)\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "            index += len(indices)\n",
    "\n",
    "        print(f\"Patches com bordas salvos em {pdf_filename}\")\n",
    "\n",
    "plot_patient_patches_balanced(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Train_Patches_SemReconstrucao_Uppersampling.pdf\",\n",
    "    patients=train_patients,\n",
    "    images_left=train_left_balanced,\n",
    "    images_right=train_right_balanced,\n",
    "    masks_left=balanced_mask_left,\n",
    "    masks_right=balanced_mask_right,\n",
    "    labels_true=y_train_balanced,\n",
    "    labels_pred=y_pred_train,\n",
    "    balanced_index_by_patients=balanced_index_patients\n",
    ")\n",
    "\n",
    "plot_patient_patches_balanced(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Valid_Patches_SemReconstrucao_Uppersampling.pdf\",\n",
    "    patients=valid_patients,\n",
    "    images_left=valid_left_balanced,\n",
    "    images_right=valid_right_balanced,\n",
    "    masks_left=balanced_mask_left,\n",
    "    masks_right=balanced_mask_right,\n",
    "    labels_true=y_valid_balanced,\n",
    "    labels_pred=y_pred_valid,\n",
    "    balanced_index_by_patients=balanced_index_patients\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
