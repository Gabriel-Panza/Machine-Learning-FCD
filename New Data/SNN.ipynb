{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models, callbacks, metrics, Input, Model, regularizers\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_label(image, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Determina o label da subimagem com base no percentual de fundo não-preto.\n",
    "    :param subimage: Array da subimagem.\n",
    "    :param threshold: Percentual mínimo de fundo não-preto para considerar como label 1.\n",
    "    :return: String indicando o label.\n",
    "    \"\"\"\n",
    "    # Total de pixels na subimagem\n",
    "    total_pixels = image.size\n",
    "    # Número de pixels não-preto\n",
    "    non_zero_pixels = np.count_nonzero(image)\n",
    "    # Proporção de pixels não-preto\n",
    "    non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    \n",
    "    # Verifica se há lesão e se o fundo não-preto é maior que o limiar\n",
    "    if np.any(image == 1) and non_black_ratio >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Função para carregar as coordenadas dos arquivos txt\n",
    "def load_coordinates(coordinates_path):\n",
    "    coordinates = {}\n",
    "    for patient_id in os.listdir(coordinates_path):\n",
    "        patient_path = os.path.join(coordinates_path, patient_id)\n",
    "        coordinates[patient_id] = []\n",
    "        for slice_file in sorted(os.listdir(patient_path)):\n",
    "            slice_path = os.path.join(patient_path, slice_file)\n",
    "            with open(slice_path, 'r') as f:\n",
    "                coords = [tuple(map(int, line.strip().split(','))) for line in f.readlines()]\n",
    "                coordinates[patient_id].append(coords)\n",
    "    return coordinates\n",
    "\n",
    "# Função que carrega os dados com pares de imagens\n",
    "def load_data_with_pairs(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"A pasta {folder} não existe.\")\n",
    "        return {}, {}, {}, {}, {}\n",
    "    \n",
    "    images_left = {}\n",
    "    images_right = {}\n",
    "    mask_left = {}\n",
    "    mask_right = {}\n",
    "    labels_left = {}\n",
    "    labels_right = {}\n",
    "    patient_ids = []\n",
    "\n",
    "    # Itera sobre os pacientes no diretório\n",
    "    for patient_id in tqdm(os.listdir(folder), desc=\"Carregamento de arquivos NIfTI...\"):\n",
    "        patient_path = os.path.join(folder, patient_id)\n",
    "\n",
    "        areas_image = [\"left\", \"right\"]\n",
    "        areas_mask = [\"lesion_left\", \"lesion_right\"]\n",
    "        path_left = os.path.join(patient_path, areas_image[0])\n",
    "        path_right = os.path.join(patient_path, areas_image[1])\n",
    "        lesion_path_left = os.path.join(patient_path, areas_mask[0])\n",
    "        lesion_path_right = os.path.join(patient_path, areas_mask[1])\n",
    "\n",
    "        if patient_id not in images_left:\n",
    "            images_left[patient_id] = []\n",
    "        if patient_id not in images_right:\n",
    "            images_right[patient_id] = []\n",
    "        if patient_id not in mask_left:\n",
    "            mask_left[patient_id] = []\n",
    "        if patient_id not in mask_right:\n",
    "            mask_right[patient_id] = []\n",
    "        if patient_id not in labels_left:\n",
    "            labels_left[patient_id] = []\n",
    "        if patient_id not in labels_right:\n",
    "            labels_right[patient_id] = []\n",
    "            \n",
    "        # Carrega as imagens e máscaras do lado esquerdo e direito\n",
    "        for patch_id_left, mask_id_left, patch_id_right, mask_id_right in zip(os.listdir(path_left), os.listdir(lesion_path_left), os.listdir(path_right), os.listdir(lesion_path_right)):\n",
    "            img_path_left = os.path.join(path_left, patch_id_left)\n",
    "            mask_path_left = os.path.join(lesion_path_left, mask_id_left)\n",
    "            img_path_right = os.path.join(path_right, patch_id_right)\n",
    "            mask_path_right = os.path.join(lesion_path_right, mask_id_right)\n",
    "             \n",
    "            for img_left, msk_left, img_right, msk_right in zip(os.listdir(img_path_left), os.listdir(mask_path_left), os.listdir(img_path_right), os.listdir(mask_path_right)):\n",
    "                data_left = nib.load(os.path.join(img_path_left, img_left)).get_fdata()\n",
    "                data_msk_left = nib.load(os.path.join(mask_path_left, msk_left)).get_fdata()\n",
    "                data_right = nib.load(os.path.join(img_path_right, img_right)).get_fdata()\n",
    "                data_msk_right = nib.load(os.path.join(mask_path_right, msk_right)).get_fdata()\n",
    "                        \n",
    "                if (len(data_left) > 0) or (len(data_msk_left) > 0):\n",
    "                    images_left[patient_id].append(data_left)\n",
    "                    mask_left[patient_id].append(data_msk_left)\n",
    "                    labels_left[patient_id].append(calculate_label(data_msk_left))\n",
    "                    \n",
    "                if (len(data_right) > 0) or (len(data_msk_right) > 0):\n",
    "                    images_right[patient_id].append(data_right)\n",
    "                    mask_right[patient_id].append(data_msk_right)\n",
    "                    labels_right[patient_id].append(calculate_label(data_msk_right))\n",
    "\n",
    "        patient_ids.append(patient_id)\n",
    "\n",
    "    # Estruturas para armazenar os pares de labels\n",
    "    labels_pair = {}\n",
    "    for patient_id,_ in zip(labels_left.keys(), labels_right.keys()):\n",
    "        labels_pair[patient_id] = []\n",
    "        for label_left, label_right in zip(labels_left[patient_id], labels_right[patient_id]): \n",
    "            if label_left == 0 and label_right == 0:\n",
    "                labels_pair[patient_id].append(0)\n",
    "            else:\n",
    "                labels_pair[patient_id].append(1)\n",
    "\n",
    "    print(f\"Total de pacientes: {len(patient_ids)}\")\n",
    "    for patient_id, labels in labels_pair.items():\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes: {len(labels)}\")\n",
    "\n",
    "    return images_left, images_right, labels_pair, mask_left, mask_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar entre 0 e 1\n",
    "def normalize_minmax(image_data): \n",
    "    min_val = np.min(image_data)\n",
    "    max_val = np.max(image_data)\n",
    "    normalized_data = (image_data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "# Função para filtrar as imagens por paciente\n",
    "def select_by_patients(patients, all_images_original, all_images_opposite, all_labels):\n",
    "    selected_images_original = {}\n",
    "    selected_images_opposite = {}\n",
    "    selected_labels = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        selected_images_original[patient] = []\n",
    "        selected_images_opposite[patient] = []\n",
    "        if patient in all_images_original and patient in all_images_opposite:\n",
    "            selected_images_original[patient].extend(all_images_original[patient])\n",
    "            selected_images_opposite[patient].extend(all_images_opposite[patient])\n",
    "            selected_labels.extend(all_labels[patient])\n",
    "        else:\n",
    "            print(f\"Paciente {patient} não encontrado em uma das listas de imagens.\")\n",
    "    \n",
    "    return selected_images_original, selected_images_opposite, selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados para treino e validação\n",
    "def prepare_data_for_training_balanced(images_left, images_right, labels_pair, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_original = {}\n",
    "    balanced_images_opposite = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_original = {}\n",
    "    balanced_mask_opposite = {}\n",
    "\n",
    "    for patient_id in images_left:\n",
    "        class_1_labels = []\n",
    "        class_0_labels = []\n",
    "        class_1_left = {}\n",
    "        class_0_left = {}\n",
    "        class_1_right = {}\n",
    "        class_0_right = {}\n",
    "        class_1_mask_left = {}\n",
    "        class_0_mask_left = {}\n",
    "        class_1_mask_right = {}\n",
    "        class_0_mask_right = {}\n",
    "        \n",
    "        class_1_left[patient_id] = []\n",
    "        class_0_left[patient_id] = []\n",
    "        class_1_right[patient_id] = []\n",
    "        class_0_right[patient_id] = []\n",
    "        class_1_mask_left[patient_id] = []\n",
    "        class_0_mask_left[patient_id] = []\n",
    "        class_1_mask_right[patient_id] = []\n",
    "        class_0_mask_right[patient_id] = []\n",
    "        index = 0\n",
    "        \n",
    "        # Iterar sobre os patches e dividir as classes 0 e 1 com base nas labels\\n\",\n",
    "        if len(labels_pair[patient_id]) == 0:\n",
    "            continue\n",
    "        for label in labels_pair[patient_id]:\n",
    "            image_left = (images_left[patient_id])[index]\n",
    "            image_right = (images_right[patient_id])[index]\n",
    "            mask_image_left = (mask_left[patient_id])[index]\n",
    "            mask_image_right = (mask_right[patient_id])[index]\n",
    "            index += 1\n",
    "            \n",
    "            if label == 1:\n",
    "                class_1_labels.append(label)\n",
    "                class_1_left[patient_id].append(image_left)\n",
    "                class_1_right[patient_id].append(image_right)\n",
    "                class_1_mask_left[patient_id].append(mask_image_left)\n",
    "                class_1_mask_right[patient_id].append(mask_image_right)\n",
    "            else:\n",
    "                class_0_labels.append(label)\n",
    "                class_0_left[patient_id].append(image_left)\n",
    "                class_0_right[patient_id].append(image_right)\n",
    "                class_0_mask_left[patient_id].append(mask_image_left)\n",
    "                class_0_mask_right[patient_id].append(mask_image_right)\n",
    "        class_1_count = len(class_1_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com labels 1: {class_1_count}\")\n",
    "\n",
    "        # Fazer undersampling aleatório da classe majoritária (label 0) para igualar ao número de exemplos da classe 1\n",
    "        class_0_count = len(class_0_labels)\n",
    "        if class_0_count > class_1_count:\n",
    "            sampled_indices = np.random.choice(range(class_0_count), class_1_count, replace=False)\n",
    "            sampled_class_0_slices_left = [class_0_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_slices_right = [class_0_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_original_modified = {}\n",
    "            class_0_original_modified[patient_id] = []\n",
    "            class_0_opposite_modified = {}\n",
    "            class_0_opposite_modified[patient_id] = []\n",
    "            sampled_class_0_mask_left = [class_0_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_mask_right = [class_0_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_mask_original_modified = {}\n",
    "            class_0_mask_original_modified[patient_id] = []\n",
    "            class_0_mask_opposite_modified = {}\n",
    "            class_0_mask_opposite_modified[patient_id] = []\n",
    "\n",
    "            for left_image, left_mask in zip(sampled_class_0_slices_left, sampled_class_0_mask_left):\n",
    "                class_0_original_modified[patient_id].append(left_image)\n",
    "                class_0_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_0_slices_right, sampled_class_0_mask_right):\n",
    "                class_0_opposite_modified[patient_id].append(right_image)\n",
    "                class_0_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_0_labels = [0] * class_1_count\n",
    "\n",
    "        balanced_images_original[patient_id] = list(class_1_left[patient_id]) + list(class_0_original_modified[patient_id])\n",
    "        balanced_images_opposite[patient_id] = list(class_1_right[patient_id]) + list(class_0_opposite_modified[patient_id])\n",
    "        balanced_labels[patient_id] = class_1_labels + class_0_labels\n",
    "        balanced_mask_original[patient_id] = list(class_1_mask_left[patient_id]) + list(class_0_mask_original_modified[patient_id])\n",
    "        balanced_mask_opposite[patient_id] = list(class_1_mask_right[patient_id]) + list(class_0_mask_opposite_modified[patient_id])\n",
    "    remove_patients = []\n",
    "    for patient_id, images in balanced_images_original.items():\n",
    "        if len(images) <= 4:\n",
    "            remove_patients.append(patient_id)\n",
    "        else:\n",
    "            print(f\"Paciente {patient_id}: Total de pares de recortes (label 1 + label 0): {len(images)}\")\n",
    "    for i in range(len(remove_patients)):\n",
    "        balanced_images_original.pop(remove_patients[i])\n",
    "        balanced_images_opposite.pop(remove_patients[i])\n",
    "        balanced_labels.pop(remove_patients[i])\n",
    "        \n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    patients = list(set(balanced_labels.keys()))\n",
    "    train_patients, valtest_patients = train_test_split(patients, train_size = train_size)\n",
    "    valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "    \n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    mask_test_original, mask_test_opposite, _ = select_by_patients(test_patients, balanced_mask_original, balanced_mask_opposite, balanced_labels)\n",
    "    \n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, np.array(y_train), np.array(y_val), train_patients, valid_patients, test_patients\n",
    "\n",
    "# Função para preparar os dados para teste\n",
    "def prepare_data_for_training_unbalanced(images_left, images_right, labels_pair, mask_left, mask_right, train_patients, valid_patients, test_patients, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_original = {}\n",
    "    balanced_images_opposite = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_original = {}\n",
    "    balanced_mask_opposite = {}\n",
    "\n",
    "    for patient_id in images_left:\n",
    "        if len(labels_pair[patient_id]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Lista para armazenar grupos de fatias\n",
    "        groups = []  \n",
    "        \n",
    "        # Criar os grupos de 4 fatias\n",
    "        for i in range(0, len(labels_pair[patient_id]), 8):\n",
    "            group = {\n",
    "                \"labels\": labels_pair[patient_id][i:i+8],\n",
    "                \"images_left\": images_left[patient_id][i:i+8],\n",
    "                \"images_right\": images_right[patient_id][i:i+8],\n",
    "                \"mask_left\": mask_left[patient_id][i:i+8],\n",
    "                \"mask_right\": mask_right[patient_id][i:i+8]\n",
    "            }\n",
    "            groups.append(group)\n",
    "\n",
    "         # Separar grupos com label 1\n",
    "        class_1_groups = [group for group in groups if 1 in group[\"labels\"]]        \n",
    "        \n",
    "        balanced_images_original[patient_id] = []\n",
    "        balanced_images_opposite[patient_id] = []\n",
    "        balanced_labels[patient_id] = []\n",
    "        balanced_mask_original[patient_id] = []\n",
    "        balanced_mask_opposite[patient_id] = []\n",
    "        \n",
    "        for group in class_1_groups:\n",
    "            balanced_images_original[patient_id].extend(group[\"images_left\"])\n",
    "            balanced_images_opposite[patient_id].extend(group[\"images_right\"])\n",
    "            balanced_labels[patient_id].extend(group[\"labels\"])\n",
    "            balanced_mask_original[patient_id].extend(group[\"mask_left\"])\n",
    "            balanced_mask_opposite[patient_id].extend(group[\"mask_right\"])\n",
    "    for patient_id, images in balanced_images_original.items():\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes: {len(images)}\")\n",
    "        \n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    # patients = list(set(balanced_labels.keys()))\n",
    "    # train_patients, valtest_patients = train_test_split(patients, train_size = train_size)\n",
    "    # valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "\n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    mask_test_original, mask_test_opposite, _ = select_by_patients(test_patients, balanced_mask_original, balanced_mask_opposite, balanced_labels)\n",
    "\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, X_test_original, X_test_opposite, np.array(y_train), np.array(y_val), np.array(y_test), mask_test_original, mask_test_opposite, balanced_images_original, balanced_images_opposite, balanced_mask_original, balanced_mask_opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir o modelo CNN 2D\n",
    "def build_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2))) \n",
    "    model.add(layers.Dropout(0.3)) \n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2))) \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2))) \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (3,3), padding=\"same\", kernel_regularizer=regularizers.l2(0.001), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2), padding=\"same\")) \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir a rede siamesa\n",
    "def build_siamese_model(input_shape):\n",
    "    input_original = Input(shape=input_shape)\n",
    "    input_opposite = Input(shape=input_shape)\n",
    "\n",
    "    # Criar a CNN base compartilhada\n",
    "    cnn_base = build_cnn_model()\n",
    "    \n",
    "    # Aplicar a mesma CNN base para ambas as entradas\n",
    "    output_original = cnn_base(input_original)\n",
    "    output_opposite = cnn_base(input_opposite)\n",
    "\n",
    "    # Calcula a diferença absoluta\n",
    "    # l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([output_original, output_opposite])\n",
    "\n",
    "    # Concatenar as duas saídas (Lado esquerdo + Contra-lateral)\n",
    "    concatenated = layers.Concatenate()([output_original, output_opposite])\n",
    "    concatenated = layers.BatchNormalization()(concatenated)\n",
    "\n",
    "    output = layers.Dense(1, activation='sigmoid')(concatenated)\n",
    "    \n",
    "    siamese_model = Model(inputs=[input_original, input_opposite], outputs=output)\n",
    "    siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', metrics.Precision(name=\"precision\"), metrics.Recall(name=\"recall\")])\n",
    "\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = 'Novo_Contralateral'\n",
    "#coordinates_path = \"Coordenadas_grid\"\n",
    "\n",
    "# Carregar e plotar as imagens\n",
    "#coordinates = load_coordinates(coordinates_path)\n",
    "\n",
    "# Carregar os dados\n",
    "X_left, X_right, y, mask_left, mask_right = load_data_with_pairs(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para treino e validação\n",
    "train_left_balanced, train_right_balanced, valid_left_balanced, valid_right_balanced, y_train_balanced, y_valid_balanced, train_patients, valid_patients, test_patients = prepare_data_for_training_balanced(X_left, X_right, y, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1)\n",
    "\n",
    "# Adiciono camada de cor\n",
    "train_left_balanced = normalize_minmax(np.array([elemento for lista in train_left_balanced.values() for elemento in lista]))\n",
    "train_left_balanced = np.expand_dims(train_left_balanced, axis=-1)\n",
    "train_right_balanced = normalize_minmax(np.array([elemento for lista in train_right_balanced.values() for elemento in lista]))\n",
    "train_right_balanced = np.expand_dims(train_right_balanced, axis=-1)\n",
    "valid_left_balanced = normalize_minmax(np.array([elemento for lista in valid_left_balanced.values() for elemento in lista]))\n",
    "valid_left_balanced = np.expand_dims(valid_left_balanced, axis=-1)\n",
    "valid_right_balanced = normalize_minmax(np.array([elemento for lista in valid_right_balanced.values() for elemento in lista]))\n",
    "valid_right_balanced = np.expand_dims(valid_right_balanced, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir e compilar o modelo CNN\n",
    "input_shape = (train_left_balanced[0].shape)\n",
    "\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o callback EarlyStopping e low rate scheduler\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Salvar a melhor epoca\n",
    "checkpoint = callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss',  save_best_only=True,  save_weights_only=True, mode='min')\n",
    "\n",
    "# Ajusta learning rate\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.3, patience=5, verbose=1)\n",
    "\n",
    "# Treinamento do modelo siames\n",
    "history = siamese_model.fit([train_left_balanced, train_right_balanced], y_train_balanced, validation_data=([valid_left_balanced, valid_right_balanced], y_valid_balanced), batch_size=64, epochs=150, callbacks=[checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o histórico do treinamento\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para teste e predição\n",
    "X_train_left, X_train_right, X_valid_left, X_valid_right, X_test_left, X_test_right, y_train, y_valid, y_test, mask_left_test, mask_right_test, images_left_by_patient, images_right_by_patient, mask_left_by_patient, mask_right_by_patient = prepare_data_for_training_unbalanced(X_left, X_right, y, mask_left, mask_right, train_patients, valid_patients, test_patients, train_size=0.7, validation_size=0.2, test_size=0.1)\n",
    "\n",
    "# Crio copias para o print em pdf\n",
    "train_left = X_train_left\n",
    "train_right = X_train_right\n",
    "valid_left = X_valid_left\n",
    "valid_right = X_valid_right\n",
    "test_left = X_test_left\n",
    "test_right = X_test_right\n",
    "\n",
    "# Adiciono camada de cor\n",
    "X_train_left = normalize_minmax(np.array([elemento for lista in X_train_left.values() for elemento in lista]))\n",
    "X_train_left = np.expand_dims(X_train_left, axis=-1)\n",
    "X_train_right = normalize_minmax(np.array([elemento for lista in X_train_right.values() for elemento in lista]))\n",
    "X_train_right = np.expand_dims(X_train_right, axis=-1)\n",
    "X_valid_left = normalize_minmax(np.array([elemento for lista in X_valid_left.values() for elemento in lista]))\n",
    "X_valid_left = np.expand_dims(X_valid_left, axis=-1)\n",
    "X_valid_right = normalize_minmax(np.array([elemento for lista in X_valid_right.values() for elemento in lista]))\n",
    "X_valid_right = np.expand_dims(X_valid_right, axis=-1)\n",
    "X_test_left = normalize_minmax(np.array([elemento for lista in X_test_left.values() for elemento in lista]))\n",
    "X_test_left = np.expand_dims(X_test_left, axis=-1)\n",
    "X_test_right = normalize_minmax(np.array([elemento for lista in X_test_right.values() for elemento in lista]))\n",
    "X_test_right = np.expand_dims(X_test_right, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando pesos da melhor época\n",
    "siamese_model.load_weights('best_model.h5')\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (siamese_model.predict([valid_left_balanced, valid_right_balanced]) >= 0.5)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (siamese_model.predict([X_test_left, X_test_right]) >= 0.5)\n",
    "\n",
    "# Calcula a curva precision-recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_test)\n",
    "\n",
    "# Calcula a AUC precision-recall\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Plote a curva precision-recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'AUC = {auc_pr:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o relatório de classificação\n",
    "print(\"Validação:\")\n",
    "print(classification_report(y_valid_balanced, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "print(classification_report(y_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(y_valid_balanced, y_pred_valid)\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "plot_confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_classifications(classifications, grid_coordinates):\n",
    "    \"\"\"\n",
    "    Sincroniza as classificações dos lados espelhados no grid (mesmo y, coordenadas da esquerda com seus espelhos à direita).\n",
    "\n",
    "    Args:\n",
    "        classifications (list): Lista de classificações (\"TP\", \"TN\", \"FP\", \"FN\").\n",
    "        grid_coordinates (list): Lista de coordenadas [y1, y2, x1, x2] para os patches.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de classificações sincronizadas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sincronizar classificações\n",
    "    for i in range (len(grid_coordinates)//2):\n",
    "        j = i + len(grid_coordinates)//2\n",
    "        # Log temporário das classificações antes da sincronização\n",
    "        print(f\"Before Sync: Left[{i}]={classifications[i]}, Right[{j}]={classifications[j]}\")\n",
    "\n",
    "        # Se qualquer um dos lados for TP, FN, FP ou TN, ambos recebem a mesma classificação\n",
    "        if classifications[i] == \"TP\" or classifications[j] == \"TP\":\n",
    "            classifications[i] = \"TP\"\n",
    "            classifications[j] = \"TP\"\n",
    "        elif classifications[i] == \"FP\" or classifications[j] == \"FP\":\n",
    "            classifications[i] = \"FP\"\n",
    "            classifications[j] = \"FP\"\n",
    "        elif classifications[i] == \"TN\" or classifications[j] == \"TN\":\n",
    "            classifications[i] = \"TN\"\n",
    "            classifications[j] = \"TN\"\n",
    "        elif classifications[i] == \"FN\" or classifications[j] == \"FN\":\n",
    "            classifications[i] = \"FN\"\n",
    "            classifications[j] = \"FN\"\n",
    "\n",
    "        # Log temporário das classificações após a sincronização\n",
    "        print(f\"After Sync: Left[{i}]={classifications[i]}, Right[{j}]={classifications[j]}\")\n",
    "\n",
    "    return classifications\n",
    "\n",
    "def resize_patch(patch, target_size):\n",
    "    \"\"\"\n",
    "    Redimensiona um patch para o tamanho desejado.\n",
    "    \n",
    "    Args:\n",
    "        patch (numpy.ndarray): Patch a ser redimensionado.\n",
    "        target_size (tuple): Tamanho alvo (altura, largura).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Patch redimensionado.\n",
    "    \"\"\"\n",
    "    return cv2.resize(patch, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def add_border(image, color, thickness=3):\n",
    "    \"\"\"\n",
    "    Adiciona uma borda colorida ao redor de uma imagem, convertendo para RGB se necessário.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Imagem original em escala de cinza.\n",
    "        color (tuple): Cor da borda (RGB).\n",
    "        thickness (int): Espessura da borda.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Imagem com a borda adicionada em formato RGB.\n",
    "    \"\"\"\n",
    "    # Normalizar a imagem para o intervalo 0-255\n",
    "    image_normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    \n",
    "    # Converter para RGB\n",
    "    if len(image_normalized.shape) == 2:  # Se a imagem for escala de cinza\n",
    "        image_rgb = cv2.cvtColor(image_normalized, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_rgb = image_normalized\n",
    "\n",
    "    # Adicionar a borda\n",
    "    bordered_image = cv2.copyMakeBorder(\n",
    "        image_rgb, \n",
    "        thickness, thickness, thickness, thickness, \n",
    "        cv2.BORDER_CONSTANT, \n",
    "        value=color\n",
    "    )\n",
    "    \n",
    "    return bordered_image\n",
    "\n",
    "\n",
    "def build_image_with_grid(img, mask, grid_coordinates, classifications):\n",
    "    \"\"\"\n",
    "    Reconstrói uma imagem e sua máscara usando as coordenadas de grid e pinta os patches com bordas coloridas.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): Imagem original.\n",
    "        mask (numpy.ndarray): Máscara original.\n",
    "        grid_coordinates (list): Lista de coordenadas [y1, y2, x1, x2] para os patches.\n",
    "        classifications (list): Lista de classificações para os patches (\"TP\", \"TN\", \"FP\", \"FN\").\n",
    "\n",
    "    Returns:\n",
    "        tuple: Imagem reconstruída com bordas coloridas, máscara reconstruída com bordas coloridas.\n",
    "    \"\"\"\n",
    "    # Tamanho da imagem reconstruída\n",
    "    height, width = img.shape[:2]\n",
    "    reconstructed_img = np.zeros((height+6, width+6, 3), dtype=np.uint8)\n",
    "    reconstructed_mask = np.zeros((height+6, width+6, 3), dtype=np.uint8)\n",
    "\n",
    "    # Mapeamento de cores para as classificações\n",
    "    colors = {\"TP\": (0, 255, 0), \"TN\": (0, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}  # RGB\n",
    "\n",
    "    # Iterar pelas coordenadas do grid e aplicar bordas coloridas\n",
    "    for idx, (y1, y2, x1, x2) in enumerate(grid_coordinates):\n",
    "        if idx >= len(grid_coordinates)//2:\n",
    "            break\n",
    "        \n",
    "        (y3, y4, x3, x4) = grid_coordinates[idx+len(grid_coordinates)//2]\n",
    "        patch_img = img[y1:y2+1, x1:x2+1]\n",
    "        patch_mask = mask[y1:y2+1, x1:x2+1]\n",
    "        patch_img_mirror = img[y3:y4+1, x3:x4+1]\n",
    "        patch_mask_mirror = mask[y3:y4+1, x3:x4+1]\n",
    "        \n",
    "        # Total de pixels na subimagem\n",
    "        total_pixels = patch_img.size\n",
    "        # Número de pixels não-preto\n",
    "        non_zero_pixels = np.count_nonzero(patch_img)\n",
    "        # Proporção de pixels não-preto\n",
    "        non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "        \n",
    "        if non_black_ratio >= 0.08:\n",
    "            # Adicionar borda colorida ao patch\n",
    "            patch_img = add_border(patch_img, colors[classifications[idx]])\n",
    "            patch_mask = add_border(patch_mask, colors[classifications[idx]])\n",
    "            patch_img_mirror = add_border(patch_img_mirror, colors[classifications[idx+len(grid_coordinates)//2]])\n",
    "            patch_mask_mirror = add_border(patch_mask_mirror, colors[classifications[idx+len(grid_coordinates)//2]])\n",
    "        else:\n",
    "            patch_img = resize_patch(patch_img, (46,46))\n",
    "            patch_mask = resize_patch(patch_mask, (46,46))\n",
    "            patch_img_mirror = resize_patch(patch_img_mirror, (46,46))\n",
    "            patch_mask_mirror = resize_patch(patch_mask_mirror, (46,46))\n",
    "            \n",
    "            patch_img = cv2.cvtColor(cv2.normalize(patch_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U), cv2.COLOR_GRAY2RGB)\n",
    "            patch_mask = cv2.cvtColor(cv2.normalize(patch_mask, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U), cv2.COLOR_GRAY2RGB)\n",
    "            patch_img_mirror = cv2.cvtColor(cv2.normalize(patch_img_mirror, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U), cv2.COLOR_GRAY2RGB)\n",
    "            patch_mask_mirror = cv2.cvtColor(cv2.normalize(patch_mask_mirror, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U), cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # Inserir os patches reconstruídos na imagem completa\n",
    "        reconstructed_img[y1:y2+7, x1:x2+7] = patch_img\n",
    "        reconstructed_mask[y1:y2+7, x1:x2+7] = patch_mask\n",
    "        reconstructed_img[y3:y4+7, x3:x4+7] = patch_img_mirror\n",
    "        reconstructed_mask[y3:y4+7, x3:x4+7] = patch_mask_mirror\n",
    "        \n",
    "    return reconstructed_img, reconstructed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para carregar a imagem e a máscara inteiras\n",
    "def load_full_image_and_mask(image_path, mask_path):\n",
    "    images = {}\n",
    "    masks = {}\n",
    "    patient_ids = []\n",
    "    for patient_id, mask_id in tqdm(zip(os.listdir(image_path), os.listdir(mask_path)), desc=\"Carregamento de arquivos NIfTI...\"):\n",
    "        patient_path = os.path.join(image_path, patient_id)\n",
    "        mask_patient_path = os.path.join(mask_path, mask_id)\n",
    "        patient_ids.append(patient_id)\n",
    "        images[patient_id] = []\n",
    "        masks[patient_id] = []\n",
    "        for patch_id, mask_patch_id in zip(os.listdir(patient_path), os.listdir(mask_patient_path)):\n",
    "            img = nib.load(os.path.join(patient_path, patch_id)).get_fdata()\n",
    "            mask = nib.load(os.path.join(mask_patient_path, mask_patch_id)).get_fdata()\n",
    "            images[patient_id].append(img)\n",
    "            masks[patient_id].append(mask)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def plot_patient_slices_with_grid(pdf_filename, patients, images, masks, grids, labels_true, labels_pred):\n",
    "    \"\"\"\n",
    "    Gera um PDF com imagens de pacientes, suas máscaras e grids reconstruídos.\n",
    "\n",
    "    Args:\n",
    "        pdf_filename (str): Nome do arquivo PDF.\n",
    "        patients (list): Lista de IDs dos pacientes.\n",
    "        images (dict): Dicionário com imagens completas dos pacientes.\n",
    "        masks (dict): Dicionário com máscaras completas dos pacientes.\n",
    "        grids (dict): Dicionário com grids (coordenadas) para os pacientes.\n",
    "        labels_true (list): Labels verdadeiros das fatias.\n",
    "        labels_pred (list): Labels preditos das fatias.\n",
    "    \"\"\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        for patient in patients:\n",
    "            cont = 0\n",
    "            for img, mask, grid_coordinates in zip(images[patient], masks[patient], grids[patient]):\n",
    "                # Total de pixels na subimagem\n",
    "                total_pixels = img.size\n",
    "                # Número de pixels não-preto\n",
    "                non_zero_pixels = np.count_nonzero(img)\n",
    "                # Proporção de pixels não-preto\n",
    "                non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "                \n",
    "                if non_black_ratio >= 0.08:\n",
    "                    classifications = []\n",
    "                    for idx, pred in enumerate(labels_pred[cont:cont + len(grid_coordinates)]):\n",
    "                        true_label = labels_true[cont + idx]\n",
    "                        if pred == 1:\n",
    "                            if true_label == 1:\n",
    "                                classifications.append(\"TP\")\n",
    "                            else:\n",
    "                                classifications.append(\"FP\")\n",
    "                        elif pred == 0:\n",
    "                            if true_label == 1:\n",
    "                                classifications.append(\"FN\")\n",
    "                            else:\n",
    "                                classifications.append(\"TN\") \n",
    "\n",
    "                    # Validar tamanhos\n",
    "                    if len(grid_coordinates) != len(classifications):\n",
    "                        print(f\"Mismatch in sizes: {len(grid_coordinates)} grid coords, {len(classifications)} classifications.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Sincronizar classificações entre os lados opostos\n",
    "                    classifications = synchronize_classifications(classifications, grid_coordinates)\n",
    "\n",
    "                    # Reconstruir imagem e máscara usando o grid\n",
    "                    reconstructed_img, reconstructed_mask = build_image_with_grid(\n",
    "                        img, mask, grid_coordinates, classifications\n",
    "                    )\n",
    "\n",
    "                    # Configurar a figura\n",
    "                    fig, axs = plt.subplots(2, 1, figsize=(6, 6))\n",
    "                    axs[0].imshow(reconstructed_img, cmap='gray')\n",
    "                    axs[0].set_title(f'{patient} - Imagem')\n",
    "                    axs[0].axis('off')\n",
    "                    axs[1].imshow(reconstructed_mask, cmap='gray')\n",
    "                    axs[1].set_title(f'{patient} - Máscara')\n",
    "                    axs[1].axis('off')\n",
    "\n",
    "                    # Adicionar ao PDF\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close(fig)\n",
    "\n",
    "                    cont += len(grid_coordinates)\n",
    "\n",
    "        print(f\"As imagens foram salvas no arquivo PDF {pdf_filename} com sucesso.\")\n",
    "\n",
    "\n",
    "# Caminhos das imagens e máscaras\n",
    "image_path = \"Fatias\"\n",
    "mask_path = \"Mask_Fatias\"\n",
    "\n",
    "# Carregar e plotar as imagens\n",
    "images, masks = load_full_image_and_mask(image_path, mask_path)\n",
    "\n",
    "# Processar Teste\n",
    "plot_patient_slices_with_grid(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Reconstruidos_Grid.pdf\",\n",
    "    patients=test_patients,\n",
    "    images=images,\n",
    "    masks=masks,\n",
    "    grids=coordinates,\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
