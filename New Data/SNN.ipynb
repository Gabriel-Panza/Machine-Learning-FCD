{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models, callbacks, metrics, Input, Model, regularizers\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(images_left, images_right, masks_left, masks_right):\n",
    "    for patient_id in images_left.keys():\n",
    "        # Combine os dados em uma única lista para embaralhar consistentemente\n",
    "        combined = list(zip(images_left[patient_id], images_right[patient_id],\n",
    "                            masks_left[patient_id], masks_right[patient_id]))\n",
    "        \n",
    "        # Embaralhar os dados\n",
    "        random.shuffle(combined)\n",
    "        \n",
    "        # Descompactar os dados embaralhados\n",
    "        images_left[patient_id], images_right[patient_id], \\\n",
    "        masks_left[patient_id], masks_right[patient_id] = zip(*combined)\n",
    "        \n",
    "        # Converter de volta para listas (zip retorna tuplas)\n",
    "        images_left[patient_id] = list(images_left[patient_id])\n",
    "        images_right[patient_id] = list(images_right[patient_id])\n",
    "        masks_left[patient_id] = list(masks_left[patient_id])\n",
    "        masks_right[patient_id] = list(masks_right[patient_id])\n",
    "\n",
    "    print(\"Os dados foram embaralhados com sucesso.\")\n",
    "    return images_left, images_right, masks_left, masks_right\n",
    "\n",
    "\n",
    "def calculate_label(image, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Determina o label da subimagem com base no percentual de fundo não-preto.\n",
    "    :param subimage: Array da subimagem.\n",
    "    :param threshold: Percentual mínimo de fundo não-preto para considerar como label 1.\n",
    "    :return: String indicando o label.\n",
    "    \"\"\"\n",
    "    # Total de pixels na subimagem\n",
    "    total_pixels = image.size\n",
    "    # Número de pixels não-preto\n",
    "    non_zero_pixels = np.count_nonzero(image)\n",
    "    # Proporção de pixels não-preto\n",
    "    non_black_ratio = non_zero_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    \n",
    "    # Verifica se há lesão e se o fundo não-preto é maior que o limiar\n",
    "    if np.any(image == 1) and non_black_ratio >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Função para carregar as coordenadas dos arquivos txt\n",
    "def load_coordinates(coordinates_path):\n",
    "    coordinates = {}\n",
    "    for patient_id in os.listdir(coordinates_path):\n",
    "        patient_path = os.path.join(coordinates_path, patient_id)\n",
    "        coordinates[patient_id] = []\n",
    "        for slice_file in sorted(os.listdir(patient_path)):\n",
    "            slice_path = os.path.join(patient_path, slice_file)\n",
    "            with open(slice_path, 'r') as f:\n",
    "                coords = [tuple(map(int, line.strip().split(','))) for line in f.readlines()]\n",
    "                coordinates[patient_id].append(coords)\n",
    "    return coordinates\n",
    "\n",
    "# Função que carrega os dados com pares de imagens\n",
    "def load_data_with_pairs(folder, coordinates):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"A pasta {folder} não existe.\")\n",
    "        return {}, {}, {}, {}, {}\n",
    "    \n",
    "    images_left = {}\n",
    "    images_right = {}\n",
    "    mask_left = {}\n",
    "    mask_right = {}\n",
    "    labels_left = {}\n",
    "    labels_right = {}\n",
    "    patient_ids = []\n",
    "\n",
    "    # Itera sobre os pacientes no diretório\n",
    "    for patient_id in tqdm(os.listdir(folder), desc=\"Carregamento de arquivos NIfTI...\"):\n",
    "        patient_path = os.path.join(folder, patient_id)\n",
    "\n",
    "        areas_image = [\"left\", \"right\"]\n",
    "        areas_mask = [\"lesion_left\", \"lesion_right\"]\n",
    "        path_left = os.path.join(patient_path, areas_image[0])\n",
    "        path_right = os.path.join(patient_path, areas_image[1])\n",
    "        lesion_path_left = os.path.join(patient_path, areas_mask[0])\n",
    "        lesion_path_right = os.path.join(patient_path, areas_mask[1])\n",
    "\n",
    "        if patient_id not in images_left:\n",
    "            images_left[patient_id] = []\n",
    "        if patient_id not in images_right:\n",
    "            images_right[patient_id] = []\n",
    "        if patient_id not in mask_left:\n",
    "            mask_left[patient_id] = []\n",
    "        if patient_id not in mask_right:\n",
    "            mask_right[patient_id] = []\n",
    "        if patient_id not in labels_left:\n",
    "            labels_left[patient_id] = []\n",
    "        if patient_id not in labels_right:\n",
    "            labels_right[patient_id] = []\n",
    "        \n",
    "        index = 0\n",
    "    \n",
    "        # Carrega as imagens e máscaras do lado esquerdo e direito\n",
    "        for patch_id_left, mask_id_left, patch_id_right, mask_id_right in zip(os.listdir(path_left), os.listdir(lesion_path_left), os.listdir(path_right), os.listdir(lesion_path_right)):\n",
    "            img_path_left = os.path.join(path_left, patch_id_left)\n",
    "            mask_path_left = os.path.join(lesion_path_left, mask_id_left)\n",
    "            img_path_right = os.path.join(path_right, patch_id_right)\n",
    "            mask_path_right = os.path.join(lesion_path_right, mask_id_right)\n",
    "            \n",
    "            # Verificar se existem coordenadas para a fatia atual\n",
    "            if patient_id not in coordinates or index >= len(coordinates[patient_id]):\n",
    "                print(f\"Aviso: Coordenadas ausentes para o paciente {patient_id}, fatia {index}\")\n",
    "                index+=1\n",
    "                continue \n",
    "             \n",
    "            for img_left, msk_left, img_right, msk_right in zip(os.listdir(img_path_left), os.listdir(mask_path_left), os.listdir(img_path_right), os.listdir(mask_path_right)):\n",
    "                data_left = nib.load(os.path.join(img_path_left, img_left)).get_fdata()\n",
    "                data_msk_left = nib.load(os.path.join(mask_path_left, msk_left)).get_fdata()\n",
    "                data_right = nib.load(os.path.join(img_path_right, img_right)).get_fdata()\n",
    "                data_msk_right = nib.load(os.path.join(mask_path_right, msk_right)).get_fdata()\n",
    "                        \n",
    "                if (len(data_left) > 0) and (len(data_msk_left) > 0):\n",
    "                    images_left[patient_id].append(data_left)\n",
    "                    mask_left[patient_id].append(data_msk_left)\n",
    "                    labels_left[patient_id].append(calculate_label(data_msk_left))\n",
    "                    \n",
    "                if (len(data_right) > 0) and (len(data_msk_right) > 0):\n",
    "                    images_right[patient_id].append(data_right)\n",
    "                    mask_right[patient_id].append(data_msk_right)\n",
    "                    labels_right[patient_id].append(calculate_label(data_msk_right))\n",
    "            index+=1\n",
    "\n",
    "        patient_ids.append(patient_id)\n",
    "\n",
    "    # Estruturas para armazenar os pares de labels\n",
    "    labels_pair = {}\n",
    "    for patient_id,_ in zip(labels_left.keys(), labels_right.keys()):\n",
    "        labels_pair[patient_id] = []\n",
    "        for label_left, label_right in zip(labels_left[patient_id], labels_right[patient_id]): \n",
    "            if label_left == 0 and label_right == 0:\n",
    "                labels_pair[patient_id].append(0)\n",
    "            else:\n",
    "                labels_pair[patient_id].append(1)\n",
    "\n",
    "    print(f\"Total de pacientes: {len(patient_ids)}\")\n",
    "    for patient_id, labels in labels_pair.items():\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes: {len(labels)}\")\n",
    "\n",
    "    return images_left, images_right, labels_pair, mask_left, mask_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar entre 0 e 1\n",
    "def normalize_minmax(image_data): \n",
    "    min_val = np.min(image_data)\n",
    "    max_val = np.max(image_data)\n",
    "    normalized_data = (image_data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "# Função para filtrar as imagens por paciente\n",
    "def select_by_patients(patients, all_images_original, all_images_opposite, all_labels):\n",
    "    selected_images_original = {}\n",
    "    selected_images_opposite = {}\n",
    "    selected_labels = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        selected_images_original[patient] = []\n",
    "        selected_images_opposite[patient] = []\n",
    "        if patient in all_images_original and patient in all_images_opposite:\n",
    "            selected_images_original[patient].extend(all_images_original[patient])\n",
    "            selected_images_opposite[patient].extend(all_images_opposite[patient])\n",
    "            selected_labels.extend(all_labels[patient])\n",
    "        else:\n",
    "            print(f\"Paciente {patient} não encontrado em uma das listas de imagens.\")\n",
    "    \n",
    "    return selected_images_original, selected_images_opposite, selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados para treino e validação\n",
    "def prepare_data_for_training_balanced(images_left, images_right, labels_pair, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_original = {}\n",
    "    balanced_images_opposite = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_original = {}\n",
    "    balanced_mask_opposite = {}\n",
    "\n",
    "    for patient_id in images_left:\n",
    "        class_1_labels = []\n",
    "        class_0_labels = []\n",
    "        class_1_left = {}\n",
    "        class_0_left = {}\n",
    "        class_1_right = {}\n",
    "        class_0_right = {}\n",
    "        class_1_mask_left = {}\n",
    "        class_0_mask_left = {}\n",
    "        class_1_mask_right = {}\n",
    "        class_0_mask_right = {}\n",
    "        \n",
    "        class_1_left[patient_id] = []\n",
    "        class_0_left[patient_id] = []\n",
    "        class_1_right[patient_id] = []\n",
    "        class_0_right[patient_id] = []\n",
    "        class_1_mask_left[patient_id] = []\n",
    "        class_0_mask_left[patient_id] = []\n",
    "        class_1_mask_right[patient_id] = []\n",
    "        class_0_mask_right[patient_id] = []\n",
    "        index = 0\n",
    "        \n",
    "        # Iterar sobre os patches e dividir as classes 0 e 1 com base nas labels\\n\",\n",
    "        for label in labels_pair[patient_id]:\n",
    "            image_left = (images_left[patient_id])[index]\n",
    "            image_right = (images_right[patient_id])[index]\n",
    "            mask_image_left = (mask_left[patient_id])[index]\n",
    "            mask_image_right = (mask_right[patient_id])[index]\n",
    "            index += 1\n",
    "            \n",
    "            if label == 1:\n",
    "                class_1_labels.append(label)\n",
    "                class_1_left[patient_id].append(image_left)\n",
    "                class_1_right[patient_id].append(image_right)\n",
    "                class_1_mask_left[patient_id].append(mask_image_left)\n",
    "                class_1_mask_right[patient_id].append(mask_image_right)\n",
    "            else:\n",
    "                class_0_labels.append(label)\n",
    "                class_0_left[patient_id].append(image_left)\n",
    "                class_0_right[patient_id].append(image_right)\n",
    "                class_0_mask_left[patient_id].append(mask_image_left)\n",
    "                class_0_mask_right[patient_id].append(mask_image_right)\n",
    "        class_1_count = len(class_1_labels)\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes com labels 1: {class_1_count}\")\n",
    "\n",
    "        # Fazer undersampling aleatório da classe majoritária (label 0) para igualar ao número de exemplos da classe 1\n",
    "        class_0_count = len(class_0_labels)\n",
    "        if class_0_count > class_1_count:\n",
    "            sampled_indices = np.random.choice(range(class_0_count), class_1_count, replace=False)\n",
    "            sampled_class_0_slices_left = [class_0_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_slices_right = [class_0_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_original_modified = {}\n",
    "            class_0_original_modified[patient_id] = []\n",
    "            class_0_opposite_modified = {}\n",
    "            class_0_opposite_modified[patient_id] = []\n",
    "            sampled_class_0_mask_left = [class_0_mask_left[patient_id][i] for i in sampled_indices]\n",
    "            sampled_class_0_mask_right = [class_0_mask_right[patient_id][i] for i in sampled_indices]\n",
    "            class_0_mask_original_modified = {}\n",
    "            class_0_mask_original_modified[patient_id] = []\n",
    "            class_0_mask_opposite_modified = {}\n",
    "            class_0_mask_opposite_modified[patient_id] = []\n",
    "\n",
    "            for left_image, left_mask in zip(sampled_class_0_slices_left, sampled_class_0_mask_left):\n",
    "                class_0_original_modified[patient_id].append(left_image)\n",
    "                class_0_mask_original_modified[patient_id].append(left_mask)\n",
    "            for right_image, right_mask in zip(sampled_class_0_slices_right, sampled_class_0_mask_right):\n",
    "                class_0_opposite_modified[patient_id].append(right_image)\n",
    "                class_0_mask_opposite_modified[patient_id].append(right_mask)\n",
    "            class_0_labels = [0] * class_1_count\n",
    "\n",
    "        balanced_images_original[patient_id] = list(class_1_left[patient_id]) + list(class_0_original_modified[patient_id])\n",
    "        balanced_images_opposite[patient_id] = list(class_1_right[patient_id]) + list(class_0_opposite_modified[patient_id])\n",
    "        balanced_labels[patient_id] = class_1_labels + class_0_labels\n",
    "        balanced_mask_original[patient_id] = list(class_1_mask_left[patient_id]) + list(class_0_mask_original_modified[patient_id])\n",
    "        balanced_mask_opposite[patient_id] = list(class_1_mask_right[patient_id]) + list(class_0_mask_opposite_modified[patient_id])\n",
    "        \n",
    "    remove_patients = []\n",
    "    for patient_id, images in balanced_images_original.items():\n",
    "        if len(images) <= 4:\n",
    "            remove_patients.append(patient_id)\n",
    "        else:\n",
    "            print(f\"Paciente {patient_id}: Total de pares de recortes (label 1 + label 0): {len(images)}\")\n",
    "    for i in range(len(remove_patients)):\n",
    "        balanced_images_original.pop(remove_patients[i])\n",
    "        balanced_images_opposite.pop(remove_patients[i])\n",
    "        balanced_labels.pop(remove_patients[i])\n",
    "        \n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    patients = list(set(balanced_labels.keys()))\n",
    "    train_patients, valtest_patients = train_test_split(patients, train_size = train_size)\n",
    "    valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "    \n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    mask_test_original, mask_test_opposite, _ = select_by_patients(test_patients, balanced_mask_original, balanced_mask_opposite, balanced_labels)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, np.array(y_train), np.array(y_val), train_patients, valid_patients, test_patients\n",
    "\n",
    "# Função para preparar os dados para teste\n",
    "def prepare_data_for_training_unbalanced(images_left, images_right, labels_pair, mask_left, mask_right, train_patients, valid_patients, test_patients, train_size=0.7, validation_size=0.2, test_size=0.1, augment_factor=1):\n",
    "    balanced_images_original = {}\n",
    "    balanced_images_opposite = {}\n",
    "    balanced_labels = {}\n",
    "    balanced_mask_original = {}\n",
    "    balanced_mask_opposite = {}\n",
    "\n",
    "    for patient_id in images_left:\n",
    "        # Lista para armazenar grupos de fatias\n",
    "        groups = []  \n",
    "        \n",
    "        # Criar os grupos de 4 fatias\n",
    "        for i in range(0, len(labels_pair[patient_id]), 8):\n",
    "            group = {\n",
    "                \"labels\": labels_pair[patient_id][i:i+8],\n",
    "                \"images_left\": images_left[patient_id][i:i+8],\n",
    "                \"images_right\": images_right[patient_id][i:i+8],\n",
    "                \"mask_left\": mask_left[patient_id][i:i+8],\n",
    "                \"mask_right\": mask_right[patient_id][i:i+8]\n",
    "            }\n",
    "            groups.append(group)\n",
    "\n",
    "         # Separar grupos com label 1\n",
    "        class_1_groups = [group for group in groups if 1 in group[\"labels\"]]        \n",
    "        \n",
    "        balanced_images_original[patient_id] = []\n",
    "        balanced_images_opposite[patient_id] = []\n",
    "        balanced_labels[patient_id] = []\n",
    "        balanced_mask_original[patient_id] = []\n",
    "        balanced_mask_opposite[patient_id] = []\n",
    "        \n",
    "        for group in class_1_groups:\n",
    "            balanced_images_original[patient_id].extend(group[\"images_left\"])\n",
    "            balanced_images_opposite[patient_id].extend(group[\"images_right\"])\n",
    "            balanced_labels[patient_id].extend(group[\"labels\"])\n",
    "            balanced_mask_original[patient_id].extend(group[\"mask_left\"])\n",
    "            balanced_mask_opposite[patient_id].extend(group[\"mask_right\"])\n",
    "    for patient_id, images in balanced_images_original.items():\n",
    "        print(f\"Paciente {patient_id}: Total de pares de recortes: {len(images)}\")\n",
    "        \n",
    "    # Separar os dados por conjunto (treino, validação, teste)\n",
    "    # patients = list(set(balanced_labels.keys()))\n",
    "    # train_patients, valtest_patients = train_test_split(patients, train_size = train_size)\n",
    "    # valid_patients, test_patients = train_test_split(valtest_patients, train_size = validation_size / (validation_size + test_size))\n",
    "\n",
    "    X_train_original, X_train_opposite, y_train = select_by_patients(train_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_val_original, X_val_opposite, y_val = select_by_patients(valid_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    X_test_original, X_test_opposite, y_test = select_by_patients(test_patients, balanced_images_original, balanced_images_opposite, balanced_labels)\n",
    "    mask_test_original, mask_test_opposite, _ = select_by_patients(test_patients, balanced_mask_original, balanced_mask_opposite, balanced_labels)\n",
    "\n",
    "    # Aplicar shuffle nos dados de treino\n",
    "    X_train_original, X_train_opposite, y_train = shuffle(X_train_original, X_train_opposite, y_train, random_state=42)\n",
    "\n",
    "    # Aplicar shuffle nos dados de validação\n",
    "    X_val_original, X_val_opposite, y_val = shuffle(X_val_original, X_val_opposite, y_val, random_state=42)\n",
    "\n",
    "    # Aplicar shuffle nos dados de teste\n",
    "    X_test_original, X_test_opposite, y_test = shuffle(X_test_original, X_test_opposite, y_test, random_state=42)\n",
    "\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 1: {y_train.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no treino ({augment_factor}*{sorted(train_patients)}) com label 0: {y_train.count(0)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 1: {y_val.count(1)}\")\n",
    "    print(f\"Total de pares de recortes na validação ({augment_factor}*{sorted(valid_patients)}) com label 0: {y_val.count(0)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 1: {y_test.count(1)}\")\n",
    "    print(f\"Total de pares de recortes no teste com ({augment_factor}*{sorted(test_patients)}) label 0: {y_test.count(0)}\")\n",
    "    \n",
    "    return X_train_original, X_train_opposite, X_val_original, X_val_opposite, X_test_original, X_test_opposite, np.array(y_train), np.array(y_val), np.array(y_test), mask_test_original, mask_test_opposite, balanced_images_original, balanced_images_opposite, balanced_mask_original, balanced_mask_opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir o modelo CNN 2D\n",
    "def build_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2))) \n",
    "    model.add(layers.Dropout(0.3)) \n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), data_format=\"channels_last\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2))) \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para construir a rede siamesa\n",
    "def build_siamese_model(input_shape):\n",
    "    input_original = Input(shape=input_shape)\n",
    "    input_opposite = Input(shape=input_shape)\n",
    "\n",
    "    # Criar a CNN base compartilhada\n",
    "    cnn_base = build_cnn_model()\n",
    "    \n",
    "    # Aplicar a mesma CNN base para ambas as entradas\n",
    "    output_original = cnn_base(input_original)\n",
    "    output_opposite = cnn_base(input_opposite)\n",
    "\n",
    "    # Calcula a diferença absoluta\n",
    "    # l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([output_original, output_opposite])\n",
    "\n",
    "    # Concatenar as duas saídas (Lado esquerdo + Contra-lateral)\n",
    "    concatenated = layers.Concatenate()([output_original, output_opposite])\n",
    "    concatenated = layers.BatchNormalization()(concatenated)\n",
    "\n",
    "    output = layers.Dense(1, activation='sigmoid')(concatenated)\n",
    "    \n",
    "    siamese_model = Model(inputs=[input_original, input_opposite], outputs=output)\n",
    "    siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', metrics.Precision(name=\"precision\"), metrics.Recall(name=\"recall\")])\n",
    "\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Graphic')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = 'Novo_Contralateral'\n",
    "coordinates_path = \"Coordenadas_grid\"\n",
    "\n",
    "# Carregar e plotar as imagens\n",
    "coordinates = load_coordinates(coordinates_path)\n",
    "\n",
    "# Carregar os dados\n",
    "X_left, X_right, y, mask_left, mask_right = load_data_with_pairs(input_folder, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para treino e validação\n",
    "train_left_balanced, train_right_balanced, valid_left_balanced, valid_right_balanced, y_train_balanced, y_valid_balanced, train_patients, valid_patients, test_patients = prepare_data_for_training_balanced(X_left, X_right, y, mask_left, mask_right, train_size=0.7, validation_size=0.2, test_size=0.1)\n",
    "\n",
    "# Adiciono camada de cor\n",
    "train_left_balanced = normalize_minmax(np.array([elemento for lista in train_left_balanced.values() for elemento in lista]))\n",
    "train_left_balanced = np.expand_dims(train_left_balanced, axis=-1)\n",
    "train_right_balanced = normalize_minmax(np.array([elemento for lista in train_right_balanced.values() for elemento in lista]))\n",
    "train_right_balanced = np.expand_dims(train_right_balanced, axis=-1)\n",
    "valid_left_balanced = normalize_minmax(np.array([elemento for lista in valid_left_balanced.values() for elemento in lista]))\n",
    "valid_left_balanced = np.expand_dims(valid_left_balanced, axis=-1)\n",
    "valid_right_balanced = normalize_minmax(np.array([elemento for lista in valid_right_balanced.values() for elemento in lista]))\n",
    "valid_right_balanced = np.expand_dims(valid_right_balanced, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir e compilar o modelo CNN\n",
    "input_shape = (train_left_balanced[0].shape)\n",
    "\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o callback EarlyStopping e low rate scheduler\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Salvar a melhor epoca\n",
    "checkpoint = callbacks.ModelCheckpoint('best_model.weights.h5', monitor='val_loss',  save_best_only=True,  save_weights_only=True, mode='min')\n",
    "\n",
    "# Ajusta learning rate\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.2, patience=5, verbose=1)\n",
    "\n",
    "# Treinamento do modelo siames\n",
    "history = siamese_model.fit([train_left_balanced, train_right_balanced], y_train_balanced, validation_data=([valid_left_balanced, valid_right_balanced], y_valid_balanced), batch_size=64, epochs=150, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o histórico do treinamento\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para teste e predição\n",
    "X_train_left, X_train_right, X_valid_left, X_valid_right, X_test_left, X_test_right, y_train, y_valid, y_test, mask_left_test, mask_right_test, images_left_by_patient, images_right_by_patient, mask_left_by_patient, mask_right_by_patient = prepare_data_for_training_unbalanced(X_left, X_right, y, mask_left, mask_right, train_patients, valid_patients, test_patients, train_size=0.7, validation_size=0.2, test_size=0.1)\n",
    "\n",
    "# Crio copias para o print em pdf\n",
    "train_left = X_train_left\n",
    "train_right = X_train_right\n",
    "valid_left = X_valid_left\n",
    "valid_right = X_valid_right\n",
    "test_left = X_test_left\n",
    "test_right = X_test_right\n",
    "\n",
    "# Adiciono camada de cor\n",
    "X_train_left = normalize_minmax(np.array([elemento for lista in X_train_left.values() for elemento in lista]))\n",
    "X_train_left = np.expand_dims(X_train_left, axis=-1)\n",
    "X_train_right = normalize_minmax(np.array([elemento for lista in X_train_right.values() for elemento in lista]))\n",
    "X_train_right = np.expand_dims(X_train_right, axis=-1)\n",
    "X_valid_left = normalize_minmax(np.array([elemento for lista in X_valid_left.values() for elemento in lista]))\n",
    "X_valid_left = np.expand_dims(X_valid_left, axis=-1)\n",
    "X_valid_right = normalize_minmax(np.array([elemento for lista in X_valid_right.values() for elemento in lista]))\n",
    "X_valid_right = np.expand_dims(X_valid_right, axis=-1)\n",
    "X_test_left = normalize_minmax(np.array([elemento for lista in X_test_left.values() for elemento in lista]))\n",
    "X_test_left = np.expand_dims(X_test_left, axis=-1)\n",
    "X_test_right = normalize_minmax(np.array([elemento for lista in X_test_right.values() for elemento in lista]))\n",
    "X_test_right = np.expand_dims(X_test_right, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando pesos da melhor época\n",
    "siamese_model.load_weights('best_model.weights.h5')\n",
    "\n",
    "# Avaliar o modelo na validação\n",
    "y_pred_valid = (siamese_model.predict([valid_left_balanced, valid_right_balanced]) > 0.5)\n",
    "\n",
    "# Avaliar o modelo no teste\n",
    "y_pred_test = (siamese_model.predict([X_test_left, X_test_right]) > 0.5)\n",
    "\n",
    "# Calcula a curva precision-recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_test)\n",
    "\n",
    "# Calcula a AUC precision-recall\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Plote a curva precision-recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'AUC = {auc_pr:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o relatório de classificação\n",
    "print(\"Validação:\")\n",
    "print(classification_report(y_valid_balanced, y_pred_valid))\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "print(classification_report(y_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar a matriz de confusão\n",
    "print(\"Validação:\")\n",
    "plot_confusion_matrix(y_valid_balanced, y_pred_valid)\n",
    "print(\"\\n#########################################################\\n\")\n",
    "print(\"Teste:\")\n",
    "plot_confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border(image, color, thickness=3):\n",
    "    \"\"\"\n",
    "    Adiciona uma borda colorida ao redor de uma imagem, convertendo para RGB se necessário.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Imagem original em escala de cinza.\n",
    "        color (tuple): Cor da borda (RGB).\n",
    "        thickness (int): Espessura da borda.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Imagem com a borda adicionada em formato RGB.\n",
    "    \"\"\"\n",
    "    # Normalizar a imagem para o intervalo 0-255\n",
    "    image_normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    \n",
    "    # Converter para RGB\n",
    "    if len(image_normalized.shape) == 2:  # Se a imagem for escala de cinza\n",
    "        image_rgb = cv2.cvtColor(image_normalized, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_rgb = image_normalized\n",
    "\n",
    "    # Adicionar a borda\n",
    "    bordered_image = cv2.copyMakeBorder(\n",
    "        image_rgb, \n",
    "        thickness, thickness, thickness, thickness, \n",
    "        cv2.BORDER_CONSTANT, \n",
    "        value=color\n",
    "    )\n",
    "    \n",
    "    return bordered_image\n",
    "\n",
    "\n",
    "def build_image(img, mask, classificacao):\n",
    "    # Tamanho dos patches\n",
    "    patch_size = 56\n",
    "\n",
    "    # Inicializar a matriz para a imagem e a máscara reconstruídas\n",
    "    imagem_reconstruida = np.zeros((4 * patch_size, 4 * patch_size, 3), dtype=np.uint8)\n",
    "    mascara_reconstruida = np.zeros((4 * patch_size, 4 * patch_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # Mapear os patches para as posições corretas na matriz com bordas baseadas na classificação\n",
    "    colors = {\"TP\": (0, 255, 0), \"TN\": (0, 255, 0), \"FP\": (255, 0, 0), \"FN\": (255, 255, 0)}  # RGB: Vermelho, Verde, Azul\n",
    "\n",
    "    # Ordem correta para reconstrução\n",
    "    correct_order = [\n",
    "        0, 1, 8, 9,    # Linha 1\n",
    "        2, 3, 10, 11,   # Linha 2\n",
    "        4, 5, 12, 13,  # Linha 3\n",
    "        6, 7, 14, 15   # Linha 4\n",
    "    ]\n",
    "    correct_order_classification = [\n",
    "        0, 1, 1, 0,    # Linha 1\n",
    "        2, 3, 3, 2,    # Linha 2\n",
    "        4, 5, 5, 4,    # Linha 3\n",
    "        6, 7, 7, 6     # Linha 4\n",
    "    ]\n",
    "\n",
    "    # Loop para reconstruir as linhas e colunas\n",
    "    for i in range(4):  # Linha\n",
    "        for j in range(4):  # Coluna\n",
    "            idx = correct_order[i * 4 + j]\n",
    "            idx_classification = correct_order_classification[i * 4 + j]\n",
    "            x_start = i * patch_size\n",
    "            y_start = j * patch_size\n",
    "            \n",
    "            # Adicionar bordas às imagens\n",
    "            imagem_reconstruida[x_start:x_start + patch_size, y_start:y_start + patch_size, :] = add_border(img[idx], colors[classificacao[idx_classification]])\n",
    "            mascara_reconstruida[x_start:x_start + patch_size, y_start:y_start + patch_size, :] = add_border(mask[idx], colors[classificacao[idx_classification]])\n",
    "    \n",
    "    return imagem_reconstruida, mascara_reconstruida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_slices(pdf_filename, patients, images_left, images_right, mask_left, mask_right, labels_true, labels_pred):\n",
    "    \"\"\"\n",
    "    Gera um PDF com imagens de pacientes e suas máscaras.\n",
    "\n",
    "    Args:\n",
    "        pdf_filename (str): Nome do arquivo PDF.\n",
    "        patients (list): Lista de IDs dos pacientes.\n",
    "        images_dict (dict): Dicionário com imagens completas dos pacientes.\n",
    "        masks_dict (dict): Dicionário com máscaras completas dos pacientes.\n",
    "        labels_true (list): Labels verdadeiros das fatias.\n",
    "        labels_pred (list): Labels preditos das fatias.\n",
    "        slice_limits (list): Limites de fatias por paciente.\n",
    "        non_black_threshold (float): Limite para considerar pixels não pretos.\n",
    "        min_percentage_non_black (float): Porcentagem mínima de pixels não pretos para exibir.\n",
    "    \"\"\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        for patient in patients:\n",
    "            cont = 0            \n",
    "            \n",
    "            classificacao = []\n",
    "            vetor_left_img = []\n",
    "            vetor_left_mask = []\n",
    "            vetor_right_img = []\n",
    "            vetor_right_mask = []\n",
    "            tmp_vetor_left_img = []\n",
    "            tmp_vetor_left_mask = []\n",
    "            tmp_vetor_right_img = []\n",
    "            tmp_vetor_right_mask = []\n",
    "            tmp_classificacao = []\n",
    "            \n",
    "            for img_left, img_right, msk_left, msk_right in zip(images_left[patient], images_right[patient], mask_left[patient], mask_right[patient]):\n",
    "                tmp_vetor_left_img.append(img_left)\n",
    "                tmp_vetor_left_mask.append(msk_left)\n",
    "                tmp_vetor_right_img.append(np.fliplr(img_right))\n",
    "                tmp_vetor_right_mask.append(np.fliplr(msk_right))\n",
    "                if labels_pred[cont] == 1:\n",
    "                    if labels_true[cont] == 1:\n",
    "                        tmp_classificacao.append(\"TP\")\n",
    "                    else:\n",
    "                        if (calculate_label(msk_left) or calculate_label(msk_right)):\n",
    "                            tmp_classificacao.append(\"TP\")\n",
    "                        else:\n",
    "                            tmp_classificacao.append(\"FP\")\n",
    "                elif labels_pred[cont] == 0:\n",
    "                    if labels_true[cont] == 1:\n",
    "                        if (calculate_label(msk_left) or calculate_label(msk_right)):\n",
    "                            tmp_classificacao.append(\"FN\")\n",
    "                        else:\n",
    "                            tmp_classificacao.append(\"TN\")\n",
    "                    else:\n",
    "                        tmp_classificacao.append(\"TN\")\n",
    "                \n",
    "                cont+=1\n",
    "                if cont%8 ==0:\n",
    "                    vetor_left_img.append(tmp_vetor_left_img)\n",
    "                    vetor_left_mask.append(tmp_vetor_left_mask)\n",
    "                    vetor_right_img.append(tmp_vetor_right_img)\n",
    "                    vetor_right_mask.append(tmp_vetor_right_mask)\n",
    "                    classificacao.append(tmp_classificacao)\n",
    "                    tmp_vetor_left_img = []\n",
    "                    tmp_vetor_left_mask = []\n",
    "                    tmp_vetor_right_img = []\n",
    "                    tmp_vetor_right_mask = []\n",
    "                    tmp_classificacao = []\n",
    "            \n",
    "            cont = 0\n",
    "            for i in range(len(vetor_left_img)):\n",
    "                imagem_reconstruida, mascara_reconstruida = build_image(vetor_left_img[i]+vetor_right_img[i], vetor_left_mask[i]+vetor_right_mask[i], classificacao[i])\n",
    "                if (np.any(imagem_reconstruida) == 1):    \n",
    "                    # Configurar a figura\n",
    "                    fig, axs = plt.subplots(2, 1, figsize=(4, 4))\n",
    "\n",
    "                    axs[0].imshow(np.flipud(imagem_reconstruida), cmap='gray')\n",
    "                    axs[0].set_title(f'{patient}')\n",
    "                    axs[0].axis('off')\n",
    "                    axs[1].imshow(np.flipud(mascara_reconstruida), cmap='gray')\n",
    "                    axs[1].axis('off')\n",
    "                    \n",
    "                    # Adicionar ao PDF\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close(fig)\n",
    "        \n",
    "        print(f\"As imagens foram salvas no arquivo PDF {pdf_filename} com sucesso.\")\n",
    "\n",
    "# Processar Teste\n",
    "plot_patient_slices(\n",
    "    pdf_filename=\"Pdf_SNN/Pacientes_Test_Reconstruidos.pdf\",\n",
    "    patients=test_patients,\n",
    "    images_left=images_left_by_patient,\n",
    "    images_right=images_right_by_patient,\n",
    "    mask_left=mask_left_by_patient,\n",
    "    mask_right=mask_right_by_patient,\n",
    "    labels_true=y_test,\n",
    "    labels_pred=y_pred_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
